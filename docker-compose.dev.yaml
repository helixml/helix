# Common runner configuration (YAML anchor, not a service)
x-runner-config: &runner-config
    restart: always
    entrypoint: bash -c "cd /workspace/helix && go version && tail -f /dev/null"
    env_file:
        - .env
    environment:
        # Explicitly set Go cache paths for clarity
        - GOMODCACHE=/go/pkg/mod
        - GOCACHE=/root/.cache/go-build
        # Prevent automatic toolchain downloads
        - GOTOOLCHAIN=local
    volumes:
        - .:/workspace/helix
        - ~/.cache/huggingface:/root/.cache/huggingface
        # Go caches for faster development
        - go-pkg-mod:/go/pkg/mod
        - go-build-cache:/root/.cache/go-build
        - go-sdk-cache:/root/.cache/go
        # comment these out if you don't have appropriate repos checked out
        # - ../axolotl:/workspace/axolotl

services:
    api:
        build:
            context: .
            dockerfile: Dockerfile
            target: api-dev-env
        networks:
            default:
                ipv4_address: 172.19.0.20
        ports:
            - ${API_PORT:-8080}:8080
            - "3478:3478/udp"  # TURN server for WebRTC NAT traversal
            - "3478:3478/tcp"  # TURN server TCP transport (firewall fallback)
        restart: always
        env_file:
            - .env
        environment:
            - SERVER_PORT=8080
            - LOG_LEVEL=${LOG_LEVEL:-debug}
            - POSTGRES_HOST=postgres
            - POSTGRES_DATABASE=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
            - RUNNER_TOKEN=${RUNNER_TOKEN-oh-hallo-insecure-token}
            - SERVER_URL=${SERVER_URL:-http://localhost:8080}
            - KEYCLOAK_URL=http://keycloak:8080/auth
            - JANITOR_SLACK_WEBHOOK_URL=${JANITOR_SLACK_WEBHOOK_URL:-}
            - JANITOR_SLACK_IGNORE_USERS=${JANITOR_SLACK_IGNORE_USERS:-}
            - OPENAI_API_KEY=${OPENAI_API_KEY:-}
            - TOGETHER_API_KEY=${TOGETHER_API_KEY:-}
            - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
            - HF_TOKEN=${HF_TOKEN:-}
            - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY:-}
            - STRIPE_WEBHOOK_SIGNING_SECRET=${STRIPE_WEBHOOK_SIGNING_SECRET:-}
            - STRIPE_PRICE_LOOKUP_KEY=${STRIPE_PRICE_LOOKUP_KEY:-}
            - FRONTEND_URL=http://frontend:8081
            # this is an insecure development key do not use!
            - KEYCLOAK_USER=admin
            - KEYCLOAK_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD-oh-hallo-insecure-password}
            - KEYCLOAK_FRONTEND_URL=${KEYCLOAK_FRONTEND_URL:-http://localhost:8080/auth/}
            # lock down dashboard in production
            - ADMIN_USER_IDS=${ADMIN_USER_IDS-all}
            - EVAL_USER_ID=${EVAL_USER_ID:-}
            - FILESTORE_LOCALFS_PATH=/filestore
            - SENTRY_DSN_API=${SENTRY_DSN_API:-}
            - SENTRY_DSN_FRONTEND=${SENTRY_DSN_FRONTEND:-}
            - GOOGLE_ANALYTICS_FRONTEND=${GOOGLE_ANALYTICS_FRONTEND:-}
            # Tools configuration
            - TOOLS_ENABLED=true
            - TOOLS_PROVIDER=${TOOLS_PROVIDER:-helix}
            - TOOLS_MODEL=${TOOLS_MODEL:-llama3:instruct}
            # Email notifications
            - EMAIL_MAILGUN_DOMAIN=${EMAIL_MAILGUN_DOMAIN:-}
            - EMAIL_MAILGUN_API_KEY=${EMAIL_MAILGUN_API_KEY:-}
            # SMTP
            - EMAIL_SMTP_HOST=${EMAIL_SMTP_HOST:-}
            - EMAIL_SMTP_PORT=${EMAIL_SMTP_PORT:-}
            - EMAIL_SMTP_USERNAME=${EMAIL_SMTP_USERNAME:-}
            - EMAIL_SMTP_PASSWORD=${EMAIL_SMTP_PASSWORD:-}
            # Discord integration
            - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN:-}
            - ADMIN_USER_SOURCE=${ADMIN_USER_SOURCE:-}
            # AI Providers management - enable/disable user-facing AI provider API keys management
            - PROVIDERS_MANAGEMENT_ENABLED=${PROVIDERS_MANAGEMENT_ENABLED:-true}
            # Socket configuration for haystack communication
            - HELIX_EMBEDDINGS_SOCKET=/socket/embeddings.sock
            - RAG_HAYSTACK_ENABLED=true
            - RAG_DEFAULT_PROVIDER=${RAG_DEFAULT_PROVIDER:-haystack}
            # URL in the compose stack (rather than localhost in the pod which is default for k8s)
            - RAG_HAYSTACK_URL=http://haystack:8000
            - RAG_PGVECTOR_PROVIDER=helix
            # Dynamic providers: format is "provider1:api_key1:base_url1,provider2:api_key2:base_url2"
            - DYNAMIC_PROVIDERS=${DYNAMIC_PROVIDERS:-}
            # Wolf integration for external agents
            - WOLF_SOCKET_PATH=/var/run/wolf/wolf.sock
            - WOLF_MODE=${WOLF_MODE:-apps}  # "apps" (default) or "lobbies" (multi-user with PIN support)
            - ZED_IMAGE=${ZED_IMAGE:-helix-sway:latest}
            - HELIX_HOST_HOME=${HELIX_HOST_HOME}
            - HELIX_DEV_MODE=true  # Enable dev file bind-mounts for hot-reloading
            # Moonlight-web architecture mode: "single" (keepalive/join, session-persistence) or "multi" (streamers API, broadcasting)
            - MOONLIGHT_WEB_MODE=${MOONLIGHT_WEB_MODE:-single}
            - MOONLIGHT_CREDENTIALS=${MOONLIGHT_CREDENTIALS:-helix}
            # TURN server configuration for WebRTC
            - TURN_ENABLED=true
            - TURN_PUBLIC_IP=${TURN_PUBLIC_IP:-api}  # Use 'api' hostname for local relay (auto-detects public IP)
            - TURN_PORT=3478
            - TURN_REALM=helix.ai
            - TURN_USERNAME=helix
            - TURN_PASSWORD=${TURN_PASSWORD:-helix-turn-secret}
        volumes:
            - ./go.mod:/app/go.mod
            - ./go.sum:/app/go.sum
            - ./api:/app/api
            - ./WORKDIR_README.md:/opt/helix/WORKDIR_README.md:ro
            - ${FILESTORE_DATA:-helix-filestore}:/filestore
            - helix-socket:/socket
            # Bind-mount from host (Wolf creates socket here)
            - /var/run/wolf:/var/run/wolf:rw
        depends_on:
            - postgres
            - postgres-mcp
        extra_hosts:
            - "host.docker.internal:host-gateway"
    postgres:
        image: postgres:12.13-alpine
        restart: always
        # ports:
        #  - 5432:5432
        volumes:
            - ${POSTGRES_DATA:-helix-postgres-db}:/var/lib/postgresql/data
            - ./scripts/postgres:/docker-entrypoint-initdb.d

        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
            - POSTGRES_DATABASES=keycloak
    # Example/test MCP server
    postgres-mcp:
        image: crystaldba/postgres-mcp:latest
        restart: always
        command: ["--access-mode=unrestricted", "--transport=sse"]
        environment:
            - DATABASE_URI=postgresql://postgres:postgres@postgres:5432/postgres
        ports:
        - 8000:8000
    # postgres 15 with pgvector installed
    # why run this as a different server?
    # because we want the quick path to something working without having to create a hard dependency on pgvector
    # being installed in our main database
    # also - we would need to migrate our existing postgres 12 DB -> 17, which is a bit of a pain
    # TODO: figure out how to ship the pgvector extension with our main database
    # so we don't need to run what is essentially 2 versions of postgres
    pgvector:
        image: ghcr.io/tensorchord/vchord_bm25-postgres:pg17-v0.1.1
        restart: always
        # ports:
        #  - 5433:5432
        volumes:
            - ${PGVECTOR_DATA:-helix-pgvector-db}:/var/lib/postgresql/data
        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${PGVECTOR_PASSWORD-postgres}

    # Kodit code indexing service
    kodit:
        profiles: [kodit]
        image: registry.helixml.tech/helix/kodit:latest
        # ports:
        #   - 8632:8632
        command: ["serve", "--host", "0.0.0.0", "--port", "8632"]
        restart: always
        depends_on:
            - vectorchord-kodit
            - api
        environment:
            - DATA_DIR=/data
            - DB_URL=postgresql+asyncpg://postgres:postgres@vectorchord-kodit:5432/kodit
            - DEFAULT_SEARCH_PROVIDER=vectorchord
            # External enrichment provider (TogetherAI direct)
            # TODO: Switch to Helix proxy once we figure out litellm model name format
            # Should be: ENRICHMENT_ENDPOINT_BASE_URL=http://api:8080/v1 with runner token
            # Currently fails with "model not found" - need to investigate Helix model routing
            - ENRICHMENT_ENDPOINT_MODEL=together_ai/Qwen/Qwen3-Next-80B-A3B-Instruct
            - ENRICHMENT_ENDPOINT_API_KEY=${TOGETHER_API_KEY}
            - ENRICHMENT_ENDPOINT_NUM_PARALLEL_TASKS=3
            - ENRICHMENT_ENDPOINT_TIMEOUT=120
            # Sync configuration
            - SYNC_PERIODIC_ENABLED=true
            - SYNC_PERIODIC_INTERVAL_SECONDS=1800  # 30 minutes
            - SYNC_PERIODIC_RETRY_ATTEMPTS=3
            - LOG_LEVEL=INFO
            - LOG_FORMAT=json
            - API_KEYS=${KODIT_API_KEYS:-dev-key}
        volumes:
            - helix-socket:/socket
            - ${KODIT_DATA:-helix-kodit-data}:/data

    # Kodit PostgreSQL database with pgvector
    vectorchord-kodit:
        profiles: [kodit]
        image: tensorchord/vchord-suite:pg17-20250601
        restart: always
        environment:
            - POSTGRES_DB=kodit
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=postgres
        volumes:
            - ${VECTORCHORD_KODIT_DATA:-helix-vectorchord-kodit}:/var/lib/postgresql/data
        # ports:
        #   - 5434:5432
    # keycloak:
    #     image: quay.io/keycloak/keycloak:23.0
    #     restart: always
    #     environment:
    #         - KC_DB=postgres
    #         - KC_DB_URL=jdbc:postgresql://postgres:5432/keycloak
    #         - KC_DB_USERNAME=postgres
    #         - KC_DB_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
    #         - KEYCLOAK_ADMIN=admin
    #         - KEYCLOAK_ADMIN_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD-oh-hallo-insecure-password}
    #         - KC_PROXY_HEADERS=forwarded|xforwarded
    #         - KC_HEALTH_ENABLED=true
    #         - KC_HOSTNAME_PATH=/auth
    #         - KC_HTTP_RELATIVE_PATH=/auth/
    #         - KC_HOSTNAME_URL=${KEYCLOAK_FRONTEND_URL:-http://localhost:8080/auth/}
    #         - KC_HOSTNAME_ADMIN_URL=${KEYCLOAK_FRONTEND_URL:-http://localhost:8080/auth/}
    #         # Theme development settings - disable caching
    #         - KC_SPI_THEME_CACHE_THEMES=false
    #         - KC_SPI_THEME_CACHE_TEMPLATES=false
    #         - KC_SPI_THEME_STATIC_MAX_AGE=-1
    #     volumes:
    #         # Mount themes directory for development
    #         - ./themes:/opt/keycloak/themes
    #     healthcheck:
    #         test:
    #             [
    #                 "CMD-SHELL",
    #                 "exec 3<>/dev/tcp/127.0.0.1/8080;echo -e \"GET /auth/health/ready HTTP/1.1\r\nhost: http://localhost\r\nConnection: close\r\n\r\n\" >&3;grep \"HTTP/1.1 200 OK\" <&3",
    #             ]
    #         interval: 5s
    #         timeout: 5s
    #         retries: 30
    #     command: ["start-dev"]
    #     # ports:
        #   - 30080:8080
    webhook_relay_stripe:
        image: webhookrelay/webhookrelayd
        environment:
            - KEY=${WEBHOOK_RELAY_KEY:-}
            - SECRET=${WEBHOOK_RELAY_SECRET:-}
            - BUCKET=${WEBHOOK_RELAY_BUCKET:-}
    tika:
        image: apache/tika:2.9.2.1
        # ports:
        #   - 9998:9998
    searxng:
        image: searxng/searxng:latest
        # ports:
        #   - 8112:8080
        volumes:
            - ./searxng/settings.yml:/etc/searxng/settings.yml
            - ./searxng/limiter.toml:/etc/searxng/limiter.toml
        environment:
            - BASE_URL=http://searxng:8080
            - INSTANCE_NAME=helix-instance
            - UWSGI_WORKERS=4
            - UWSGI_THREADS=4

    typense-ui:
        image: ghcr.io/bfritscher/typesense-dashboard:latest
        # ports:
        #   - 8877:80
        volumes:
            - ./scripts/config.json:/srv/config.json
        depends_on:
            - typesense
    typesense:
        build:
            context: .
            dockerfile: Dockerfile.typesense
        command: ["--data-dir", "/data", "--api-key", "typesense"]
        # ports:
        #   - 8108:8108
        volumes:
            - ${TYPESENSE_DATA:-helix-typesense-db}:/data
    chrome:
        image: ghcr.io/go-rod/rod:v0.115.0
        restart: always
        volumes:
            - ./integration-test/data/smoke:/integration-test/data/smoke
        # ports:
        #   - 7317:7317

    wolf:
      profiles: [wolf]
      # Using public upstream image for ARM64 compatibility (local build not available on Apple Silicon)
      # For local dev builds: uncomment wolf:helix-fixed and comment this out, but requires x86_64
      # image: wolf:helix-fixed
      image: ghcr.io/games-on-whales/wolf:wolf-ui
      networks:
        default:
          ipv4_address: 172.19.0.50
      environment:
        - NVIDIA_DRIVER_CAPABILITIES=all
        - NVIDIA_VISIBLE_DEVICES=all
        # Wolf-UI required environment variables
        - XDG_RUNTIME_DIR=/tmp/sockets
        - HOST_APPS_STATE_FOLDER=/etc/wolf
        - WOLF_SOCKET_PATH=/var/run/wolf/wolf.sock
        # Debug logging for HTTPS connection issues and UDP/RTP activity
        - WOLF_LOG_LEVEL=DEBUG
        # GST_DEBUG levels: 0=none, 1=ERROR, 2=WARNING, 3=INFO, 4=DEBUG, 5=LOG (full trace)
        # Level 3 (INFO) temporarily enabled for buffer pool diagnosis
        # WARNING: Level 5 produces massive logs - use sparingly
        - GST_DEBUG=3
        # NOTE: Interpipe cleanup CRITICAL errors are harmless - occur when containers terminate
        # "gst_inter_pipe_ilistener_push_buffer: assertion failed" during session cleanup
        # Fix HTTPS serverinfo hangs by avoiding slow MAC address enumeration
        - WOLF_INTERNAL_MAC=00:11:22:33:44:55
        - WOLF_INTERNAL_IP=172.19.0.50
        # Fix HTTPS SSL certificate paths for proper SSL operation
        - WOLF_PRIVATE_KEY_FILE=/etc/wolf/cfg/key.pem
        - WOLF_PRIVATE_CERT_FILE=/etc/wolf/cfg/cert.pem
        # Enable Nvidia zero-copy for better performance with new waylanddisplaysrc
        # New wolf-ui branch supports direct CUDAMemory output from waylanddisplaysrc
        - WOLF_USE_ZERO_COPY=TRUE
        # Internal moonlight-web pairing PIN (secure random, shared via env)
        - MOONLIGHT_INTERNAL_PAIRING_PIN=${MOONLIGHT_INTERNAL_PAIRING_PIN:-}
        # GOP size (keyframe interval): frames between I-frames
        # Configured in .env file - see comments there for recommended values
        - GOP_SIZE=${GOP_SIZE:-15}
      volumes:
        - ./wolf/:/etc/wolf/cfg/
        # Mount init script into container init directory
        - ./wolf/init-wolf-config.sh:/etc/cont-init.d/05-init-wolf-config.sh:ro
        - /tmp/sockets:/tmp/sockets:rw
        - /var/run/docker.sock:/var/run/docker.sock:rw
        - /dev/:/dev/:rw
        - /run/udev:/run/udev:rw
        # Bind-mount to host so wolf-ui containers can bind-mount it
        - /var/run/wolf:/var/run/wolf:rw
      device_cgroup_rules:
        - 'c 13:* rmw'
      devices:
        - /dev/dri
        - /dev/uinput
        - /dev/uhid
      ports:
        # Moonlight protocol ports
        - "47984:47984"     # HTTPS
        - "47989:47989"     # HTTP (pairing, serverinfo)
        - "48010:48010"     # RTSP
        - "47415:47415/udp" # Discovery
        - "47999:47999/udp" # Control
        - "48100:48100/udp" # Video RTP
        - "48200:48200/udp" # Audio RTP
      runtime: nvidia
      deploy:
        resources:
          reservations:
            devices:
              - capabilities: [gpu]
      restart: unless-stopped

    # Moonlight Web Stream - Browser-based Moonlight streaming
    moonlight-web:
      profiles: [wolf]
      image: helix-moonlight-web:helix-fixed
      command: bash -c "/app/server/init-moonlight-config.sh"
      ports:
        - "8081:8080"  # Web interface
        - "40000-40100:40000-40100/udp"  # WebRTC UDP ports (expanded for multiple concurrent sessions)
      networks:
        - default
      environment:
        # Enable trace logging for debugging UDP/streaming issues
        # Reduce webrtc_sctp noise to warn level (debug floods logs with peer_last_tsn messages)
        - RUST_LOG=moonlight_common=trace,moonlight_web=trace,streamer::video=info,webrtc_sctp=warn
        # Internal pairing PIN (shared with Wolf, secure random in production)
        - MOONLIGHT_INTERNAL_PAIRING_PIN=${MOONLIGHT_INTERNAL_PAIRING_PIN:-}
        # Moonlight credentials for API authentication (must match config.json)
        - MOONLIGHT_CREDENTIALS=${MOONLIGHT_CREDENTIALS:-helix}
        # TURN server credentials (must match config.json)
        - TURN_PASSWORD=${TURN_PASSWORD:-helix-turn-secret}
        # TURN server public IP (auto-detected if not set, or use --api-host from install.sh)
        - TURN_PUBLIC_IP=${TURN_PUBLIC_IP:-}
        # Note: TURN config is templated in config.json.template with {{TURN_PUBLIC_IP}}
        # Both moonlight-web and browser clients use the same ICE servers from that config
        #
        # IMPORTANT: config.json persists across restarts to avoid unnecessary regeneration.
        # If your public IP changes and browser input stops working, force a refresh:
        #   rm moonlight-web-config/config.json && docker compose -f docker-compose.dev.yaml restart moonlight-web
      volumes:
        - ./moonlight-web-config:/app/server:rw
      restart: unless-stopped
      depends_on:
        - wolf

    # GPU-enabled runner (for LLM inference)
    runner_gpu:
        <<: *runner-config
        profiles: ["runner_gpu"]
        entrypoint: bash -c "cd /workspace/helix && export PATH=/root/go/bin:\$PATH && export HELIX_COMMAND=runner && air --build.bin /helix-runner --build.cmd 'CGO_ENABLED=1 go build -buildvcs=false -tags \"!rocm\" -ldflags \"-s -w -X github.com/helixml/helix/api/pkg/data.Version=v0.0.0+dev\" -o /helix-runner ./runner-cmd/helix-runner' --build.stop_on_error true --log.main_only true"
        build:
            context: .
            dockerfile: Dockerfile.runner
            args:
                TAG: 2025-08-13c-large
        environment:
            # Runner configuration
            - API_HOST=http://172.17.0.1:8080
            - API_TOKEN=oh-hallo-insecure-token
            - RUNNER_ID=dev-gpu-runner
            - LOG_LEVEL=debug
            - HELIX_COMMAND=runner
            # Prevent toolchain downloads
            - GOTOOLCHAIN=local
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [gpu]

    demos:
        profiles: ["demos"]
        build:
            context: .
            dockerfile: Dockerfile.demos
        ports:
            - ${DEMOS_PORT:-8085}:8085
        restart: always
        env_file:
            - .env
        environment:
            - PORT=8085
        entrypoint: ${DEMOS_ENTRYPOINT:-tail -f /dev/null}
        volumes:
            - ./go.mod:/app/go.mod
            - ./go.sum:/app/go.sum
            - ./demos:/app/demos

    frontend:
        # ports:
        #   - 8081:${FRONTEND_INTERNAL_PORT:-8081}
        build:
            context: .
            dockerfile: Dockerfile
            target: ui-dev-env
        restart: always
        volumes:
            # Mount source code for hot reload, but preserve container's node_modules
            - ./frontend/src:/app/src
            - ./frontend/assets:/app/assets
            - ./frontend/index.html:/app/index.html
            - ./frontend/tsconfig.json:/app/tsconfig.json
            - ./frontend/vite.config.ts:/app/vite.config.ts
            - ./frontend/package.json:/app/package.json
            - ./frontend/yarn.lock:/app/yarn.lock
            # Preserve node_modules from image build (don't mount from host)
            - /app/node_modules

    haystack:
        build:
            context: ./haystack_service
        # ports:
        #   - 8001:8000
        restart: always
        environment:
            - PGVECTOR_DSN=postgresql://postgres:postgres@pgvector:5432/postgres
            - LOG_LEVEL=INFO
            - VLLM_BASE_URL=${RAG_HAYSTACK_EMBEDDINGS_BASE_URL:-} # Need to set this to an external VLLM server in development
            - VLLM_API_KEY=${RAG_HAYSTACK_EMBEDDINGS_API_KEY:-EMPTY}
            - RAG_HAYSTACK_EMBEDDINGS_MODEL=${RAG_HAYSTACK_EMBEDDINGS_MODEL:-MrLight/dse-qwen2-2b-mrl-v1}
            - RAG_HAYSTACK_EMBEDDINGS_DIM=${RAG_HAYSTACK_EMBEDDINGS_DIM:-1536}
            - RAG_HAYSTACK_EMBEDDINGS_MAX_TOKENS=${RAG_HAYSTACK_EMBEDDINGS_MAX_TOKENS:-32768}
            - RAG_HAYSTACK_CHUNK_SIZE=${RAG_HAYSTACK_CHUNK_SIZE:-500}
            - RAG_HAYSTACK_CHUNK_OVERLAP=${RAG_HAYSTACK_CHUNK_OVERLAP:-50}
            # Socket configuration for api communication
            - HELIX_EMBEDDINGS_SOCKET=/socket/embeddings.sock
            - RAG_VISION_EMBEDDINGS_SOCKET=/socket/embeddings.sock
            # Vision RAG Settings
            - RAG_VISION_ENABLED=${RAG_VISION_ENABLED:-true}
            - RAG_VISION_BASE_URL=${RAG_VISION_BASE_URL:-}
            - RAG_VISION_API_KEY=${RAG_VISION_API_KEY:-}
            - RAG_VISION_EMBEDDINGS_MODEL=${RAG_VISION_EMBEDDINGS_MODEL:-MrLight/dse-qwen2-2b-mrl-v1}
            - RAG_VISION_EMBEDDINGS_DIM=${RAG_VISION_EMBEDDINGS_DIM:-1536}
            - RAG_VISION_PGVECTOR_TABLE=${RAG_VISION_PGVECTOR_TABLE:-haystack_documents_vision}
        volumes:
            - ./haystack_service/app:/app/app
            - ./haystack_service/main.py:/app/main.py
            - helix-socket:/socket
        command:
            [
                "uvicorn",
                "main:app",
                "--host",
                "0.0.0.0",
                "--port",
                "8000",
            ]
        depends_on:
            - pgvector
        extra_hosts:
            - "host.docker.internal:host-gateway"

volumes:
    helix-keycloak-db:
    helix-postgres-db:
    helix-pgvector-db:
    helix-vectorchord-kodit:
    helix-kodit-data:
    helix-filestore:
    helix-typesense-db:
    helix-socket:
    wolf-socket:
    zed-work:

    go-pkg-mod: # Go module cache
    go-build-cache: # Go build cache
    go-sdk-cache: # Go toolchain/SDK cache
    # No persistent volumes for zed workspaces - using tmpfs for clean sessions

networks:
    default:
        name: helix_default
        ipam:
            config:
                - subnet: 172.19.0.0/16
