# Common runner configuration (YAML anchor, not a service)
x-runner-config: &runner-config
    restart: always
    entrypoint: bash -c "cd /workspace/helix && go version && tail -f /dev/null"
    env_file:
        - .env
    environment:
        # Explicitly set Go cache paths for clarity
        - GOMODCACHE=/go/pkg/mod
        - GOCACHE=/root/.cache/go-build
        # Prevent automatic toolchain downloads
        - GOTOOLCHAIN=local
    volumes:
        - .:/workspace/helix
        - ~/.cache/huggingface:/root/.cache/huggingface
        # Go caches for faster development
        - go-pkg-mod:/go/pkg/mod
        - go-build-cache:/root/.cache/go-build
        - go-sdk-cache:/root/.cache/go
        # comment these out if you don't have appropriate repos checked out
        # - ../axolotl:/workspace/axolotl

services:
    api:
        build:
            context: .
            dockerfile: Dockerfile
            target: api-dev-env
        ports:
            - ${API_PORT:-8080}:8080
            # RDP proxy port range for Guacamole connections
            - "15900-15999:15900-15999"
        restart: always
        env_file:
            - .env
        environment:
            - SERVER_PORT=8080
            - LOG_LEVEL=${LOG_LEVEL:-debug}
            - POSTGRES_HOST=postgres
            - POSTGRES_DATABASE=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
            - RUNNER_TOKEN=${RUNNER_TOKEN-oh-hallo-insecure-token}
            - SERVER_URL=${SERVER_URL:-http://localhost:8080}
            - KEYCLOAK_URL=http://keycloak:8080/auth
            - JANITOR_SLACK_WEBHOOK_URL=${JANITOR_SLACK_WEBHOOK_URL:-}
            - JANITOR_SLACK_IGNORE_USERS=${JANITOR_SLACK_IGNORE_USERS:-}
            - OPENAI_API_KEY=${OPENAI_API_KEY:-}
            - TOGETHER_API_KEY=${TOGETHER_API_KEY:-}
            - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
            - HF_TOKEN=${HF_TOKEN:-}
            - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY:-}
            - STRIPE_WEBHOOK_SIGNING_SECRET=${STRIPE_WEBHOOK_SIGNING_SECRET:-}
            - STRIPE_PRICE_LOOKUP_KEY=${STRIPE_PRICE_LOOKUP_KEY:-}
            - FRONTEND_URL=http://frontend:8081
            # this is an insecure development key do not use!
            - KEYCLOAK_USER=admin
            - KEYCLOAK_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD-oh-hallo-insecure-password}
            - KEYCLOAK_FRONTEND_URL=${KEYCLOAK_FRONTEND_URL:-http://localhost:8080/auth/}
            # lock down dashboard in production
            - ADMIN_USER_IDS=${ADMIN_USER_IDS-all}
            - EVAL_USER_ID=${EVAL_USER_ID:-}
            - FILESTORE_LOCALFS_PATH=/filestore
            - SENTRY_DSN_API=${SENTRY_DSN_API:-}
            - SENTRY_DSN_FRONTEND=${SENTRY_DSN_FRONTEND:-}
            - GOOGLE_ANALYTICS_FRONTEND=${GOOGLE_ANALYTICS_FRONTEND:-}
            # Tools configuration
            - TOOLS_ENABLED=true
            - TOOLS_PROVIDER=${TOOLS_PROVIDER:-helix}
            - TOOLS_MODEL=${TOOLS_MODEL:-llama3:instruct}
            # Email notifications
            - EMAIL_MAILGUN_DOMAIN=${EMAIL_MAILGUN_DOMAIN:-}
            - EMAIL_MAILGUN_API_KEY=${EMAIL_MAILGUN_API_KEY:-}
            # SMTP
            - EMAIL_SMTP_HOST=${EMAIL_SMTP_HOST:-}
            - EMAIL_SMTP_PORT=${EMAIL_SMTP_PORT:-}
            - EMAIL_SMTP_USERNAME=${EMAIL_SMTP_USERNAME:-}
            - EMAIL_SMTP_PASSWORD=${EMAIL_SMTP_PASSWORD:-}
            # Discord integration
            - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN:-}
            - ADMIN_USER_SOURCE=${ADMIN_USER_SOURCE:-}
            # Socket configuration for haystack communication
            - HELIX_EMBEDDINGS_SOCKET=/socket/embeddings.sock
            - RAG_HAYSTACK_ENABLED=true
            - RAG_DEFAULT_PROVIDER=${RAG_DEFAULT_PROVIDER:-haystack}
            # URL in the compose stack (rather than localhost in the pod which is default for k8s)
            - RAG_HAYSTACK_URL=http://haystack:8000
            - RAG_PGVECTOR_PROVIDER=helix
            # Dynamic providers: format is "provider1:api_key1:base_url1,provider2:api_key2:base_url2"
            - DYNAMIC_PROVIDERS=${DYNAMIC_PROVIDERS:-}
            # Guacamole configuration
            - GUACAMOLE_SERVER_URL=${GUACAMOLE_SERVER_URL:-http://guacamole-client:8080}
            - GUACAMOLE_USERNAME=${GUACAMOLE_USERNAME:-guacadmin}
            - GUACAMOLE_PASSWORD=${GUACAMOLE_PASSWORD:-guacadmin}
            # Direct VNC proxy for local development (bypasses reverse dial)
            - DIRECT_VNC_PROXY=${DIRECT_VNC_PROXY:-true}
        volumes:
            - ./go.mod:/app/go.mod
            - ./go.sum:/app/go.sum
            - ./api:/app/api
            - ${FILESTORE_DATA:-helix-filestore}:/filestore
            - helix-socket:/socket
        depends_on:
            - postgres
            - keycloak
            - postgres-mcp
        extra_hosts:
            - "host.docker.internal:host-gateway"
    postgres:
        image: postgres:12.13-alpine
        restart: always
        # ports:
        #  - 5432:5432
        volumes:
            - ${POSTGRES_DATA:-helix-postgres-db}:/var/lib/postgresql/data
            - ./scripts/postgres:/docker-entrypoint-initdb.d

        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
            - POSTGRES_DATABASES=keycloak,guacamole_db
    # Example/test MCP server
    postgres-mcp:
        image: crystaldba/postgres-mcp:latest
        restart: always
        command: ["--access-mode=unrestricted", "--transport=sse"]
        environment:
            - DATABASE_URI=postgresql://postgres:postgres@postgres:5432/postgres
        ports:
        - 8000:8000
    # postgres 15 with pgvector installed
    # why run this as a different server?
    # because we want the quick path to something working without having to create a hard dependency on pgvector
    # being installed in our main database
    # also - we would need to migrate our existing postgres 12 DB -> 17, which is a bit of a pain
    # TODO: figure out how to ship the pgvector extension with our main database
    # so we don't need to run what is essentially 2 versions of postgres
    pgvector:
        image: ghcr.io/tensorchord/vchord_bm25-postgres:pg17-v0.1.1
        restart: always
        # ports:
        #  - 5433:5432
        volumes:
            - ${PGVECTOR_DATA:-helix-pgvector-db}:/var/lib/postgresql/data
        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${PGVECTOR_PASSWORD-postgres}
    keycloak:
        image: quay.io/keycloak/keycloak:23.0
        restart: always
        environment:
            - KC_DB=postgres
            - KC_DB_URL=jdbc:postgresql://postgres:5432/keycloak
            - KC_DB_USERNAME=postgres
            - KC_DB_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
            - KEYCLOAK_ADMIN=admin
            - KEYCLOAK_ADMIN_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD-oh-hallo-insecure-password}
            - KC_PROXY_HEADERS=forwarded|xforwarded
            - KC_HEALTH_ENABLED=true
            - KC_HOSTNAME_PATH=/auth
            - KC_HTTP_RELATIVE_PATH=/auth/
            - KC_HOSTNAME_URL=${KEYCLOAK_FRONTEND_URL:-http://localhost:8080/auth/}
            - KC_HOSTNAME_ADMIN_URL=${KEYCLOAK_FRONTEND_URL:-http://localhost:8080/auth/}
            # Theme development settings - disable caching
            - KC_SPI_THEME_CACHE_THEMES=false
            - KC_SPI_THEME_CACHE_TEMPLATES=false
            - KC_SPI_THEME_STATIC_MAX_AGE=-1
        volumes:
            # Mount themes directory for development
            - ./themes:/opt/keycloak/themes
        healthcheck:
            test:
                [
                    "CMD-SHELL",
                    "exec 3<>/dev/tcp/127.0.0.1/8080;echo -e \"GET /auth/health/ready HTTP/1.1\r\nhost: http://localhost\r\nConnection: close\r\n\r\n\" >&3;grep \"HTTP/1.1 200 OK\" <&3",
                ]
            interval: 5s
            timeout: 5s
            retries: 30
        command: ["start-dev"]
        # ports:
        #   - 30080:8080
    webhook_relay_stripe:
        image: webhookrelay/webhookrelayd
        environment:
            - KEY=${WEBHOOK_RELAY_KEY:-}
            - SECRET=${WEBHOOK_RELAY_SECRET:-}
            - BUCKET=${WEBHOOK_RELAY_BUCKET:-}
    tika:
        image: apache/tika:2.9.2.1
        # ports:
        #   - 9998:9998
    searxng:
        image: searxng/searxng:latest
        # ports:
        #   - 8112:8080
        volumes:
            - ./searxng/settings.yml:/etc/searxng/settings.yml
            - ./searxng/limiter.toml:/etc/searxng/limiter.toml
        environment:
            - BASE_URL=http://searxng:8080
            - INSTANCE_NAME=helix-instance
            - UWSGI_WORKERS=4
            - UWSGI_THREADS=4

    typense-ui:
        image: ghcr.io/bfritscher/typesense-dashboard:latest
        # ports:
        #   - 8877:80
        volumes:
            - ./scripts/config.json:/srv/config.json
        depends_on:
            - typesense
    typesense:
        build:
            context: .
            dockerfile: Dockerfile.typesense
        command: ["--data-dir", "/data", "--api-key", "typesense"]
        # ports:
        #   - 8108:8108
        volumes:
            - ${TYPESENSE_DATA:-helix-typesense-db}:/data
    chrome:
        image: ghcr.io/go-rod/rod:v0.115.0
        restart: always
        volumes:
            - ./integration-test/data/smoke:/integration-test/data/smoke
        # ports:
        #   - 7317:7317


    # Zed Agent Task Runner Pool (replaces gptscript runner entirely)
    # Scale with: docker-compose up --scale zed-runner=5
    zed-runner:
        build:
            context: .
            dockerfile: Dockerfile.zed-agent-vnc
            args:
                - BUILD_TYPE=release
        ports:
            - "5901:5901"  # Expose VNC for direct testing
            # Moonlight/Sunshine ports for direct client testing
            - "47989:47989"  # Moonlight HTTP/HTTPS main port
            - "47990:47990"  # Sunshine web UI (HTTPS config interface)
            - "47984:47984"  # Moonlight HTTPS control
            - "47999:47999"  # Moonlight control port (TCP)
            - "47999:47999/udp"  # Moonlight control port (UDP)  
            - "48010:48010"  # Moonlight RTSP (TCP)
            - "48010:48010/udp"  # Moonlight RTSP (UDP)
            - "47998:47998/udp"  # Moonlight video RTP stream (actual streaming port)
            - "48000:48000/udp"  # Moonlight audio RTP stream (actual streaming port)
            - "48100:48100"  # Moonlight video ping/discovery (TCP)
            - "48100:48100/udp"  # Moonlight video ping/discovery (UDP)
            - "48200:48200"  # Moonlight audio ping/discovery (TCP)
            - "48200:48200/udp"  # Moonlight audio ping/discovery (UDP)
        environment:
            # Control plane connection
            - API_HOST=http://api:8080
            - API_TOKEN=${RUNNER_TOKEN-oh-hallo-insecure-token}
            - LOG_LEVEL=debug

            # Zed runner configuration - one session per container, then exit
            - CONCURRENCY=1
            - MAX_TASKS=0  # 0 means unlimited tasks - stay alive for multiple requests
            - SESSION_TIMEOUT=3600

            # Container uses fixed settings since each container is isolated
            - WORKSPACE_DIR=/tmp/workspace
            - WAYLAND_DISPLAY=wayland-0
            - WLR_RENDERER=gles2
            - WLR_BACKENDS=headless
            - WLR_HEADLESS_OUTPUTS=1
            - WLR_NO_HARDWARE_CURSORS=1
            - VNC_PASSWORD=${VNC_PASSWORD:-helix123}
            # Also set RDP_PASSWORD for Helix agent (backwards compatibility)
            - RDP_PASSWORD=${VNC_PASSWORD:-helix123}

            # Wolf-style GPU configuration for container runtime
            - NVIDIA_VISIBLE_DEVICES=all
            - NVIDIA_DRIVER_CAPABILITIES=all
            - WOLF_RENDER_NODE=/dev/dri/renderD128
            - GST_GL_DRM_DEVICE=/dev/dri/renderD128
        volumes:
            # Mount source code for hot reloading during development
            - .:/workspace/helix
            # Persistence for user data in zed environment
            - zed-work:/home/ubuntu/work
            # Go caches for faster development
            - go-pkg-mod:/go/pkg/mod
            - go-build-cache:/root/.cache/go-build
            # Mount Zed launcher scripts for easy iteration
            - ./zed.sh:/usr/local/bin/zed.sh
            - ./zed-vgl.sh:/usr/local/bin/zed-vgl.sh
            - ./zed-wayland.sh:/usr/local/bin/zed-wayland.sh
            # Mount zed-build directory for live binary updates
            - ./zed-build:/zed-build
            # Mount startup script for fast iteration without rebuilds
            - ./start-wayland-vnc.sh:/start-wayland-vnc.sh
            - ./start-ubuntu-session.sh:/start-ubuntu-session.sh
            # Mount Hyprland config for fast iteration
            - ./hypr-config:/home/ubuntu/.config/hypr
            # Mount AGS config from dots-hyprland for fast iteration
            - /home/luke/pm/dots-hyprland/.config/ags:/home/ubuntu/.config/ags
            # Mount screencopy frame captures for debugging/monitoring
            - ./screencopy-frames:/tmp/hyprmoon_frame_dumps
            # Mount Zed config for persistence
            - ./zed-config:/home/ubuntu/.config/zed
        # Add comprehensive GPU access via DRI and NVIDIA devices (Wolf-style)
        devices:
            - "/dev/dri:/dev/dri"
            - "/dev/nvidia0:/dev/nvidia0"
            - "/dev/nvidiactl:/dev/nvidiactl"
            - "/dev/nvidia-modeset:/dev/nvidia-modeset"
            - "/dev/nvidia-uvm:/dev/nvidia-uvm"
            - "/dev/nvidia-uvm-tools:/dev/nvidia-uvm-tools"
        # Enable privileged mode for better GPU access
        privileged: true
        # Explicitly use nvidia runtime for full GPU support
        runtime: nvidia
        # No port mapping needed - RDP proxied over WebSocket connection
        restart: always
        depends_on:
            - api
        deploy:
            # Default to 1 runner, scale with --scale zed-runner=N
            replicas: 1
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [gpu]

    # GPU-enabled runner (for LLM inference)
    runner_gpu:
        <<: *runner-config
        profiles: ["runner_gpu"]
        entrypoint: bash -c "cd /workspace/helix && export PATH=/root/go/bin:\$PATH && export HELIX_COMMAND=runner && air --build.bin /helix-runner --build.cmd 'CGO_ENABLED=1 go build -buildvcs=false -tags \"!rocm\" -ldflags \"-s -w -X github.com/helixml/helix/api/pkg/data.Version=v0.0.0+dev\" -o /helix-runner ./runner-cmd/helix-runner' --build.stop_on_error true --log.main_only true"
        build:
            context: .
            dockerfile: Dockerfile.runner
            args:
                TAG: 2025-08-13c-large
        environment:
            # Runner configuration
            - API_HOST=http://172.17.0.1:8080
            - API_TOKEN=oh-hallo-insecure-token
            - RUNNER_ID=dev-gpu-runner
            - LOG_LEVEL=debug
            - HELIX_COMMAND=runner
            # Prevent toolchain downloads
            - GOTOOLCHAIN=local
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [gpu]

    demos:
        profiles: ["demos"]
        build:
            context: .
            dockerfile: Dockerfile.demos
        ports:
            - ${DEMOS_PORT:-8085}:8085
        restart: always
        env_file:
            - .env
        environment:
            - PORT=8085
        entrypoint: ${DEMOS_ENTRYPOINT:-tail -f /dev/null}
        volumes:
            - ./go.mod:/app/go.mod
            - ./go.sum:/app/go.sum
            - ./demos:/app/demos

    frontend:
        # ports:
        #   - 8081:${FRONTEND_INTERNAL_PORT:-8081}
        build:
            context: .
            dockerfile: Dockerfile
            target: ui-dev-env
        restart: always
        volumes:
            - ./frontend/package.json:/app/package.json
            - ./frontend/src:/app/src
            - ./frontend/assets:/app/assets
            - ./frontend/index.html:/app/index.html
            - ./frontend/tsconfig.json:/app/tsconfig.json
            - ./frontend/vite.config.ts:/app/vite.config.ts

    haystack:
        build:
            context: ./haystack_service
        # ports:
        #   - 8001:8000
        restart: always
        environment:
            - PGVECTOR_DSN=postgresql://postgres:postgres@pgvector:5432/postgres
            - LOG_LEVEL=INFO
            - VLLM_BASE_URL=${RAG_HAYSTACK_EMBEDDINGS_BASE_URL:-} # Need to set this to an external VLLM server in development
            - VLLM_API_KEY=${RAG_HAYSTACK_EMBEDDINGS_API_KEY:-EMPTY}
            - RAG_HAYSTACK_EMBEDDINGS_MODEL=${RAG_HAYSTACK_EMBEDDINGS_MODEL:-MrLight/dse-qwen2-2b-mrl-v1}
            - RAG_HAYSTACK_EMBEDDINGS_DIM=${RAG_HAYSTACK_EMBEDDINGS_DIM:-1536}
            - RAG_HAYSTACK_EMBEDDINGS_MAX_TOKENS=${RAG_HAYSTACK_EMBEDDINGS_MAX_TOKENS:-32768}
            - RAG_HAYSTACK_CHUNK_SIZE=${RAG_HAYSTACK_CHUNK_SIZE:-500}
            - RAG_HAYSTACK_CHUNK_OVERLAP=${RAG_HAYSTACK_CHUNK_OVERLAP:-50}
            # Socket configuration for api communication
            - HELIX_EMBEDDINGS_SOCKET=/socket/embeddings.sock
            - RAG_VISION_EMBEDDINGS_SOCKET=/socket/embeddings.sock
            # Vision RAG Settings
            - RAG_VISION_ENABLED=${RAG_VISION_ENABLED:-true}
            - RAG_VISION_BASE_URL=${RAG_VISION_BASE_URL:-}
            - RAG_VISION_API_KEY=${RAG_VISION_API_KEY:-}
            - RAG_VISION_EMBEDDINGS_MODEL=${RAG_VISION_EMBEDDINGS_MODEL:-MrLight/dse-qwen2-2b-mrl-v1}
            - RAG_VISION_EMBEDDINGS_DIM=${RAG_VISION_EMBEDDINGS_DIM:-1536}
            - RAG_VISION_PGVECTOR_TABLE=${RAG_VISION_PGVECTOR_TABLE:-haystack_documents_vision}
        volumes:
            - ./haystack_service/app:/app/app
            - ./haystack_service/main.py:/app/main.py
            - helix-socket:/socket
        command:
            [
                "uvicorn",
                "main:app",
                "--host",
                "0.0.0.0",
                "--port",
                "8000",
                "--reload",
            ]
        depends_on:
            - pgvector
        extra_hosts:
            - "host.docker.internal:host-gateway"

    # Apache Guacamole for web-based RDP access
    guacamole:
        image: guacamole/guacd:1.5.4
        restart: always
        # ports:
        #   - 4822:4822





    guacamole-client:
        image: guacamole/guacamole:1.5.5
        restart: always
        ports:
            - ${GUACAMOLE_PORT:-8090}:8080
        environment:
            - GUACD_HOSTNAME=guacamole
            - GUACD_PORT=4822
            - POSTGRES_HOSTNAME=postgres
            - POSTGRES_PORT=5432
            - POSTGRES_DATABASE=guacamole_db
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
            - JAVA_OPTS=-Djava.awt.headless=true -Dcom.sun.management.jmxremote=false -XX:+UseContainerSupport -XX:+UnlockExperimentalVMOptions -XX:+UseCGroupMemoryLimitForHeap
        depends_on:
            - postgres
            - guacamole




volumes:
    helix-keycloak-db:
    helix-postgres-db:
    helix-pgvector-db:
    helix-filestore:
    helix-typesense-db:
    helix-socket:
    zed-work:

    go-pkg-mod: # Go module cache
    go-build-cache: # Go build cache
    go-sdk-cache: # Go toolchain/SDK cache
    # No persistent volumes for zed workspaces - using tmpfs for clean sessions

networks:
    default:
        name: helix_default
