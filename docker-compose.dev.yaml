# Common runner configuration (YAML anchor, not a service)
x-runner-config: &runner-config
    restart: always
    entrypoint: bash -c "cd /workspace/helix && go version && GOTOOLCHAIN=local go mod download && tail -f /dev/null"
    env_file:
        - .env
    environment:
        # Explicitly set Go cache paths for clarity
        - GOMODCACHE=/go/pkg/mod
        - GOCACHE=/root/.cache/go-build
        # Prevent automatic toolchain downloads
        - GOTOOLCHAIN=local
    volumes:
        - .:/workspace/helix
        - ~/.cache/huggingface:/root/.cache/huggingface
        # Go caches for faster development
        - go-pkg-mod:/go/pkg/mod
        - go-build-cache:/root/.cache/go-build
        - go-sdk-cache:/root/.cache/go
        # comment these out if you don't have appropriate repos checked out
        # - ../axolotl:/workspace/axolotl

services:
    api:
        build:
            context: .
            dockerfile: Dockerfile
            target: api-dev-env
        ports:
            - ${API_PORT:-8080}:8080
        restart: always
        env_file:
            - .env
        environment:
            - SERVER_PORT=8080
            - LOG_LEVEL=${LOG_LEVEL:-debug}
            - APP_URL=${SERVER_URL:-http://localhost:8080}
            - POSTGRES_HOST=postgres
            - POSTGRES_DATABASE=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
            - RUNNER_TOKEN=${RUNNER_TOKEN-oh-hallo-insecure-token}
            - SERVER_URL=${SERVER_URL:-http://localhost:8080}
            - KEYCLOAK_URL=http://keycloak:8080/auth
            - JANITOR_SLACK_WEBHOOK_URL=${JANITOR_SLACK_WEBHOOK_URL:-}
            - JANITOR_SLACK_IGNORE_USERS=${JANITOR_SLACK_IGNORE_USERS:-}
            - OPENAI_API_KEY=${OPENAI_API_KEY:-}
            - TOGETHER_API_KEY=${TOGETHER_API_KEY:-}
            - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
            - HF_TOKEN=${HF_TOKEN:-}
            - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY:-}
            - STRIPE_WEBHOOK_SIGNING_SECRET=${STRIPE_WEBHOOK_SIGNING_SECRET:-}
            - STRIPE_PRICE_LOOKUP_KEY=${STRIPE_PRICE_LOOKUP_KEY:-}
            - FRONTEND_URL=http://frontend:8081
            # this is an insecure development key do not use!
            - KEYCLOAK_USER=admin
            - KEYCLOAK_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD-oh-hallo-insecure-password}
            - KEYCLOAK_FRONTEND_URL=${KEYCLOAK_FRONTEND_URL:-http://localhost:8080/auth/}
            # lock down dashboard in production
            - ADMIN_USER_IDS=${ADMIN_USER_IDS-all}
            - EVAL_USER_ID=${EVAL_USER_ID:-}
            - FILESTORE_LOCALFS_PATH=/filestore
            - SENTRY_DSN_API=${SENTRY_DSN_API:-}
            - SENTRY_DSN_FRONTEND=${SENTRY_DSN_FRONTEND:-}
            - GOOGLE_ANALYTICS_FRONTEND=${GOOGLE_ANALYTICS_FRONTEND:-}
            # Tools configuration
            - TOOLS_ENABLED=true
            - TOOLS_PROVIDER=${TOOLS_PROVIDER:-helix}
            - TOOLS_MODEL=${TOOLS_MODEL:-llama3:instruct}
            # Email notifications
            - EMAIL_MAILGUN_DOMAIN=${EMAIL_MAILGUN_DOMAIN:-}
            - EMAIL_MAILGUN_API_KEY=${EMAIL_MAILGUN_API_KEY:-}
            # SMTP
            - EMAIL_SMTP_HOST=${EMAIL_SMTP_HOST:-}
            - EMAIL_SMTP_PORT=${EMAIL_SMTP_PORT:-}
            - EMAIL_SMTP_USERNAME=${EMAIL_SMTP_USERNAME:-}
            - EMAIL_SMTP_PASSWORD=${EMAIL_SMTP_PASSWORD:-}
            # Discord integration
            - DISCORD_BOT_TOKEN=${DISCORD_BOT_TOKEN:-}
            - ADMIN_USER_SOURCE=${ADMIN_USER_SOURCE:-}
            # Socket configuration for haystack communication
            - HELIX_EMBEDDINGS_SOCKET=/socket/embeddings.sock
            - RAG_HAYSTACK_ENABLED=true
            - RAG_DEFAULT_PROVIDER=${RAG_DEFAULT_PROVIDER:-haystack}
            # URL in the compose stack (rather than localhost in the pod which is default for k8s)
            - RAG_HAYSTACK_URL=http://haystack:8000
            - RAG_PGVECTOR_PROVIDER=helix
            # Dynamic providers: format is "provider1:api_key1:base_url1,provider2:api_key2:base_url2"
            - DYNAMIC_PROVIDERS=${DYNAMIC_PROVIDERS:-}
        volumes:
            - ./go.mod:/app/go.mod
            - ./go.sum:/app/go.sum
            - ./api:/app/api
            - ${FILESTORE_DATA:-helix-filestore}:/filestore
            - helix-socket:/socket
        depends_on:
            - postgres
            - keycloak
            - postgres-mcp
        extra_hosts:
            - "host.docker.internal:host-gateway"
    postgres:
        image: postgres:12.13-alpine
        restart: always
        # ports:
        #  - 5432:5432
        volumes:
            - ${POSTGRES_DATA:-helix-postgres-db}:/var/lib/postgresql/data
            - ./scripts/postgres:/docker-entrypoint-initdb.d
        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
            - POSTGRES_DATABASES=keycloak
    # docker run -p 8000:8000 \
    #   -e DATABASE_URI=postgresql://username:password@localhost:5432/dbname \
    #   crystaldba/postgres-mcp --access-mode=unrestricted --transport=sse
    postgres-mcp:
        image: crystaldba/postgres-mcp:latest
        restart: always
        command: ["--access-mode=unrestricted", "--transport=sse"]
        environment:
            - DATABASE_URI=postgresql://postgres:postgres@postgres:5432/postgres            
        ports:
        - 8000:8000
    # postgres 15 with pgvector installed
    # why run this as a different server?
    # because we want the quick path to something working without having to create a hard dependency on pgvector
    # being installed in our main database
    # also - we would need to migrate our existing postgres 12 DB -> 17, which is a bit of a pain
    # TODO: figure out how to ship the pgvector extension with our main database
    # so we don't need to run what is essentially 2 versions of postgres
    pgvector:
        image: ghcr.io/tensorchord/vchord_bm25-postgres:pg17-v0.1.1
        restart: always
        # ports:
        #  - 5433:5432
        volumes:
            - ${PGVECTOR_DATA:-helix-pgvector-db}:/var/lib/postgresql/data
        environment:
            - POSTGRES_DB=postgres
            - POSTGRES_USER=postgres
            - POSTGRES_PASSWORD=${PGVECTOR_PASSWORD-postgres}
    keycloak:
        image: quay.io/keycloak/keycloak:23.0
        restart: always
        environment:
            - KC_DB=postgres
            - KC_DB_URL=jdbc:postgresql://postgres:5432/keycloak
            - KC_DB_USERNAME=postgres
            - KC_DB_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
            - KEYCLOAK_ADMIN=admin
            - KEYCLOAK_ADMIN_PASSWORD=${KEYCLOAK_ADMIN_PASSWORD-oh-hallo-insecure-password}
            - KC_PROXY_HEADERS=forwarded|xforwarded
            - KC_HEALTH_ENABLED=true
            - KC_HOSTNAME_PATH=/auth
            - KC_HTTP_RELATIVE_PATH=/auth/
            - KC_HOSTNAME_URL=${KEYCLOAK_FRONTEND_URL:-http://localhost:8080/auth/}
            - KC_HOSTNAME_ADMIN_URL=${KEYCLOAK_FRONTEND_URL:-http://localhost:8080/auth/}
            # Theme development settings - disable caching
            - KC_SPI_THEME_CACHE_THEMES=false
            - KC_SPI_THEME_CACHE_TEMPLATES=false
            - KC_SPI_THEME_STATIC_MAX_AGE=-1
        volumes:
            # Mount themes directory for development
            - ./themes:/opt/keycloak/themes
        healthcheck:
            test:
                [
                    "CMD-SHELL",
                    "exec 3<>/dev/tcp/127.0.0.1/8080;echo -e \"GET /auth/health/ready HTTP/1.1\r\nhost: http://localhost\r\nConnection: close\r\n\r\n\" >&3;grep \"HTTP/1.1 200 OK\" <&3",
                ]
            interval: 5s
            timeout: 5s
            retries: 30
        command: ["start-dev"]
        # ports:
        #   - 30080:8080
    webhook_relay_stripe:
        image: webhookrelay/webhookrelayd
        environment:
            - KEY=${WEBHOOK_RELAY_KEY:-}
            - SECRET=${WEBHOOK_RELAY_SECRET:-}
            - BUCKET=${WEBHOOK_RELAY_BUCKET:-}
    tika:
        image: apache/tika:2.9.2.1
        # ports:
        #   - 9998:9998
    searxng:
        image: searxng/searxng:latest
        # ports:
        #   - 8112:8080
        volumes:
            - ./searxng/settings.yml:/etc/searxng/settings.yml
            - ./searxng/limiter.toml:/etc/searxng/limiter.toml
        environment:
            - BASE_URL=http://searxng:8080
            - INSTANCE_NAME=helix-instance
            - UWSGI_WORKERS=4
            - UWSGI_THREADS=4

    typense-ui:
        image: ghcr.io/bfritscher/typesense-dashboard:latest
        # ports:
        #   - 8877:80
        volumes:
            - ./scripts/config.json:/srv/config.json
        depends_on:
            - typesense
    typesense:
        build:
            context: .
            dockerfile: Dockerfile.typesense
        command: ["--data-dir", "/data", "--api-key", "typesense"]
        # ports:
        #   - 8108:8108
        volumes:
            - ${TYPESENSE_DATA:-helix-typesense-db}:/data
    chrome:
        image: ghcr.io/go-rod/rod:v0.115.0
        restart: always
        volumes:
            - ./integration-test/data/smoke:/integration-test/data/smoke
        # ports:
        #   - 7317:7317
    gptscript_runner:
        build:
            context: .
            dockerfile: Dockerfile.gptscript
        restart: always
        environment:
            - OPENAI_API_KEY=${OPENAI_API_KEY:-}
            - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
            - API_HOST=http://api:8080
            - API_TOKEN=${RUNNER_TOKEN-oh-hallo-insecure-token}
            - GPTSCRIPT_PROVIDER_API_API_KEY=${RUNNER_TOKEN:-}
            - CONCURRENCY=20 # number of tasks to run concurrently
            - MAX_TASKS=0 # max number of tasks to run before exiting. Set to 0 to run forever
        depends_on:
            - api

    # Base runner without GPU, fakes GPU by using CPU memory
    runner:
        <<: *runner-config
        profiles: ["runner"]
        build:
            context: .
            dockerfile: Dockerfile.runner
            args:
                TAG: 2025-08-13c-small
                # Builds vllm in CPU-only mode per https://github.com/vllm-project/vllm/discussions/8090
                DEVELOPMENT_CPU_ONLY: "true"
        environment:
            # Passes cpu-only flags to vllm
            - DEVELOPMENT_CPU_ONLY=true
            # Prevent toolchain downloads
            - GOTOOLCHAIN=local
            # Force vLLM to use CPU
            - VLLM_DEVICE=cpu
            - VLLM_LOGGING_LEVEL=DEBUG

    # GPU-enabled runner
    runner_gpu:
        <<: *runner-config
        profiles: ["runner_gpu"]
        build:
            context: .
            dockerfile: Dockerfile.runner
            args:
                TAG: 2025-08-13c-large
        environment:
            # Prevent toolchain downloads
            - GOTOOLCHAIN=local
        deploy:
            resources:
                reservations:
                    devices:
                        - driver: nvidia
                          count: all
                          capabilities: [gpu]

    demos:
        profiles: ["demos"]
        build:
            context: .
            dockerfile: Dockerfile.demos
        ports:
            - ${DEMOS_PORT:-8085}:8085
        restart: always
        env_file:
            - .env
        environment:
            - PORT=8085
        entrypoint: ${DEMOS_ENTRYPOINT:-tail -f /dev/null}
        volumes:
            - ./go.mod:/app/go.mod
            - ./go.sum:/app/go.sum
            - ./demos:/app/demos

    frontend:
        # ports:
        #   - 8081:${FRONTEND_INTERNAL_PORT:-8081}
        build:
            context: .
            dockerfile: Dockerfile
            target: ui-dev-env
        restart: always
        volumes:
            - ./frontend/package.json:/app/package.json
            - ./frontend/src:/app/src
            - ./frontend/assets:/app/assets
            - ./frontend/index.html:/app/index.html
            - ./frontend/tsconfig.json:/app/tsconfig.json
            - ./frontend/vite.config.ts:/app/vite.config.ts

    haystack:
        build:
            context: ./haystack_service
        # ports:
        #   - 8001:8000
        restart: always
        environment:
            - PGVECTOR_DSN=postgresql://postgres:postgres@pgvector:5432/postgres
            - LOG_LEVEL=INFO
            - VLLM_BASE_URL=${RAG_HAYSTACK_EMBEDDINGS_BASE_URL} # Need to set this to an external VLLM server in development
            - VLLM_API_KEY=${RAG_HAYSTACK_EMBEDDINGS_API_KEY:-EMPTY}
            - RAG_HAYSTACK_EMBEDDINGS_MODEL=${RAG_HAYSTACK_EMBEDDINGS_MODEL:-MrLight/dse-qwen2-2b-mrl-v1}
            - RAG_HAYSTACK_EMBEDDINGS_DIM=${RAG_HAYSTACK_EMBEDDINGS_DIM:-1536}
            - RAG_HAYSTACK_EMBEDDINGS_MAX_TOKENS=${RAG_HAYSTACK_EMBEDDINGS_MAX_TOKENS:-32768}
            - RAG_HAYSTACK_CHUNK_SIZE=${RAG_HAYSTACK_CHUNK_SIZE:-500}
            - RAG_HAYSTACK_CHUNK_OVERLAP=${RAG_HAYSTACK_CHUNK_OVERLAP:-50}
            # Socket configuration for api communication
            - HELIX_EMBEDDINGS_SOCKET=/socket/embeddings.sock
            - RAG_VISION_EMBEDDINGS_SOCKET=/socket/embeddings.sock
            # Vision RAG Settings
            - RAG_VISION_ENABLED=${RAG_VISION_ENABLED:-true}
            - RAG_VISION_BASE_URL=${RAG_VISION_BASE_URL:-}
            - RAG_VISION_API_KEY=${RAG_VISION_API_KEY:-}
            - RAG_VISION_EMBEDDINGS_MODEL=${RAG_VISION_EMBEDDINGS_MODEL:-MrLight/dse-qwen2-2b-mrl-v1}
            - RAG_VISION_EMBEDDINGS_DIM=${RAG_VISION_EMBEDDINGS_DIM:-1536}
            - RAG_VISION_PGVECTOR_TABLE=${RAG_VISION_PGVECTOR_TABLE:-haystack_documents_vision}
        volumes:
            - ./haystack_service/app:/app/app
            - ./haystack_service/main.py:/app/main.py
            - helix-socket:/socket
        command:
            [
                "uvicorn",
                "main:app",
                "--host",
                "0.0.0.0",
                "--port",
                "8000",
                "--reload",
            ]
        depends_on:
            - pgvector
        extra_hosts:
            - "host.docker.internal:host-gateway"

volumes:
    helix-keycloak-db:
    helix-postgres-db:
    helix-pgvector-db:
    helix-filestore:
    helix-typesense-db:
    helix-socket:
    go-pkg-mod: # Go module cache
    go-build-cache: # Go build cache
    go-sdk-cache: # Go toolchain/SDK cache

networks:
    default:
        name: helix_default
