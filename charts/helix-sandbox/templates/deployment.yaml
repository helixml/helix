{{- if or (not .Values.deployment) (eq (default "Deployment" .Values.deployment.type) "Deployment") }}
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include "helix-sandbox.fullname" . }}
  labels:
    {{- include "helix-sandbox.labels" . | nindent 4 }}
spec:
  replicas: {{ .Values.replicaCount }}
  {{- if and .Values.deployment .Values.deployment.strategy }}
  strategy:
    type: {{ .Values.deployment.strategy.type | default "Recreate" }}
    {{- if eq .Values.deployment.strategy.type "RollingUpdate" }}
    rollingUpdate:
      maxSurge: {{ .Values.deployment.strategy.rollingUpdate.maxSurge | default "25%" }}
      maxUnavailable: {{ .Values.deployment.strategy.rollingUpdate.maxUnavailable | default "25%" }}
    {{- end }}
  {{- else }}
  strategy:
    type: Recreate
  {{- end }}
  selector:
    matchLabels:
      {{- include "helix-sandbox.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "helix-sandbox.labels" . | nindent 8 }}
        {{- with .Values.podLabels }}
        {{- toYaml . | nindent 8 }}
        {{- end }}
    spec:
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "helix-sandbox.serviceAccountName" . }}
      {{- if .Values.podSecurityContext }}
      securityContext:
        {{- toYaml .Values.podSecurityContext | nindent 8 }}
      {{- end }}
      {{- $gpuVendor := include "helix-sandbox.gpuVendor" . }}
      {{- $runtimeClass := include "helix-sandbox.runtimeClassName" . }}
      {{- if $runtimeClass }}
      runtimeClassName: {{ $runtimeClass }}
      {{- end }}
      containers:
        - name: {{ .Chart.Name }}
          securityContext:
            {{- toYaml .Values.securityContext | nindent 12 }}
          image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
          imagePullPolicy: {{ .Values.image.pullPolicy }}
          {{- if and .Values.gpu .Values.gpu.nvidia .Values.gpu.nvidia.gkeSetup }}
          # GKE NVIDIA setup: configure library paths and cgroups for nested GPU containers
          command: ["/bin/bash", "-c"]
          args:
            - |
              if [ -d "/usr/local/nvidia/lib64" ]; then
                echo "/usr/local/nvidia/lib64" > /etc/ld.so.conf.d/nvidia-gke.conf
                ldconfig
                sed -i 's/#no-cgroups = false/no-cgroups = true/' /etc/nvidia-container-runtime/config.toml 2>/dev/null || true
              fi
              exec /entrypoint.sh
          {{- end }}
          env:
            # =====================================================
            # Core Helix configuration
            # =====================================================
            - name: HELIX_API_URL
              value: {{ .Values.sandbox.apiUrl | quote }}
            - name: HELIX_API_BASE_URL
              value: {{ .Values.sandbox.apiUrl | quote }}
            - name: RUNNER_TOKEN
              {{- if .Values.sandbox.runnerTokenExistingSecret }}
              valueFrom:
                secretKeyRef:
                  name: {{ .Values.sandbox.runnerTokenExistingSecret }}
                  key: {{ .Values.sandbox.runnerTokenExistingSecretKey | default "token" }}
              {{- else }}
              value: {{ .Values.sandbox.runnerToken | quote }}
              {{- end }}
            - name: SANDBOX_INSTANCE_ID
              {{- if .Values.sandbox.instanceId }}
              value: {{ .Values.sandbox.instanceId | quote }}
              {{- else }}
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
              {{- end }}
            - name: MAX_SANDBOXES
              value: {{ .Values.sandbox.maxSandboxes | quote }}

            # Helix hostname for display
            - name: HELIX_HOSTNAME
              {{- if .Values.sandbox.helixHostname }}
              value: {{ .Values.sandbox.helixHostname | quote }}
              {{- else }}
              value: {{ .Values.sandbox.apiUrl | trimPrefix "https://" | trimPrefix "http://" | regexFind "^[^:/]+" | quote }}
              {{- end }}

            # Video encoding configuration
            - name: GOP_SIZE
              value: {{ .Values.sandbox.gopSize | quote }}

            # =====================================================
            # Hydra configuration (multi-tenant isolation)
            # =====================================================
            - name: HYDRA_ENABLED
              value: {{ .Values.hydra.enabled | quote }}
            - name: HYDRA_PRIVILEGED_MODE_ENABLED
              value: {{ .Values.hydra.privilegedMode | quote }}

            # =====================================================
            # Desktop image configuration
            # =====================================================
            {{- if .Values.desktopImages.imageOverride }}
            - name: ZED_IMAGE
              value: {{ .Values.desktopImages.imageOverride | quote }}
            {{- else }}
            - name: ZED_IMAGE
              value: "{{ .Values.desktopImages.registry }}/helix/{{ .Values.desktopImages.default }}:{{ .Values.desktopImages.tag }}"
            {{- end }}
            - name: HELIX_SANDBOX_REGISTRY
              value: {{ .Values.desktopImages.registry | quote }}

            # =====================================================
            # GPU vendor configuration
            # =====================================================
            - name: GPU_VENDOR
              value: {{ $gpuVendor | quote }}

            {{- if eq $gpuVendor "nvidia" }}
            # NVIDIA-specific environment
            - name: NVIDIA_DRIVER_CAPABILITIES
              value: "all"
            - name: NVIDIA_VISIBLE_DEVICES
              value: "all"
            # GKE/Cloud: NVIDIA libraries are at /usr/local/nvidia/lib64
            # This path is harmless if it doesn't exist on other systems
            - name: LD_LIBRARY_PATH
              value: "/usr/local/nvidia/lib64"
            {{- else if eq $gpuVendor "none" }}
            # Software rendering environment (no GPU)
            - name: LIBGL_ALWAYS_SOFTWARE
              value: "1"
            - name: MESA_GL_VERSION_OVERRIDE
              value: "4.5"
            {{- end }}

            # =====================================================
            # Runtime configuration
            # =====================================================
            - name: HELIX_DEV_MODE
              value: "false"
            - name: XDG_RUNTIME_DIR
              value: "/tmp/sockets"
            - name: SANDBOX_DATA_PATH
              value: "/data"

            # =====================================================
            # Debugging options
            # =====================================================
            - name: HELIX_KEEP_DEAD_CONTAINERS
              value: {{ .Values.debug.keepDeadContainers | quote }}
            - name: GST_DEBUG
              value: {{ .Values.debug.gstDebug | quote }}

          volumeMounts:
            - name: docker-storage
              mountPath: /var/lib/docker
            - name: hydra-data
              mountPath: /hydra-data
            - name: workspace-data
              mountPath: /data
            - name: tmp-sockets
              mountPath: /tmp/sockets
            - name: hydra-socket
              mountPath: /var/run/hydra
            {{- if not .Values.testing.disableHostPaths }}
            - name: udev
              mountPath: /run/udev
              readOnly: true
            {{- end }}
            {{- if ne $gpuVendor "none" }}
            # GPU modes need /dev mounted for DRI access
            - name: dev
              mountPath: /dev
            {{- end }}

          resources:
            {{- $resources := dict }}
            {{- if .Values.resources.limits }}
            {{- $resources = merge $resources (dict "limits" .Values.resources.limits) }}
            {{- end }}
            {{- if .Values.resources.requests }}
            {{- $resources = merge $resources (dict "requests" .Values.resources.requests) }}
            {{- end }}
            {{- /* Add GPU resources based on vendor */ -}}
            {{- if eq $gpuVendor "nvidia" }}
            {{- if .Values.gpu.nvidia.enabled }}
            {{- $gpuLimit := dict "nvidia.com/gpu" (.Values.gpu.nvidia.count | default 1) }}
            {{- if $resources.limits }}
            {{- $resources = merge $resources (dict "limits" (merge $resources.limits $gpuLimit)) }}
            {{- else }}
            {{- $resources = merge $resources (dict "limits" $gpuLimit) }}
            {{- end }}
            {{- end }}
            {{- else if eq $gpuVendor "amd" }}
            {{- if and .Values.gpu.amd.enabled .Values.gpu.amd.resourceName }}
            {{- $gpuLimit := dict .Values.gpu.amd.resourceName 1 }}
            {{- if $resources.limits }}
            {{- $resources = merge $resources (dict "limits" (merge $resources.limits $gpuLimit)) }}
            {{- else }}
            {{- $resources = merge $resources (dict "limits" $gpuLimit) }}
            {{- end }}
            {{- end }}
            {{- else if eq $gpuVendor "intel" }}
            {{- if and .Values.gpu.intel.enabled .Values.gpu.intel.resourceName }}
            {{- $gpuLimit := dict .Values.gpu.intel.resourceName 1 }}
            {{- if $resources.limits }}
            {{- $resources = merge $resources (dict "limits" (merge $resources.limits $gpuLimit)) }}
            {{- else }}
            {{- $resources = merge $resources (dict "limits" $gpuLimit) }}
            {{- end }}
            {{- end }}
            {{- end }}
            {{- toYaml $resources | nindent 12 }}

          # Health check: verify nested dockerd is running
          # The sandbox doesn't expose ports (uses RevDial for outbound connection)
          livenessProbe:
            exec:
              command:
                - docker
                - info
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3

          readinessProbe:
            exec:
              command:
                - docker
                - info
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 3

      volumes:
        - name: docker-storage
          {{- if .Values.persistence.dockerStorage.enabled }}
          persistentVolumeClaim:
            claimName: {{ include "helix-sandbox.fullname" . }}-docker
          {{- else }}
          emptyDir: {}
          {{- end }}
        - name: hydra-data
          {{- if .Values.persistence.hydraData.enabled }}
          persistentVolumeClaim:
            claimName: {{ include "helix-sandbox.fullname" . }}-hydra
          {{- else }}
          emptyDir: {}
          {{- end }}
        - name: workspace-data
          {{- if .Values.persistence.workspaceData.enabled }}
          persistentVolumeClaim:
            claimName: {{ include "helix-sandbox.fullname" . }}-workspace
          {{- else }}
          emptyDir: {}
          {{- end }}
        - name: tmp-sockets
          emptyDir: {}
        - name: hydra-socket
          emptyDir: {}
        {{- if not .Values.testing.disableHostPaths }}
        - name: udev
          hostPath:
            path: /run/udev
            type: Directory
        {{- end }}
        {{- if ne $gpuVendor "none" }}
        - name: dev
          hostPath:
            path: /dev
            type: Directory
        {{- end }}

      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
{{- end }}
