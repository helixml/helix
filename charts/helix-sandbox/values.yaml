# Default values for helix-sandbox.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: registry.helixml.tech/helix/helix-sandbox
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

# Sandbox configuration
sandbox:
  # Helix control plane URL (required)
  # Example: https://helix.mycompany.com
  apiUrl: ""

  # Runner token for authentication (required)
  # Can be specified directly or read from a Kubernetes secret
  runnerToken: ""
  # Alternative: read token from a Kubernetes secret
  runnerTokenExistingSecret: ""
  runnerTokenExistingSecretKey: ""  # defaults to "token" if not specified

  # Sandbox instance ID (defaults to pod name)
  # Leave empty to use pod name as instance ID
  instanceId: ""

  # Maximum number of concurrent sessions (desktop containers)
  maxSandboxes: 10

  # Helix hostname displayed in browser
  helixHostname: ""

  # GOP size (keyframe interval) for video encoding
  # Higher = lower bandwidth, lower = better latency
  # 120-240 recommended for remote connections
  gopSize: 120

# Hydra configuration (multi-tenant container isolation)
hydra:
  # Enable Hydra for per-session Docker daemon isolation
  # When enabled, each session gets its own isolated dockerd
  enabled: true

  # Privileged mode uses host Docker socket instead of isolated dockerd
  # WARNING: Only for development - disables tenant isolation
  privilegedMode: false

# Desktop images configuration
# The sandbox pulls desktop images from a registry at runtime
desktopImages:
  # Registry to pull desktop images from
  # Default uses Helix public registry
  # For enterprise/air-gapped: set to your internal registry
  registry: "registry.helixml.tech"

  # Default desktop image to use
  # Options: helix-sway (Sway compositor), helix-ubuntu (GNOME)
  default: "helix-sway"

  # Image tag (version)
  # Use "latest" or specific version tag
  tag: "latest"

  # Full image reference override (optional)
  # If set, overrides registry/default/tag settings
  # Example: "my-registry.com/custom/desktop:v1.2.3"
  imageOverride: ""

# GPU configuration
# Supported vendors: "nvidia", "amd", "intel", "none"
# "none" enables software rendering (CPU-only, no GPU required)
gpu:
  # GPU vendor: nvidia, amd, intel, none
  vendor: "nvidia"

  # NVIDIA-specific configuration
  nvidia:
    # Enable NVIDIA runtime (required for NVIDIA GPUs)
    enabled: true
    # Number of GPUs to allocate (0 = all available)
    count: 1
    # Runtime class name for OpenShift/Kubernetes
    # OpenShift typically uses "nvidia" or custom runtime class
    runtimeClassName: ""

  # AMD-specific configuration
  amd:
    # Enable AMD GPU support
    enabled: false
    # Device paths to mount (typically /dev/kfd and /dev/dri)
    devices:
      - /dev/kfd
      - /dev/dri
    # Runtime class for AMD GPUs (if using ROCR device plugin)
    runtimeClassName: ""
    # GPU resource name for Kubernetes device plugin
    # Common value: "amd.com/gpu"
    # Leave empty to not request AMD GPU resources (relies on device mounts)
    resourceName: "amd.com/gpu"

  # Intel-specific configuration
  intel:
    # Enable Intel GPU support
    enabled: false
    # Device path (typically /dev/dri)
    devices:
      - /dev/dri
    # Runtime class for Intel GPUs
    runtimeClassName: ""
    # GPU resource name for Kubernetes device plugin
    # Common values: "gpu.intel.com/i915" (most common), "gpu.intel.com/xe" (newer Intel Arc GPUs)
    # Default to i915 as it covers most Intel GPUs (Iris, UHD, Xe integrated, data center Flex)
    resourceName: "gpu.intel.com/i915"

  # Software rendering configuration (no GPU)
  software:
    # Enabled when gpu.vendor is "none"
    # Uses Mesa llvmpipe for rendering
    # Note: Performance will be limited without hardware acceleration
    enabled: false

# Resource limits and requests
resources:
  limits:
    memory: "16Gi"
  requests:
    memory: "4Gi"
    cpu: "2"

# Service account configuration
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}
podLabels: {}

# Pod security context
# The sandbox requires privileged mode for Docker-in-Docker
podSecurityContext: {}

# Container security context
# Sandbox requires privileged for DinD and device access
securityContext:
  privileged: true

# Service configuration
# Note: The sandbox uses RevDial (outbound connection to control plane)
# A service is only needed if you want to expose metrics or health endpoints
service:
  # Set to false to disable service creation (sandbox uses RevDial)
  enabled: false
  type: ClusterIP
  annotations: {}

# Persistence for sandbox Docker storage
persistence:
  # Docker storage for sandbox's nested dockerd
  dockerStorage:
    enabled: true
    size: 50Gi
    storageClassName: ""
    accessModes:
      - ReadWriteOnce

  # Hydra data storage (per-session dockerd data)
  # IMPORTANT: Must be a real volume, not overlay filesystem
  # Docker overlay2 cannot mount on top of overlay
  hydraData:
    enabled: true
    size: 20Gi
    storageClassName: ""
    accessModes:
      - ReadWriteOnce

  # Workspace data storage (user session data)
  workspaceData:
    enabled: true
    size: 100Gi
    storageClassName: ""
    accessModes:
      - ReadWriteOnce

# Debugging options
debug:
  # Keep dead containers for inspection (don't auto-remove)
  keepDeadContainers: false

  # GStreamer debug level (0-9, higher = more verbose)
  gstDebug: "2"

# Node selector for GPU nodes
nodeSelector: {}
# Example for NVIDIA GPU nodes:
# nvidia.com/gpu.present: "true"
# Example for AMD GPU nodes:
# amd.com/gpu: "true"

# Tolerations for GPU nodes
tolerations: []
# Example for NVIDIA GPU taints:
# - key: nvidia.com/gpu
#   operator: Exists
#   effect: NoSchedule

# Affinity rules
affinity: {}

# OpenShift-specific configuration
openshift:
  # Enable OpenShift-specific settings
  enabled: false
  # Security Context Constraints (SCC)
  # The sandbox requires privileged SCC for DinD
  scc:
    # Create a custom SCC for the sandbox
    create: true
    # Name of existing SCC to use (if create is false)
    existingName: ""
  # Route configuration (alternative to LoadBalancer)
  route:
    enabled: false
    annotations: {}
    host: ""
    tls:
      enabled: true
      termination: passthrough
