kind: pipeline
type: docker
name: default

workspace:
  base: /go
  path: src/github.com/helix-ml/helix

steps:
- name: build-backend
  image: golang:1.22.2-alpine3.19
  commands:
    - go build -o helix

- name: unit-test
  image: golang:1.22.2-alpine3.19
  environment:
    OPENAI_API_KEY:
      from_secret: openai_tools
    TOGETHER_API_KEY:
      from_secret: openai_api_key
    TOGETHER_BASE_URL:
      from_secret: openai_base_url
    # Database config (running in a sidecar)
    POSTGRES_HOST: postgres
  commands:
    - go test -v ./...

- name: build-frontend
  image: node:21-alpine
  commands:
    - cd frontend
    - yarn install
    - yarn build


services:
- name: postgres
  image: postgres:12.13-alpine
  environment:
    POSTGRES_USER: postgres
    POSTGRES_PASSWORD: postgres
    POSTGRES_DB: postgres

---
kind: pipeline
type: docker
name: build-controlplane

volumes:
  - name: dockersocket
    host:
      path: /var/run/docker.sock

steps:
- name: publish-image
  image: plugins/gar
  pull: always
  settings:
    dockerfile: Dockerfile
    auto_tag: true
    repo: helixml/helix/controlplane
    location: europe
    json_key:
      from_secret: gar_json_key_b64
  volumes:
  - name: dockersocket
    path: /var/run/docker.sock
  when:
    branch:
    - main
    event:
    - tag
    - push

depends_on:
- default

---
kind: pipeline
type: docker
name: build-runner

volumes:
  - name: dockersocket
    host:
      path: /var/run/docker.sock

steps:
- name: publish-runner
  image: plugins/gar
  pull: always
  settings:
    dockerfile: Dockerfile.runner
    auto_tag: true
    repo: helixml/helix/runner
    location: europe
    json_key:
      from_secret: gar_json_key_b64
  volumes:
  - name: dockersocket
    path: /var/run/docker.sock
  when:
    branch:
    - main
    event:
    - tag
    - push

depends_on:
- default

---
kind: pipeline
type: docker
name: build-gptscript-runner

volumes:
  - name: dockersocket
    host:
      path: /var/run/docker.sock

steps:
- name: publish-image
  image: plugins/gar
  pull: always
  settings:
    dockerfile: Dockerfile.gptscript
    auto_tag: true
    repo: helixml/helix/gptscript-runner
    location: europe
    json_key:
      from_secret: gar_json_key_b64
  volumes:
  - name: dockersocket
    path: /var/run/docker.sock
  when:
    branch:
    - main
    event:
    - tag
    - push

depends_on:
- default

---
kind: pipeline
type: docker
name: build-runner-with-llama-8b

volumes:
  - name: dockersocket
    host:
      path: /var/run/docker.sock

steps:
- name: publish-runner
  image: plugins/gar
  pull: always
  settings:
    dockerfile: Dockerfile.runner
    tags:
    - "${DRONE_TAG:-main}-small" # Default to branch
    - "latest-small"
    repo: helixml/helix/runner
    location: europe
    build_args:
      # Small models only
      - PULL_OLLAMA_MODELS=llama3:instruct;phi3:instruct
    json_key:
      from_secret: gar_json_key_b64
  volumes:
  - name: dockersocket
    path: /var/run/docker.sock
  when:
    branch:
    - main
    event:
    - tag
    - push

depends_on:
- default
- build-runner

# llama3 70B + the whole cake
---
kind: pipeline
type: docker
name: build-runner-with-llama-70b

volumes:
  - name: dockersocket
    host:
      path: /var/run/docker.sock

steps:
- name: publish-runner
  image: plugins/gar
  pull: always
  settings:
    dockerfile: Dockerfile.runner
    tags:
    - "${DRONE_TAG:-main}-large"
    - "latest-large"
    repo: helixml/helix/runner
    location: europe
    build_args:
      # Small and big models
      - PULL_OLLAMA_MODELS=llama3:instruct;llama3:70b;mixtral:instruct;adrienbrault/nous-hermes2theta-llama3-8b:q8_0;phi3:instruct
    json_key:
      from_secret: gar_json_key_b64
  volumes:
  - name: dockersocket
    path: /var/run/docker.sock
  when:
    branch:
    - main
    event:
    - tag
    - push

depends_on:
- default
- build-runner-with-llama-8b

---
kind: pipeline
type: docker
name: build-gptscript_devserver

volumes:
  - name: dockersocket
    host:
      path: /var/run/docker.sock

steps:
- name: publish-gptscript_devserver
  image: plugins/gar
  pull: always
  settings:
    dockerfile: Dockerfile.gptscript_devserver
    auto_tag: true
    repo: helixml/helix/gptscript_devserver
    location: europe
    json_key:
      from_secret: gar_json_key_b64
  volumes:
  - name: dockersocket
    path: /var/run/docker.sock
  when:
    branch:
    - main
    event:
    - tag
    - push

depends_on:
- default

---
kind: pipeline
type: docker
name: build-llamaindex

volumes:
  - name: dockersocket
    host:
      path: /var/run/docker.sock

steps:
- name: publish-llamaindex
  image: plugins/gar
  pull: always
  settings:
    dockerfile: llamaindex/Dockerfile
    context: llamaindex
    auto_tag: true
    repo: helixml/helix/llamaindex
    location: europe
    json_key:
      from_secret: gar_json_key_b64
  volumes:
  - name: dockersocket
    path: /var/run/docker.sock
  when:
    branch:
    - main
    event:
    - tag
    - push

depends_on:
- default

---
kind: pipeline
type: docker
name: build-demos

volumes:
  - name: dockersocket
    host:
      path: /var/run/docker.sock

steps:
- name: publish-demos
  image: plugins/gar
  pull: always
  settings:
    dockerfile: Dockerfile.demos
    auto_tag: true
    repo: helixml/helix/demos
    location: europe
    json_key:
      from_secret: gar_json_key_b64
  volumes:
  - name: dockersocket
    path: /var/run/docker.sock
  when:
    branch:
    - main
    event:
    - tag
    - push

depends_on:
- default
