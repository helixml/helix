# Production docker-compose.yaml for HelixML :latest
# See https://docs.helixml.tech/helix/private-deployment/controlplane/

services:
  api:
    image: registry.helixml.tech/helix/controlplane:latest
    # If you want to run the API on a different port, set the
    # API_PORT environment variable and also updated env variables
    # connect to Helix
    ports:
      - ${API_PORT:-8080}:8080
      - "3478:3478/udp"  # TURN server for WebRTC (Helix Code)
      - "3478:3478/tcp"  # TURN server TCP transport (firewall fallback)
    restart: always
    env_file:
      - .env
    environment:
      - LOG_LEVEL=${LOG_LEVEL:-info}
      - SERVER_PORT=8080
      - APP_URL=${SERVER_URL:-http://localhost:8080}
      - POSTGRES_HOST=postgres
      - POSTGRES_DATABASE=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
      - TOGETHER_API_KEY=${TOGETHER_API_KEY:-}
      - RUNNER_TOKEN=${RUNNER_TOKEN-oh-hallo-insecure-token}
      - SERVER_URL=${SERVER_URL:-http://localhost:8080}
      # lock down dashboard in production
      - ADMIN_USER_IDS=${ADMIN_USER_IDS-all}
      - ADMIN_USER_SOURCE=${ADMIN_USER_SOURCE-env}
      - EVAL_USER_ID=${EVAL_USER_ID:-}
      - FILESTORE_LOCALFS_PATH=/filestore
      - RAG_DEFAULT_PROVIDER=${RAG_DEFAULT_PROVIDER:-typesense}
      # name of the helix llm provider to use for embeddings socket
      - RAG_PGVECTOR_PROVIDER=${RAG_PGVECTOR_PROVIDER:-helix}
      # Socket configuration for haystack communication
      - HELIX_EMBEDDINGS_SOCKET=/socket/embeddings.sock
      - RAG_HAYSTACK_ENABLED=${RAG_HAYSTACK_ENABLED:-false}
      - RAG_HAYSTACK_URL=http://haystack:8000
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - HF_TOKEN=${HF_TOKEN:-}
      # Dynamic providers: format is "provider1:api_key1:base_url1,provider2:api_key2:base_url2"
      # Only creates providers that don't already exist (won't overwrite existing ones)
      # Example: DYNAMIC_PROVIDERS=groq:gsk_xxxx:https://api.groq.com/openai/v1,cerebras:csk_xxxx:https://api.cerebras.ai/v1
      - DYNAMIC_PROVIDERS=${DYNAMIC_PROVIDERS:-}
      # Wolf integration for Helix Code (External Agents / PDEs)
      - WOLF_SOCKET_PATH=/var/run/wolf/wolf.sock
      - WOLF_MODE=${WOLF_MODE:-lobbies}  # "lobbies" (default, multi-user with PIN support) or "apps" (legacy)
      - EXTERNAL_AGENTS_MAX_CONCURRENT_LOBBIES=${EXTERNAL_AGENTS_MAX_CONCURRENT_LOBBIES:-10}
      - ZED_IMAGE=${ZED_IMAGE:-registry.helixml.tech/helix/zed-agent:latest}
      - HELIX_HOST_HOME=${HELIX_HOST_HOME:-}
      # Hydra multi-Docker isolation (per-scope dockerd for each agent session)
      - HYDRA_ENABLED=${HYDRA_ENABLED:-true}
      # Moonlight Web credentials (must match moonlight-web config.json)
      - MOONLIGHT_CREDENTIALS=${MOONLIGHT_CREDENTIALS:-helix}
      # TURN server configuration for WebRTC (Helix Code)
      - TURN_ENABLED=${TURN_ENABLED:-true}
      - TURN_PUBLIC_IP=${TURN_PUBLIC_IP:-}
      - TURN_PORT=${TURN_PORT:-3478}
      - TURN_REALM=${TURN_REALM:-helix.ai}
      - TURN_USERNAME=${TURN_USERNAME:-helix}
      - TURN_PASSWORD=${TURN_PASSWORD:-}
    volumes:
      - ${FILESTORE_DATA:-helix-filestore}:/filestore
      - helix-socket:/socket
      # Bind-mount from host (Wolf creates socket here) - only needed for sandbox profiles
      - /var/run/wolf:/var/run/wolf:rw
    depends_on:
      - postgres
    extra_hosts:
      - "host.docker.internal:host-gateway"
  postgres:
    image: postgres:12.13-alpine
    restart: always
    # ports:
    #   - 5432:5432
    volumes:
      - ${POSTGRES_DATA:-helix-postgres-db}:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${POSTGRES_ADMIN_PASSWORD-postgres}
  # postgres 15 with pgvector installed for vector database
  pgvector:
    profiles: [haystack]
    image: ghcr.io/tensorchord/vchord_bm25-postgres:pg17-v0.1.1
    restart: always
    # ports:
    #   - 5433:5432
    volumes:
      - ${PGVECTOR_DATA:-helix-pgvector-db}:/var/lib/postgresql/data
    environment:
      - POSTGRES_DB=postgres
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=${PGVECTOR_PASSWORD-pgvector}
  tika:
    image: apache/tika:2.9.2.1
    restart: always
    # ports:
    #   - 9998:9998
  searxng:
    image: searxng/searxng:2025.7.24-84c3a83
    # ports:
    #   - 8112:8080
    volumes:
      - ./searxng/settings.yml:/etc/searxng/settings.yml
      - ./searxng/limiter.toml:/etc/searxng/limiter.toml
    environment:
      - BASE_URL=http://searxng:8080
      - INSTANCE_NAME=helix-instance
      - UWSGI_WORKERS=4
      - UWSGI_THREADS=4
  typesense:
    image: registry.helixml.tech/helix/typesense:latest
    restart: always
    command: ["--data-dir", "/data", "--api-key", "typesense"]
    # ports:
    #   - 8108:8108
    volumes:
      - ${TYPESENSE_DATA:-helix-typesense-db}:/data
  chrome:
    image: ghcr.io/go-rod/rod:v0.115.0
    restart: always
    volumes:
      - ./integration-test/data/smoke:/integration-test/data/smoke
    # ports:
    #   - 7317:7317
  haystack:
    profiles: [haystack]
    image: registry.helixml.tech/helix/haystack:latest
    restart: always
    environment:
      - PGVECTOR_DSN=postgresql://postgres:${PGVECTOR_PASSWORD-pgvector}@pgvector:5432/postgres
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - VLLM_BASE_URL=${RAG_HAYSTACK_EMBEDDINGS_BASE_URL:-}
      - VLLM_API_KEY=${RAG_HAYSTACK_EMBEDDINGS_API_KEY:-EMPTY}
      - RAG_HAYSTACK_EMBEDDINGS_MODEL=${RAG_HAYSTACK_EMBEDDINGS_MODEL:-MrLight/dse-qwen2-2b-mrl-v1}
      - RAG_HAYSTACK_EMBEDDINGS_DIM=${RAG_HAYSTACK_EMBEDDINGS_DIM:-1536}
      - RAG_HAYSTACK_EMBEDDINGS_MAX_TOKENS=${RAG_HAYSTACK_EMBEDDINGS_MAX_TOKENS:-32768}
      - RAG_HAYSTACK_CHUNK_SIZE=${RAG_HAYSTACK_CHUNK_SIZE:-1000}
      - RAG_HAYSTACK_CHUNK_OVERLAP=${RAG_HAYSTACK_CHUNK_OVERLAP:-50}
      # Socket configuration for api communication
      - HELIX_EMBEDDINGS_SOCKET=/socket/embeddings.sock
      - RAG_VISION_EMBEDDINGS_SOCKET=/socket/embeddings.sock
      # Vision RAG Settings
      - RAG_VISION_ENABLED=${RAG_VISION_ENABLED:-true}
      - RAG_VISION_BASE_URL=${RAG_VISION_BASE_URL:-}
      - RAG_VISION_API_KEY=${RAG_VISION_API_KEY:-}
      - RAG_VISION_EMBEDDINGS_MODEL=${RAG_VISION_EMBEDDINGS_MODEL:-MrLight/dse-qwen2-2b-mrl-v1}
      - RAG_VISION_EMBEDDINGS_DIM=${RAG_VISION_EMBEDDINGS_DIM:-1536}
      - RAG_VISION_PGVECTOR_TABLE=${RAG_VISION_PGVECTOR_TABLE:-haystack_documents_vision}
    volumes:
      - helix-socket:/socket
    depends_on:
      - pgvector
    extra_hosts:
      - "host.docker.internal:host-gateway"
  kodit:
    profiles: [kodit]
    image: registry.helixml.tech/helix/kodit:latest
    # ports:
    #   - 8632:8632
    command: ["serve", "--host", "0.0.0.0", "--port", "8632"]
    restart: always
    depends_on:
      - vectorchord-kodit # Wait for VectorChord to start before Kodit
      - api
    environment:
      - DATA_DIR=/data
      - DB_URL=postgresql+asyncpg://postgres:${PGVECTOR_PASSWORD-pgvector}@vectorchord-kodit:5432/kodit
      - DEFAULT_SEARCH_PROVIDER=vectorchord

      # External embedding provider
      # - EMBEDDING_ENDPOINT_TYPE=openai
      # - EMBEDDING_ENDPOINT_SOCKET_PATH=/socket/embeddings.sock
      # - EMBEDDING_ENDPOINT_BASE_URL=http://api:8080/v1
      # - EMBEDDING_ENDPOINT_MODEL=MrLight/dse-qwen2-2b-mrl-v1
      # - EMBEDDING_ENDPOINT_NUM_PARALLEL_TASKS=1
      # - EMBEDDING_ENDPOINT_TIMEOUT=120

      # External enrichment provider
      - ENRICHMENT_ENDPOINT_TYPE=openai
      - ENRICHMENT_ENDPOINT_SOCKET_PATH=/socket/embeddings.sock
      - ENRICHMENT_ENDPOINT_BASE_URL=http://api:8080/v1
      - ENRICHMENT_ENDPOINT_MODEL=qwen3:8b
      - ENRICHMENT_ENDPOINT_NUM_PARALLEL_TASKS=3
      - ENRICHMENT_ENDPOINT_TIMEOUT=120

      # Sync configuration
      - SYNC_PERIODIC_ENABLED=true
      - SYNC_PERIODIC_INTERVAL_SECONDS=1800  # 30 minutes
      - SYNC_PERIODIC_RETRY_ATTEMPTS=3

      - LOG_LEVEL=INFO # INFO or DEBUG
      - LOG_FORMAT=json

      # API Key Configuration
      - API_KEYS=${KODIT_API_KEYS:-}


    volumes:
      - ${KODIT_DATA:-helix-kodit}:/data
      - helix-socket:/socket

  vectorchord-kodit:
    profiles: [kodit]
    image: tensorchord/vchord-suite:pg17-20250601
    environment:
      - POSTGRES_DB=kodit
      - POSTGRES_PASSWORD=${PGVECTOR_PASSWORD-pgvector}
    volumes:
      - ${VECTORCHORD_DATA:-helix-vectorchord-kodit}:/var/lib/postgresql/data
    ports:
      - "5432"
    restart: unless-stopped

  # NOTE: Sandbox services are NOT defined here - they are configured by install.sh
  # for production deployments. See docker-compose.dev.yaml for development sandboxes.

volumes:
  helix-postgres-db:
  helix-pgvector-db:
  helix-filestore:
  helix-typesense-db:
  wolf-debug-dumps:  # Wolf hourly debug dumps (WOLF_MAX_DUMPS controls retention)
  helix-socket:
  helix-kodit:
  helix-vectorchord-kodit:
  wolf-docker-storage:  # Wolf's isolated dockerd storage (sandboxes + devcontainers)

networks:
  default:
    name: helix_default
    ipam:
      config:
        - subnet: 172.19.0.0/16
