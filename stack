#!/usr/bin/env bash
set -euo pipefail
IFS=$'\n\t'

export DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
export HELIX_HOST_HOME="$DIR"
export TMUX_SESSION=${TMUX_SESSION:="helix"}
export WITH_RUNNER=${WITH_RUNNER:=""}
export WITH_DEMOS=${WITH_DEMOS:=""}
export STOP_KEYCLOAK=${STOP_KEYCLOAK:=""}
export STOP_POSTGRES=${STOP_POSTGRES:=""}
export STOP_PGVECTOR=${STOP_PGVECTOR:=""}
export WIPE_SLOTS=${WIPE_SLOTS:="0"}

# Helper function to check for GPU and set appropriate runner profile
function setup_runner_profile() {
  export FORCE_CPU=${FORCE_CPU:=""}

  if [[ -n "$FORCE_CPU" ]]; then
    # Forced CPU mode
    echo "üíª FORCE_CPU is set, forcing CPU mode regardless of GPU detection"
    export RUNNER_CONTAINER="runner"
    export RUNNER_PROFILE="--profile runner"
    export DEV_CPU_ONLY_CMD="DEVELOPMENT_CPU_ONLY=true "
    export VLLM_ENV_VARS="VLLM_DEVICE=cpu VLLM_LOGGING_LEVEL=DEBUG"
  elif command -v nvidia-smi &> /dev/null && nvidia-smi &> /dev/null; then
    # NVIDIA GPU mode
    echo "üöÄ NVIDIA GPU detected, using GPU support"
    export RUNNER_CONTAINER="runner_gpu"
    export RUNNER_PROFILE="--profile runner_gpu"
    export DEV_CPU_ONLY_CMD=""
    export VLLM_ENV_VARS=""
  elif [[ -e "/dev/kfd" ]] && [[ -d "/dev/dri" ]] && command -v lspci &> /dev/null && lspci | grep -iE "(VGA|3D|Display).*AMD" &> /dev/null; then
    # AMD GPU mode (ROCm)
    echo "üöÄ AMD GPU detected (ROCm), using AMD GPU support"
    export RUNNER_CONTAINER="runner_gpu_amd"
    export RUNNER_PROFILE="--profile runner_gpu_amd"
    export DEV_CPU_ONLY_CMD=""
    export VLLM_ENV_VARS=""
  else
    # CPU mode (fallback)
    echo "‚ùå No supported GPU detected, running without GPU support"
    export RUNNER_CONTAINER="runner"
    export RUNNER_PROFILE="--profile runner"
    export DEV_CPU_ONLY_CMD="DEVELOPMENT_CPU_ONLY=true "
    export VLLM_ENV_VARS="VLLM_DEVICE=cpu VLLM_LOGGING_LEVEL=DEBUG"
  fi
}

# Helper function to detect GPU type and set appropriate sandbox profile
# Sets COMPOSE_PROFILES to include 'code' (NVIDIA) or 'code-amd' (AMD/Intel) if not already set
function setup_sandbox_profile() {
  # Check if COMPOSE_PROFILES was set in environment BEFORE sourcing .env (even if empty)
  # ${var+x} expands to "x" if var is set, nothing if unset
  local env_was_set=""
  if [[ -n "${COMPOSE_PROFILES+x}" ]]; then
    env_was_set="true"
  fi

  # Load existing .env if present
  if [[ -f "$DIR/.env" ]]; then
    source "$DIR/.env"
  fi

  # Stop conflicting sandbox containers before starting
  # All sandbox variants use the same static IP (172.19.0.50), so only one can run at a time
  # Silently remove any sandbox containers that might conflict with the one we're about to start
  local current_profile="${COMPOSE_PROFILES:-}"
  if [[ "$current_profile" == *"code-software"* ]]; then
    # Starting software sandbox - stop GPU sandboxes
    docker rm -f helix-sandbox-1 helix-sandbox-amd-1 2>/dev/null || true
  elif [[ "$current_profile" == *"code-amd"* ]]; then
    # Starting AMD sandbox - stop other sandboxes
    docker rm -f helix-sandbox-1 helix-sandbox-software-1 2>/dev/null || true
  else
    # Starting NVIDIA sandbox (default) - stop other sandboxes
    docker rm -f helix-sandbox-software-1 helix-sandbox-amd-1 2>/dev/null || true
  fi

  # If COMPOSE_PROFILES was set in environment before .env (even to empty), respect it
  if [[ "$env_was_set" == "true" ]]; then
    echo "üéÆ Using COMPOSE_PROFILES from environment: '${COMPOSE_PROFILES:-<empty>}'"
    return
  fi

  # If COMPOSE_PROFILES is explicitly set in .env (even to empty), respect it
  if [[ -f "$DIR/.env" ]] && grep -q "^COMPOSE_PROFILES=" "$DIR/.env"; then
    echo "üéÆ Using COMPOSE_PROFILES from .env: '${COMPOSE_PROFILES:-<empty>}'"
    return
  fi

  # Auto-detect GPU type
  local gpu_profile=""

  # Check for NVIDIA GPU first
  if command -v nvidia-smi &> /dev/null && nvidia-smi &> /dev/null; then
    gpu_profile="code"
    echo "üéÆ NVIDIA GPU detected, using 'code' sandbox profile"
  # Check for AMD GPU (ROCm)
  elif [[ -e "/dev/kfd" ]] && [[ -d "/dev/dri" ]] && command -v lspci &> /dev/null && lspci | grep -iE "(VGA|3D|Display).*AMD" &> /dev/null; then
    gpu_profile="code-amd"
    echo "üéÆ AMD GPU detected (ROCm), using 'code-amd' sandbox profile"
  # Check for Intel GPU (or generic /dev/dri)
  elif [[ -d "/dev/dri" ]] && [[ -n "$(ls -A /dev/dri 2>/dev/null)" ]]; then
    gpu_profile="code-amd"  # Intel uses same profile as AMD (no nvidia runtime)
    echo "üéÆ Intel/Generic GPU detected, using 'code-amd' sandbox profile"
  else
    echo "‚ö†Ô∏è  No GPU detected, sandbox features may not work"
    return
  fi

  # Add to COMPOSE_PROFILES if we detected a GPU
  if [[ -n "$gpu_profile" ]]; then
    if [[ -n "${COMPOSE_PROFILES:-}" ]]; then
      export COMPOSE_PROFILES="${COMPOSE_PROFILES},${gpu_profile}"
    else
      export COMPOSE_PROFILES="$gpu_profile"
    fi
    echo "üìã COMPOSE_PROFILES set to: $COMPOSE_PROFILES"
  fi
}

function mock-runner() {
  echo "üî® Building helix-runner binary for mock runner..."
  build-runner || return 1

  echo "üöÄ Starting mock runner..."
  ./helix-runner \
    --mock-runner \
    --server-port 8090 \
    --api-host http://localhost:8080 \
    --api-token oh-hallo-insecure-token \
    --memory 24GB \
    --runner-id mock \
    --label gpu=4090 "$@"
}


function build() {
  # First detect GPU and set variables
  setup_runner_profile

  if [[ -n "$WITH_RUNNER" ]]; then
    # Check for Zed dependency and build if needed
    if [ ! -d "../zed" ]; then
      echo "‚ùå ERROR: Zed source code not found at ../zed/"
      echo ""
      echo "The Zed runner requires the Zed source code to be checked out alongside Helix."
      echo ""
      echo "Please run:"
      echo "  cd .."
      echo "  git clone https://github.com/helixml/zed.git"
      echo "  cd helix"
      echo "  WITH_RUNNER=1 ./stack build"
      exit 1
    fi

    if [ ! -f "./zed-build/zed" ]; then
      echo "üî® Zed binary not found, building automatically..."
      build-zed || {
        echo "‚ùå Failed to build Zed. Please check the error messages above."
        echo "Note: Rust/Cargo is required to build Zed. Install from: https://rustup.rs/"
        exit 1
      }
    fi

    echo "üî® Building runner: $RUNNER_CONTAINER"
    docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" build
    return
  fi

  if [[ -n "$WITH_DEMOS" ]]; then
    echo "üî® Building demos"
    docker compose -f docker-compose.dev.yaml --profile demos build
    return
  fi

  # No profiles specified, just build everything
  echo "üî® Building all services"
  docker compose -f docker-compose.dev.yaml build
}

function static-compile() {
  export CGO_ENABLED=0
  go build -ldflags '-extldflags "-static"' -o helix .
}

function build-runner() {
  echo "üî® Building helix-runner binary..."
  export CGO_ENABLED=1
  local APP_VERSION=${APP_VERSION:-"v0.0.0+dev"}

  if go build -buildvcs=false -tags '!rocm' -ldflags '-s -w -X github.com/helixml/helix/api/pkg/data.Version='$APP_VERSION -o helix-runner ./runner-cmd/helix-runner; then
    echo "‚úÖ Successfully built helix-runner binary"
  else
    echo "‚ùå Failed to build helix-runner binary"
    return 1
  fi
}

function build-runner-image() {
  echo "üê≥ Building runner Docker image..."
  local IMAGE_TAG="${1:-test}"
  local APP_VERSION=$(git rev-parse HEAD 2>/dev/null || echo "v0.0.0+dev")
  # Base image tag - default to latest-empty for fast test builds (skips ~16GB download)
  # Use 'latest-small' for production builds that need full base image
  local BASE_TAG="${2:-latest-empty}"

  echo "  Output: registry.helixml.tech/helix/runner:$IMAGE_TAG"
  echo "  Base: registry.helixml.tech/helix/runner-base:$BASE_TAG"
  echo "  Version: $APP_VERSION"
  echo "  Note: ROCm vLLM build takes ~10 minutes"
  echo ""

  docker build \
    -f Dockerfile.runner \
    --build-arg TAG="$BASE_TAG" \
    --build-arg APP_VERSION="$APP_VERSION" \
    -t "registry.helixml.tech/helix/runner:$IMAGE_TAG" \
    .
}

function build-zed() {
  echo "üî® Building Zed with External WebSocket Thread Sync..."

  local ZED_SOURCE_DIR="../zed"
  local ZED_OUTPUT_DIR="./zed-build"
  local BUILD_TYPE="${1:-dev}"

  # Validate build type
  if [[ "$BUILD_TYPE" != "dev" && "$BUILD_TYPE" != "release" ]]; then
    echo "‚ùå Error: BUILD_TYPE must be 'dev' or 'release'"
    echo "Usage: ./stack build-zed [dev|release]"
    echo ""
    echo "Build types:"
    echo "  dev     - Fast incremental builds with debug symbols (default)"
    echo "  release - Optimized production builds (slower, ~3-5 minutes)"
    return 1
  fi

  # Check if Zed source directory exists
  if [ ! -d "$ZED_SOURCE_DIR" ]; then
    echo "‚ùå Zed source directory not found at: $ZED_SOURCE_DIR"
    echo "Expected directory structure:"
    echo "  helix/                 (current directory)"
    echo "  zed/                   (Zed fork with external_websocket_sync)"
    return 1
  fi

  # Check if external_websocket_sync exists in Zed source
  if [ ! -d "$ZED_SOURCE_DIR/crates/external_websocket_sync" ]; then
    echo "‚ùå external_websocket_sync crate not found in Zed source"
    echo "Make sure you're using the Zed fork with External WebSocket Thread Sync"
    return 1
  fi

  # Check if Rust is installed
  if ! command -v cargo &> /dev/null; then
    echo "‚ùå Rust/Cargo not found. Please install Rust first."
    echo "Install Rust: https://rustup.rs/"
    return 1
  fi

  # Create output directory
  mkdir -p "$ZED_OUTPUT_DIR"

  # Change to Zed source directory
  cd "$ZED_SOURCE_DIR"

  echo "üî® Building Zed with External WebSocket Thread Sync..."
  echo "Source directory: $(pwd)"
  echo "Build type: $BUILD_TYPE"

  # Build Zed based on build type
  if [ "$BUILD_TYPE" = "release" ]; then
    echo "üî® Building in release mode (optimized, stripped, slower build)..."
    # Use RUSTFLAGS to enable stripping during build (better than post-build strip)
    if RUSTFLAGS="-C link-arg=-s" RUST_LOG=info cargo build --release --features external_websocket_sync; then
      BINARY_PATH="target/release/zed"
    else
      echo "‚ùå Zed release build failed"
      cd - > /dev/null
      return 1
    fi
  else
    echo "üî® Building in dev mode (fast incremental builds with debug symbols)..."
    if RUST_LOG=info cargo build --features external_websocket_sync; then
      BINARY_PATH="target/debug/zed"
    else
      echo "‚ùå Zed dev build failed"
      cd - > /dev/null
      return 1
    fi
  fi

  # Check if build was successful
  if [ ! -f "$BINARY_PATH" ]; then
    echo "‚ùå Build failed: Binary not found at $BINARY_PATH"
    cd - > /dev/null
    return 1
  fi

  echo "‚úÖ Zed compilation completed successfully"

  # Copy binary to output directory (atomic rename to avoid "text file busy")
  cd - > /dev/null
  cp "$ZED_SOURCE_DIR/$BINARY_PATH" "$ZED_OUTPUT_DIR/zed.new"
  chmod +x "$ZED_OUTPUT_DIR/zed.new"

  # Atomic rename (works even if old binary is in use by running containers)
  if [ -f "$ZED_OUTPUT_DIR/zed" ]; then
    mv "$ZED_OUTPUT_DIR/zed" "$ZED_OUTPUT_DIR/zed.old" 2>/dev/null || true
  fi
  mv "$ZED_OUTPUT_DIR/zed.new" "$ZED_OUTPUT_DIR/zed"
  rm -f "$ZED_OUTPUT_DIR/zed.old" 2>/dev/null || true

  # Get binary info
  local BINARY_SIZE=$(du -h "$ZED_OUTPUT_DIR/zed" | cut -f1)

  echo "‚úÖ Zed binary copied to: $ZED_OUTPUT_DIR/zed"
  echo "üì¶ Binary size: $BINARY_SIZE"

  # Verify external WebSocket sync is included
  if strings "$ZED_OUTPUT_DIR/zed" | grep -q "external_websocket_sync"; then
    echo "‚úÖ External WebSocket Thread Sync detected in binary"
  else
    echo "‚ö†Ô∏è  External WebSocket Thread Sync not clearly detectable (this might be normal)"
  fi

  # Note: Release builds are already stripped via RUSTFLAGS during compilation
  if [ "$BUILD_TYPE" = "release" ]; then
    echo "‚úÖ Binary built with symbols stripped (via linker flags)"
  fi

  # Create test configuration
  cat > "$ZED_OUTPUT_DIR/test-settings.json" << EOF
{
  "external_websocket_sync": {
    "enabled": true,
    "server": {
      "enabled": true,
      "host": "127.0.0.1",
      "port": 3030
    },
    "websocket_sync": {
      "enabled": true,
      "external_url": "localhost:8080",
      "use_tls": false,
      "auto_reconnect": true
    }
  }
}
EOF

  echo "‚úÖ Created test configuration: $ZED_OUTPUT_DIR/test-settings.json"
  echo "üéâ Zed build completed successfully!"
  echo ""
  echo "Next steps:"
  echo "  1. Test the binary: cd $ZED_OUTPUT_DIR && ./zed --version"
  echo "  2. Build Sway container with Zed: ./stack build-sway"
  echo "  3. Start services: ./stack start"
}

function start() {
  if tmux has-session -t "$TMUX_SESSION" 2>/dev/null; then
    echo "üì∫ Session $TMUX_SESSION already exists. Attaching..."
    sleep 1
    tmux -2 attach -t $TMUX_SESSION
    exit 0;
  fi

  # Check for Zed dependency and build if needed
  if [ ! -d "../zed" ]; then
    echo "‚ùå ERROR: Zed source code not found at ../zed/"
    echo ""
    echo "The Zed runner requires the Zed source code to be checked out alongside Helix."
    echo ""
    echo "Please run:"
    echo "  cd .."
    echo "  git clone https://github.com/helixml/zed.git"
    echo "  cd helix"
    echo "  ./stack start"
    exit 1
  fi

  if [ ! -f "./zed-build/zed" ]; then
    echo "üî® Zed binary not found, building automatically..."
    build-zed || {
      echo "‚ùå Failed to build Zed. Please check the error messages above."
      exit 1
    }
  fi

  # Check if Wolf container exists, build if needed
  if ! docker image inspect wolf:helix-fixed &> /dev/null; then
    echo "üê∫ Wolf container not found, building automatically..."
    build-wolf || {
      echo "‚ùå Failed to build Wolf. Please check the error messages above."
      exit 1
    }
  fi

  # Check if Moonlight Web container exists, build if needed
  if ! docker image inspect helix-moonlight-web:helix-fixed &> /dev/null; then
    echo "üåô Moonlight Web container not found, building automatically..."
    build-moonlight-web || {
      echo "‚ùå Failed to build Moonlight Web. Please check the error messages above."
      exit 1
    }
  fi

  export MANUALRUN=1
  export LOG_LEVEL=debug

  # Clean Wolf and Moonlight Web pairing state for fresh startup
  echo "üßπ Cleaning Wolf and Moonlight Web pairing state..."

  # Stop sandbox if running (Wolf + Moonlight Web are unified in sandbox now)
  docker compose -f docker-compose.dev.yaml stop sandbox 2>/dev/null || true

  # Remove state files to force fresh pairing on startup
  # These are bind-mounted into the sandbox container
  rm -f "$DIR/wolf/config.toml" "$DIR/moonlight-web-config/data.json" 2>/dev/null || true
  echo "‚úÖ Pairing state cleaned (will auto-pair on startup)"

  echo "üê≥ Starting docker compose"

  # Setup runner profiles first
  setup_runner_profile

  # Setup sandbox profile based on GPU detection
  setup_sandbox_profile

  # Start services based on enabled profiles
  if [[ -n "$WITH_RUNNER" ]]; then
    if [[ -n "$WITH_DEMOS" ]]; then
      # Both runner and demos
      echo "üöÄ Starting services with runner ($RUNNER_CONTAINER) and demos profiles"
      docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" --profile demos up -d
    else
      # Just runner
      echo "üöÄ Starting services with runner ($RUNNER_CONTAINER) profile"
      docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" up -d
    fi
  elif [[ -n "$WITH_DEMOS" ]]; then
    # Just demos
    echo "üöÄ Starting services with demos profile"
    docker compose -f docker-compose.dev.yaml --profile demos up -d
  else
    # No special profiles
    echo "üöÄ Starting base services"
    docker compose -f docker-compose.dev.yaml up -d
  fi

  sleep 2

  # Wait for postgres to be ready before trying to wipe slots
  echo "‚è≥ Waiting for postgres to be ready..."
  timeout=60
  while ! docker compose -f docker-compose.dev.yaml exec postgres pg_isready -h localhost -p 5432 >/dev/null 2>&1; do
    timeout=$((timeout - 1))
    if [[ $timeout -eq 0 ]]; then
      echo "‚ö†Ô∏è Warning: Postgres not ready after 60 seconds, continuing anyway"
      break
    fi
    echo "‚è≥ Waiting for postgres... ($timeout seconds remaining)"
    sleep 1
  done

  # Check if WIPE_SLOTS is set and wipe slots if requested
  if [[ -n "$WIPE_SLOTS" ]]; then
    echo "üßπ WIPE_SLOTS is set, wiping slots from database..."
    if ! wipe-slots; then
      echo "‚ö†Ô∏è Warning: Failed to wipe slots, but continuing startup..."
    fi
  fi

  echo "üì∫ Creating tmux session $TMUX_SESSION with 3x2 grid layout + full-width hacking terminal..."
  tmux -2 new-session -d -s "$TMUX_SESSION"

  # Create a 3x2 grid layout with full-width hacking terminal at bottom
  # First create top and middle rows for logs
  tmux split-window -v -d
  tmux split-window -v -d

  # Split the top row into 3 columns (Frontend, API, Haystack)
  tmux select-pane -t 0
  tmux split-window -h -d
  tmux select-pane -t 1
  tmux split-window -h -d

  # Split the middle row into 3 columns (Zed Agent, Zed Process, GPU Runner)
  tmux select-pane -t 3
  tmux split-window -h -d
  tmux select-pane -t 4
  tmux split-window -h -d

  # Bottom pane (6) stays full-width for hacking terminal

  # Set pane titles and start processes in 3x2 + full-width layout
  # Top row (0-2): Frontend, API, Haystack
  tmux select-pane -t 0 -T "Frontend Logs"
  tmux send-keys -t 0 'docker compose -f docker-compose.dev.yaml logs -f frontend' C-m

  tmux select-pane -t 1 -T "API Logs"
  tmux send-keys -t 1 'docker compose -f docker-compose.dev.yaml logs -f api' C-m

  tmux select-pane -t 2 -T "Haystack Logs"
  tmux send-keys -t 2 'docker compose -f docker-compose.dev.yaml logs -f haystack' C-m

  # Middle row (3-5): Context-aware based on WITH_RUNNER
  if [[ -n "$WITH_RUNNER" ]]; then
    # WITH_RUNNER mode: Sandbox logs in pane 3
    tmux select-pane -t 3 -T "Sandbox Logs (Wolf + Moonlight)"
    tmux send-keys -t 3 'docker compose -f docker-compose.dev.yaml logs -f sandbox' C-m

    tmux select-pane -t 4 -T "üî® HACKING TERMINAL"
    tmux send-keys -t 4 'echo "üî® Hacking terminal ready!" && echo "üí° Tip: Use this for development, debugging, and building"' C-m

    # GPU runner logs with air hot reloading
    tmux select-pane -t 5 -T "GPU Runner ($RUNNER_CONTAINER)"
    tmux send-keys -t 5 'echo "Monitoring GPU Runner logs (with air hot reloading)..." && sleep 3 && docker compose -f docker-compose.dev.yaml --profile '"$RUNNER_CONTAINER"' logs -f '"$RUNNER_CONTAINER" C-m
  else
    # WITHOUT_RUNNER mode: Unified sandbox logs (Wolf + Moonlight Web in one container)
    tmux select-pane -t 3 -T "Sandbox Logs (Wolf + Moonlight)"
    tmux send-keys -t 3 'docker compose -f docker-compose.dev.yaml logs -f sandbox' C-m

    tmux select-pane -t 4 -T "üî® HACKING TERMINAL"
    tmux send-keys -t 4 'echo "üî® Hacking terminal ready!" && echo "üí° Tip: Use this for development, debugging, and building"' C-m

    # Middle right pane (5) - contextual based on demos
    if [[ -n "$WITH_DEMOS" ]]; then
      # Demos interactive session
      tmux select-pane -t 5 -T "Demos"
      tmux send-keys -t 5 'docker compose -f docker-compose.dev.yaml --profile demos exec demos bash' C-m
    else
      # Hacking terminal
      tmux select-pane -t 5 -T "üî® HACKING TERMINAL"
      tmux send-keys -t 5 'echo "üî® Hacking terminal ready!" && echo "üí° Tip: Use this for development, debugging, and building"' C-m
    fi
  fi

  # Bottom full-width pane (6) - HACKING TERMINAL! üî®
  tmux select-pane -t 6 -T "üî® HACKING TERMINAL"
  tmux send-keys -t 6 'echo "üî® Full-width hacking terminal ready!" && echo "üí° Tip: Use this for development, debugging, and building"' C-m

  if [[ -n "$WITH_DEMOS" && -n "$WITH_RUNNER" ]]; then
    echo "Note: Both GPU runner and demos enabled - demos available in background. Run manually with: docker compose -f docker-compose.dev.yaml --profile demos exec demos bash"
  fi

  # Enable pane titles display
  tmux set-option -g pane-border-status top
  tmux set-option -g pane-border-format "#{pane_index}: #{pane_title}"

  # Make all panes equal size
  tmux select-layout even-horizontal
  tmux select-layout tiled

  tmux -2 attach-session -t $TMUX_SESSION
}

function stop() {
  echo "üõë Stopping docker containers and tmux session..."

  # Clean up Wolf config and certificates to ensure fresh start next time
  if [ -f "wolf/config.toml" ]; then
    echo "üóëÔ∏è  Removing Wolf config.toml (will be regenerated from template on next start)"
    rm -f wolf/config.toml
  fi
  if [ -f "wolf/cert.pem" ] || [ -f "wolf/key.pem" ]; then
    echo "üóëÔ∏è  Removing Wolf SSL certificates (will be regenerated on next start)"
    rm -f wolf/cert.pem wolf/key.pem
  fi

  # Clean up Moonlight Web pairing data to ensure fresh pairing with Wolf's new certs
  if [ -f "moonlight-web-config/data.json" ]; then
    echo "üóëÔ∏è  Removing Moonlight Web pairing data (will re-pair with Wolf on next start)"
    rm -f moonlight-web-config/data.json
  fi

  # Build exclude pattern for services that should not be stopped
  local exclude_services=()
  [[ -z "$STOP_KEYCLOAK" ]] && exclude_services+=("keycloak")
  [[ -z "$STOP_POSTGRES" ]] && exclude_services+=("postgres")
  [[ -z "$STOP_PGVECTOR" ]] && exclude_services+=("pgvector")

  # Setup runner profiles first
  setup_runner_profile

  if [[ ${#exclude_services[@]} -eq 0 ]]; then
    echo "üóëÔ∏è Removing all docker containers"

    # Stop containers based on enabled profiles
    if [[ -n "$WITH_RUNNER" ]]; then
      if [[ -n "$WITH_DEMOS" ]]; then
        # Both runner and demos
        echo "üîÑ Stopping services with runner ($RUNNER_CONTAINER) and demos profiles"
        docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" --profile demos down -t 1 || echo "‚ö†Ô∏è  Some services may not exist"
      else
        # Just runner
        echo "üîÑ Stopping services with runner ($RUNNER_CONTAINER) profile"
        docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" down -t 1 || echo "‚ö†Ô∏è  Some services may not exist"
      fi
    elif [[ -n "$WITH_DEMOS" ]]; then
      # Just demos
      echo "üîÑ Stopping services with demos profile"
      docker compose -f docker-compose.dev.yaml --profile demos down -t 1 || echo "‚ö†Ô∏è  Some services may not exist"
    else
      # Include all profiles when no environment variables are set
      echo "üîÑ Stopping all services (all profiles)"
      docker compose -f docker-compose.dev.yaml --profile runner --profile runner_gpu --profile demos down -t 1 || echo "‚ö†Ô∏è  Some services may not exist"
    fi
  else
    # Create exclude list for display and grep pattern
    local exclude_list=$(IFS=', '; echo "${exclude_services[*]}")
    local exclude_pattern=$(IFS='|'; echo "${exclude_services[*]}")
    echo "üóëÔ∏è Removing docker containers (except: $exclude_list)"

    # Get list of services to stop (excluding the ones we want to keep)
    if [[ -n "$WITH_RUNNER" ]]; then
      if [[ -n "$WITH_DEMOS" ]]; then
        echo "üîÑ Stopping services with runner ($RUNNER_CONTAINER) and demos profiles (except: $exclude_list)"
        local services=$(docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" --profile demos config --services 2>/dev/null | grep -v -E "$exclude_pattern" || true)
      else
        echo "üîÑ Stopping services with runner ($RUNNER_CONTAINER) profile (except: $exclude_list)"
        local services=$(docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" config --services 2>/dev/null | grep -v -E "$exclude_pattern" || true)
      fi
    elif [[ -n "$WITH_DEMOS" ]]; then
      echo "üîÑ Stopping services with demos profile (except: $exclude_list)"
      local services=$(docker compose -f docker-compose.dev.yaml --profile demos config --services 2>/dev/null | grep -v -E "$exclude_pattern" || true)
    else
      echo "üîÑ Stopping all services (all profiles, except: $exclude_list)"
      local services=$(docker compose -f docker-compose.dev.yaml --profile runner --profile runner_gpu --profile demos config --services 2>/dev/null | grep -v -E "$exclude_pattern" || true)
    fi

    # Stop only the non-excluded services
    if [[ -n "$services" ]]; then
      echo "üóëÔ∏è Going to remove containers: $(echo $services | tr '\n' ' ')"
      # Stop and remove containers using a while loop to avoid xargs command line length issues
      while IFS= read -r service; do
        if [[ -n "$service" ]]; then
          echo "üóëÔ∏è Stopping and removing: $service"
          docker compose -f docker-compose.dev.yaml stop "$service" 2>/dev/null && \
          docker compose -f docker-compose.dev.yaml rm -f "$service" 2>/dev/null || \
          echo "‚ö†Ô∏è  Could not stop/remove $service"
        fi
      done <<< "$services"
    else
      echo "‚ú® No services to stop (all are excluded)"
    fi
  fi

  echo "üì∫ Stopping tmux session $TMUX_SESSION..."
  if tmux has-session -t $TMUX_SESSION 2>/dev/null; then
    tmux kill-session -t $TMUX_SESSION || echo "‚ö†Ô∏è  Failed to kill tmux session, but continuing..."
  else
    echo "üì∫ Tmux session $TMUX_SESSION not found"
  fi

  echo "‚ú® Stop completed successfully!"
}

function up() {
  # Check if Wolf source code exists, if not clone it
  if [ ! -d "../wolf" ]; then
    echo "üê∫ Wolf source code not found at ../wolf/"
    echo "üì• Cloning Wolf repository..."
    cd ..
    git clone https://github.com/games-on-whales/wolf.git
    cd helix
    echo "‚úÖ Wolf repository cloned successfully"
  fi

  # Setup sandbox profile based on GPU detection (if not already in .env)
  setup_sandbox_profile

  # Sandbox services are enabled via COMPOSE_PROFILES in .env or auto-detected above
  # Profile 'code' = NVIDIA GPU, 'code-amd' = AMD/Intel GPU

  docker compose -f docker-compose.dev.yaml up -d $@
}

function build-zed-agent() {
  echo "üî® Building Zed agent Docker image..."

  # Build the Docker image using the Zed binary we built
  if [ ! -f "./zed-build/zed" ]; then
    echo "‚ùå Zed binary not found. Run './stack build-zed' first."
    return 1
  fi

  docker build -t helix-sway:latest -f Dockerfile.sway-helix .

  if [ $? -eq 0 ]; then
    echo "‚úÖ Zed agent Docker image built successfully"
  else
    echo "‚ùå Failed to build Zed agent Docker image"
    return 1
  fi
}

function zed-agent-up() {
  echo "Starting Zed agent services..."

  # Build Zed if binary doesn't exist
  if [ ! -f "./zed-build/zed" ]; then
    echo "Zed binary not found, building first..."
    build-zed || return 1
  fi

  # Check if image doesn't exist
  if ! docker image inspect helix/zed-agent:latest &> /dev/null; then
    echo "Zed agent image not found, building first..."
    build-zed-agent || return 1
  fi

  docker compose -f docker-compose.zed-agent.yaml up -d

  echo "‚úÖ Zed agent services started"
  echo "üìã Services running:"
  echo "  - Helix API: http://localhost:8080"
  echo "  - Zed HTTP API: http://localhost:3030"
  echo "  - VNC Web Client: http://localhost:6080"
  echo ""
  echo "üß™ Test commands:"
  echo "  curl http://localhost:8080/health    # Helix API"
  echo "  curl http://localhost:3030/health    # Zed integration API"
}

function zed-agent-down() {
  echo "Stopping Zed agent services..."
  docker compose -f docker-compose.zed-agent.yaml down
}

function zed-agent-logs() {
  docker compose -f docker-compose.zed-agent.yaml logs -f "${1:-zed-agent-runner}"
}

function rebuild() {
  docker compose -f docker-compose.dev.yaml up -d --build $@
}

# Helper function to build image tags string (commit hash + git tag if available)
function get_image_tags() {
  local OLD_IFS=$IFS
  IFS=' '  # Temporarily use space as IFS for proper word splitting

  local IMAGE_BASE=$1
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")

  local TAG_STRING="-t ${IMAGE_BASE}:${COMMIT_HASH}"

  if [ -n "$GIT_TAG" ]; then
    TAG_STRING="${TAG_STRING} -t ${IMAGE_BASE}:${GIT_TAG}"
    echo "üè∑Ô∏è  Git tag detected: ${GIT_TAG}" >&2
  fi

  printf "%s" "${TAG_STRING}"  # Use printf to avoid trailing newline issues

  IFS=$OLD_IFS
}

# Helper function to push all image tags
function push_image_tags() {
  local IMAGE_BASE=$1
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  # Use exported GIT_TAG if available (from build-and-push-helix-code), otherwise detect from git
  local GIT_TAG="${GIT_TAG:-$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")}"

  # Always push commit hash tag
  echo "üì§ Pushing ${IMAGE_BASE}:${COMMIT_HASH}"
  if ! docker push "${IMAGE_BASE}:${COMMIT_HASH}"; then
    echo "‚ö†Ô∏è  Failed to push ${IMAGE_BASE}:${COMMIT_HASH}"
    return 1
  fi

  # Also push git tag if available
  if [ -n "$GIT_TAG" ]; then
    echo "üì§ Pushing ${IMAGE_BASE}:${GIT_TAG}"
    if ! docker push "${IMAGE_BASE}:${GIT_TAG}"; then
      echo "‚ö†Ô∏è  Failed to push ${IMAGE_BASE}:${GIT_TAG}"
      return 1
    fi
  fi

  return 0
}

function build-wolf() {
  echo "üê∫ Building Wolf container with latest source code..."

  # Check if Wolf source directory exists
  if [ ! -d "../wolf" ]; then
    echo "‚ùå ERROR: Wolf source code not found at ../wolf/"
    echo ""
    echo "The Wolf integration requires the Wolf source code to be checked out alongside Helix."
    echo ""
    echo "Please run:"
    echo "  cd .."
    echo "  git clone https://github.com/games-on-whales/wolf.git"
    echo "  cd helix"
    echo "  ./stack build-wolf"
    exit 1
  fi

  # Build Wolf container with image tags
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")

  echo "üî® Building Wolf container from source..."
  cd ../wolf

  if [ -n "$GIT_TAG" ]; then
    echo "üè∑Ô∏è  Git tag detected: ${GIT_TAG}"
    docker build -f docker/wolf.Dockerfile \
      -t wolf:helix-fixed \
      -t "registry.helixml.tech/helix/wolf:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/wolf:${GIT_TAG}" \
      .
  else
    docker build -f docker/wolf.Dockerfile \
      -t wolf:helix-fixed \
      -t "registry.helixml.tech/helix/wolf:${COMMIT_HASH}" \
      .
  fi

  if [ $? -eq 0 ]; then
    echo "‚úÖ Wolf container built successfully"
  else
    echo "‚ùå Failed to build Wolf container"
    cd - > /dev/null
    return 1
  fi
  cd - > /dev/null

  # Note: Wolf image is an intermediate build artifact, embedded in helix-sandbox
  # It's not pushed to registry separately - only the sandbox container is pushed
  # Wolf runs inside the sandbox container now, not as a standalone service
}

function build-xfce() {
  echo "üñ•Ô∏è  Building custom XFCE container with passwordless sudo..."

  # Build the custom XFCE image
  echo "üî® Building helix-xfce:latest container..."
  if docker build -f Dockerfile.xfce-helix -t helix-xfce:latest .; then
    echo "‚úÖ XFCE container built successfully"
    echo "üñ•Ô∏è  Custom XFCE image ready: helix-xfce:latest"
    echo ""
    echo "Features added:"
    echo "  - Passwordless sudo for retro and user accounts"
    echo "  - Proper work directory permissions"
  else
    echo "‚ùå Failed to build XFCE container"
    exit 1
  fi
}

function build-sway() {
  echo "ü™ü  Building custom Sway container for Personal Dev Environments..."

  # Production mode: Always rebuild Zed from latest source in release mode
  if [ -n "${SKIP_DEV_RESTART:-}" ]; then
    echo "üî® Production mode: Building fresh Zed release from latest source..."
    if ! build-zed release; then
      echo "‚ùå Failed to build Zed binary"
      exit 1
    fi
  # Dev mode: Only build if binary doesn't exist
  elif [ ! -f "./zed-build/zed" ]; then
    echo "‚ùå Zed binary not found. Building in release mode first..."
    if ! build-zed release; then
      echo "‚ùå Failed to build Zed binary"
      exit 1
    fi
  else
    echo "‚úÖ Using existing Zed binary at ./zed-build/zed (dev mode)"
  fi

  # Build the custom Sway image with image tags
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")

  echo "üî® Building helix-sway:latest container with Zed..."

  if [ -n "$GIT_TAG" ]; then
    echo "üè∑Ô∏è  Git tag detected: ${GIT_TAG}"
    docker build -f Dockerfile.sway-helix \
      -t helix-sway:latest \
      -t "helix-sway:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/zed-agent:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/zed-agent:${GIT_TAG}" \
      .
  else
    docker build -f Dockerfile.sway-helix \
      -t helix-sway:latest \
      -t "helix-sway:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/zed-agent:${COMMIT_HASH}" \
      .
  fi

  if [ $? -eq 0 ]; then
    echo "‚úÖ Sway container built successfully"
    echo "ü™ü  Custom Sway image ready: helix-sway:latest"
    echo ""
    echo "Features added:"
    echo "  - Sway tiling window manager with waybar"
    echo "  - Zed editor with External WebSocket Thread Sync"
    echo "  - Firefox, Ghostty terminal, OnlyOffice"
    echo "  - Screenshot server (grim-based) for Moonlight streaming"
    echo "  - Passwordless sudo for development"
    echo "  - Docker CLI for container-in-container workflows"
  else
    echo "‚ùå Failed to build Sway container"
    exit 1
  fi

  echo "‚úÖ Sway container build completed"
  echo "üì¶ Note: helix-sway is embedded in helix-sandbox (not pushed separately to registry)"

  # Transfer helix-sway image to sandbox's dockerd (Wolf runs inside sandbox container)
  # Only transfer if sandbox is already running (hot reload during development)
  # Skip if called from build-sandbox (which restarts sandbox with embedded tarball)
  if [ -z "${SKIP_SWAY_TRANSFER:-}" ]; then
    transfer-sway-to-sandbox
  fi
}

function transfer-sway-to-sandbox() {
  # Transfer helix-sway image from host to sandbox's isolated dockerd
  # This is required because sandbox runs its own dockerd (DinD) and doesn't have access to host images

  # Check if sandbox container is running
  if ! docker compose -f docker-compose.dev.yaml ps sandbox | grep -q "Up"; then
    echo "‚ÑπÔ∏è  Sandbox container not running, skipping image transfer (will transfer on next start)"
    return 0
  fi

  # Check if helix-sway image exists on host
  if ! docker images helix-sway:latest -q | grep -q .; then
    echo "‚ö†Ô∏è  helix-sway:latest not found on host, skipping transfer"
    return 0
  fi

  # Get commit hash BEFORE transfer (needed for tagging)
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local IMAGE_HASH=$(docker images helix-sway:latest --format '{{.ID}}')

  # Check if versioned tag exists on host
  local HAS_VERSIONED_TAG=""
  if docker images "helix-sway:${COMMIT_HASH}" -q | grep -q .; then
    HAS_VERSIONED_TAG="true"
  fi

  # Transfer image(s) to sandbox's dockerd
  local TRANSFER_SUCCESS=""
  if [ -n "$HAS_VERSIONED_TAG" ]; then
    # Transfer BOTH tags: latest and versioned (Wolf uses helix-sway:${version})
    echo "üì¶ Transferring helix-sway:latest and helix-sway:${COMMIT_HASH} to sandbox's dockerd..."
    if docker save helix-sway:latest "helix-sway:${COMMIT_HASH}" | docker exec -i helix-sandbox-1 docker load 2>/dev/null; then
      TRANSFER_SUCCESS="true"
      echo "‚úÖ helix-sway images transferred to sandbox's dockerd"
    fi
  else
    # Only :latest exists - transfer and tag inside sandbox
    echo "üì¶ Transferring helix-sway:latest to sandbox's dockerd..."
    if docker save helix-sway:latest | docker exec -i helix-sandbox-1 docker load 2>/dev/null; then
      echo "‚úÖ helix-sway:latest transferred to sandbox's dockerd"
      # Tag it with the version inside sandbox
      echo "üè∑Ô∏è  Tagging helix-sway:latest as helix-sway:${COMMIT_HASH} inside sandbox..."
      docker exec helix-sandbox-1 docker tag helix-sway:latest "helix-sway:${COMMIT_HASH}"
      TRANSFER_SUCCESS="true"
    fi
  fi

  if [ -n "$TRANSFER_SUCCESS" ]; then
    # Update version files inside sandbox
    echo "üìù Updating version files in sandbox (version: ${COMMIT_HASH}, hash: ${IMAGE_HASH})..."
    docker exec helix-sandbox-1 bash -c "echo '${COMMIT_HASH}' > /opt/images/helix-sway.version"
    docker exec helix-sandbox-1 bash -c "echo '${IMAGE_HASH}' > /opt/images/helix-sway.tar.hash"

    # Restart heartbeat to immediately report new version (supervisor loop will restart it)
    echo "üîÑ Restarting heartbeat daemon..."
    docker exec helix-sandbox-1 pkill -f sandbox-heartbeat 2>/dev/null || true

    echo "‚úÖ Version files updated and heartbeat restarted"
  else
    echo "‚ÑπÔ∏è  Could not transfer image to sandbox (container may be starting/restarting)"
    echo "   Image will be loaded from embedded tarball when sandbox is ready"
  fi
}

function build-moonlight-web() {
  echo "üåô Building Moonlight Web container..."

  # Check if moonlight-web source directory exists
  if [ ! -d "../moonlight-web-stream" ]; then
    echo "‚ùå ERROR: Moonlight Web source code not found at ../moonlight-web-stream/"
    echo ""
    echo "The Moonlight Web integration requires the source code to be checked out alongside Helix."
    echo ""
    echo "Please run:"
    echo "  cd .."
    echo "  git clone https://github.com/helixml/moonlight-web-stream.git"
    echo "  cd helix"
    echo "  ./stack build-moonlight-web"
    exit 1
  fi

  # Build Moonlight Web container with image tags (like Wolf)
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")

  # Determine build mode: always use release (fast, optimized)
  # Set BUILD_MODE=debug to override for debugging purposes
  local BUILD_MODE="${BUILD_MODE:-release}"
  if [ "$BUILD_MODE" = "release" ]; then
    echo "üî® Building Moonlight Web container from source (RELEASE MODE)..."
  else
    echo "üî® Building Moonlight Web container from source (DEBUG MODE)..."
  fi
  cd ../moonlight-web-stream

  if [ -n "$GIT_TAG" ]; then
    echo "üè∑Ô∏è  Git tag detected: ${GIT_TAG}"
    docker build -f Dockerfile \
      --build-arg BUILD_MODE=$BUILD_MODE \
      -t helix-moonlight-web:helix-fixed \
      -t "registry.helixml.tech/helix/moonlight-web:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/moonlight-web:${GIT_TAG}" \
      .
  else
    docker build -f Dockerfile \
      --build-arg BUILD_MODE=$BUILD_MODE \
      -t helix-moonlight-web:helix-fixed \
      -t "registry.helixml.tech/helix/moonlight-web:${COMMIT_HASH}" \
      .
  fi

  if [ $? -eq 0 ]; then
    echo "‚úÖ Moonlight Web container built successfully"
  else
    echo "‚ùå Failed to build Moonlight Web container"
    cd - > /dev/null
    return 1
  fi
  cd - > /dev/null

  # Note: Moonlight Web image is an intermediate build artifact, embedded in helix-sandbox
  # It's not pushed to registry separately - only the sandbox container is pushed
  # Moonlight Web runs inside the sandbox container now, not as a standalone service
}

function build-sandbox() {
  echo "üì¶ Building unified Helix Sandbox container (Wolf + Moonlight Web + RevDial + DinD)..."
  echo ""
  echo "This builds a unified container with:"
  echo "  ‚Ä¢ Wolf streaming platform (from ~/pm/wolf)"
  echo "  ‚Ä¢ Moonlight Web (from ~/pm/moonlight-web-stream)"
  echo "  ‚Ä¢ RevDial client (built from source)"
  echo "  ‚Ä¢ Docker-in-Docker with NVIDIA runtime"
  echo "  ‚Ä¢ helix-sway image (pre-loaded into Wolf's dockerd)"
  echo "  ‚Ä¢ GOW base-app init system (cont-init.d + entrypoint.sh)"
  echo ""

  local COMMIT_HASH=$(git rev-parse --short HEAD)
  # Use exported GIT_TAG if available (from build-and-push-helix-code), otherwise detect from git
  local GIT_TAG="${GIT_TAG:-$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")}"

  # Step 0: Build Wolf and Moonlight Web (fast if unchanged due to Docker cache)
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üìù [0/4] Building Wolf and Moonlight Web dependencies..."
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

  # Build Wolf (skip container restart - we'll restart sandbox instead)
  echo "üê∫ Building Wolf..."
  if ! SKIP_DEV_RESTART=1 build-wolf; then
    echo "‚ùå Failed to build Wolf"
    return 1
  fi

  # Build Moonlight Web (skip container restart - we'll restart sandbox instead)
  echo "üåô Building Moonlight Web..."
  if ! SKIP_DEV_RESTART=1 build-moonlight-web; then
    echo "‚ùå Failed to build Moonlight Web"
    return 1
  fi
  echo ""

  # Step 1: Build Zed if needed (required for helix-sway)
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üìù [1/4] Checking Zed binary..."
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  if [ ! -f "./zed-build/zed" ] || [ -n "${SKIP_DEV_RESTART:-}" ]; then
    echo "Building Zed in release mode..."
    if ! build-zed release; then
      echo "‚ùå Failed to build Zed"
      return 1
    fi
  else
    echo "‚úÖ Using existing Zed binary"
  fi
  echo ""

  # Step 2: Build helix-sway and export as tarball
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üìù [2/4] Building helix-sway and exporting tarball..."
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

  # Build helix-sway image (Sway + Zed desktop environment)
  echo "üî® Building helix-sway:latest..."

  # Get image hash BEFORE build (if image exists)
  HASH_BEFORE=$(docker images helix-sway:latest --format '{{.ID}}' 2>/dev/null || echo "")

  # Skip image transfer since we'll restart sandbox with new embedded tarball
  if ! SKIP_SWAY_TRANSFER=1 build-sway; then
    echo "‚ùå Failed to build helix-sway"
    return 1
  fi

  # Get image hash AFTER build
  HASH_AFTER=$(docker images helix-sway:latest --format '{{.ID}}')

  # Remove old compressed tarball if it exists (migrating to uncompressed)
  [ -f helix-sway.tar.gz ] && rm -f helix-sway.tar.gz helix-sway.tar.gz.hash

  # Compare hashes to detect if image actually changed
  if [ "$HASH_BEFORE" != "$HASH_AFTER" ]; then
    # Image changed - must export fresh tarball
    echo "üì¶ Exporting fresh helix-sway tarball (image hash changed: ${HASH_BEFORE:-none} -> $HASH_AFTER)..."
    # Tag with commit hash for versioning (in addition to :latest)
    docker tag helix-sway:latest helix-sway:${COMMIT_HASH}
    # Save with both tags so DinD gets versioned tag after load
    docker save helix-sway:latest helix-sway:${COMMIT_HASH} > helix-sway.tar
    TARBALL_SIZE=$(du -h helix-sway.tar | cut -f1)
    echo "$HASH_AFTER" > helix-sway.tar.hash
    echo "${COMMIT_HASH}" > helix-sway.version
    echo "‚úÖ Tarball created: helix-sway.tar ($TARBALL_SIZE) version=${COMMIT_HASH}"
  elif [ ! -f helix-sway.tar ]; then
    # Image unchanged but no tarball - create one
    echo "üì¶ Creating helix-sway tarball (image unchanged but tarball missing)..."
    docker tag helix-sway:latest helix-sway:${COMMIT_HASH}
    docker save helix-sway:latest helix-sway:${COMMIT_HASH} > helix-sway.tar
    TARBALL_SIZE=$(du -h helix-sway.tar | cut -f1)
    echo "$HASH_AFTER" > helix-sway.tar.hash
    echo "${COMMIT_HASH}" > helix-sway.version
    echo "‚úÖ Tarball created: helix-sway.tar ($TARBALL_SIZE) version=${COMMIT_HASH}"
  else
    # Image unchanged AND tarball exists - fast path!
    TARBALL_SIZE=$(du -h helix-sway.tar | cut -f1)
    # Update hash/version files if missing
    [ ! -f helix-sway.tar.hash ] && echo "$HASH_AFTER" > helix-sway.tar.hash
    [ ! -f helix-sway.version ] && echo "${COMMIT_HASH}" > helix-sway.version
    echo "‚úÖ Reusing existing tarball: helix-sway.tar ($TARBALL_SIZE) (image hash unchanged: $HASH_AFTER)"
  fi
  echo ""

  # Step 3: Build unified sandbox container with embedded tarball
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üìù [3/4] Building helix-sandbox container..."
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

  # Build sandbox with tarball embedded
  if [ -n "$GIT_TAG" ]; then
    echo "üè∑Ô∏è  Git tag detected: ${GIT_TAG}"
    docker build -f Dockerfile.sandbox \
      -t helix-sandbox:latest \
      -t "registry.helixml.tech/helix/helix-sandbox:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/helix-sandbox:${GIT_TAG}" \
      .
  else
    docker build -f Dockerfile.sandbox \
      -t helix-sandbox:latest \
      -t "registry.helixml.tech/helix/helix-sandbox:${COMMIT_HASH}" \
      .
  fi

  if [ $? -ne 0 ]; then
    echo "‚ùå Failed to build helix-sandbox container"
    rm -f helix-sway.tar
    return 1
  fi

  # Keep tarball for future builds (enables fast rebuilds when helix-sway is cached)
  # Only cleanup on failure or when explicitly requested
  echo "‚úÖ helix-sandbox container built successfully (kept helix-sway.tar for next build)"
  echo ""

  # Step 4: Restart sandbox and transfer fresh image
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üìù [4/4] Restarting sandbox container..."
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"

  # Restart to pick up new image (handled by existing code below)

  # Push to registry in production mode
  if [ -n "${PUSH_TO_REGISTRY:-}" ]; then
    echo "üì§ Pushing sandbox image to registry..."

    # Push helix-sandbox (contains Wolf + Moonlight Web + helix-sway tarball)
    local SANDBOX_BASE="registry.helixml.tech/helix/helix-sandbox"
    if push_image_tags "$SANDBOX_BASE"; then
      echo "‚úÖ Sandbox images pushed successfully"
    else
      echo "‚ö†Ô∏è  Failed to push sandbox images"
      return 1
    fi

    echo "üì¶ Registry images pushed (helix-sway is embedded, not pushed separately)"
  fi

  # Restart sandbox in dev mode
  if [ -z "${SKIP_DEV_RESTART:-}" ]; then
    echo "üîÑ Restarting sandbox container with updated image..."
    docker compose -f docker-compose.dev.yaml rm -f sandbox
    docker compose -f docker-compose.dev.yaml up -d sandbox

    echo "‚úÖ Sandbox container rebuilt and restarted successfully"
  fi

  echo ""
  echo "üì¶ Unified sandbox ready: helix-sandbox:latest"
  echo ""
  echo "Components included:"
  echo "  ‚Ä¢ Wolf (streaming platform)"
  echo "  ‚Ä¢ Moonlight Web (WebRTC browser streaming)"
  echo "  ‚Ä¢ RevDial client (control plane connection)"
  echo "  ‚Ä¢ Docker-in-Docker (Wolf's isolated dockerd)"
  echo "  ‚Ä¢ helix-sway image (pre-loaded tarball: $TARBALL_SIZE)"
  echo ""
  echo "Services managed by GOW's init system:"
  echo "  ‚Ä¢ 04-start-dockerd.sh - starts Wolf's dockerd + loads helix-sway"
  echo "  ‚Ä¢ 05-init-wolf-config.sh - initializes Wolf config"
  echo "  ‚Ä¢ 06-init-moonlight-config.sh - initializes Moonlight Web"
  echo "  ‚Ä¢ 07-start-moonlight-web.sh - starts Moonlight Web daemon"
  echo "  ‚Ä¢ 08-start-revdial-client.sh - starts RevDial daemon (if configured)"
  echo "  ‚Ä¢ startup-app.sh - starts Wolf as main process"
  echo ""
  echo "üéâ Sandbox build completed successfully!"
}

# NOTE: This function requires specific branches to be checked out in dependency repositories:
# - wolf: wolf-ui-working (adds client_unique_id for secure auto-join)
# - moonlight-web-stream: feature/kickoff (threads Wolf client_id through stack)
# - zed: feature/external-thread-sync (external agent WebSocket sync support)
# Verify branches before running: cd ../wolf && git branch --show-current
function build-and-push-helix-code() {
  # Optional: pass a tag override as first argument to force tagging even if commit doesn't match
  local TAG_OVERRIDE="${1:-}"

  echo "üöÄ Building and pushing Helix Code components for production deployment"
  echo "========================================================================"
  echo ""
  echo "Note: API and Frontend are built by CI - this builds Wolf, Zed Agent, Moonlight Web, and Sandbox"
  echo ""

  # Enable image pushing to registry for production builds
  export PUSH_TO_REGISTRY=1
  # Skip dev service restarts during production builds
  export SKIP_DEV_RESTART=1

  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")
  local BUILD_START=$(date +%s)
  local FAILED_BUILDS=()

  # Allow tag override for building specific tags even if commit doesn't exactly match
  if [ -n "$TAG_OVERRIDE" ]; then
    echo "‚ö†Ô∏è  Tag override: ${TAG_OVERRIDE} (ignoring git tag check)"
    GIT_TAG="$TAG_OVERRIDE"
  fi

  # Export GIT_TAG so build-sandbox and other functions can use it
  export GIT_TAG

  echo "üìù Commit hash: ${COMMIT_HASH}"
  if [ -n "$GIT_TAG" ]; then
    echo "üè∑Ô∏è  Git tag: ${GIT_TAG}"
  fi
  echo "üìÖ Build started: $(date)"
  echo ""

  # Track build status
  # Note: helix-sway (Zed agent) is built as part of build-sandbox, not separately
  local TOTAL_BUILDS=3
  local COMPLETED_BUILDS=0

  # 1. Build Wolf
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üì¶ [1/$TOTAL_BUILDS] Building Wolf streaming platform..."
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  if build-wolf; then
    echo "‚úÖ Wolf built and pushed successfully"
    COMPLETED_BUILDS=$((COMPLETED_BUILDS + 1))
  else
    echo "‚ùå Failed to build Wolf"
    FAILED_BUILDS+=("wolf")
  fi
  echo ""

  # 2. Build Moonlight Web
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üì¶ [2/$TOTAL_BUILDS] Building Moonlight Web..."
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  if build-moonlight-web; then
    echo "‚úÖ Moonlight Web built and pushed successfully"
    COMPLETED_BUILDS=$((COMPLETED_BUILDS + 1))
  else
    echo "‚ùå Failed to build Moonlight Web"
    FAILED_BUILDS+=("moonlight-web")
  fi
  echo ""

  # 3. Build unified Sandbox (Wolf + Moonlight Web + Sway/Zed + RevDial + DinD)
  # Note: This also builds helix-sway (Zed agent) and embeds it as a tarball
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  echo "üì¶ [3/$TOTAL_BUILDS] Building unified Sandbox container (includes Sway/Zed)..."
  echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
  if build-sandbox; then
    echo "‚úÖ Sandbox built and pushed successfully"
    COMPLETED_BUILDS=$((COMPLETED_BUILDS + 1))
  else
    echo "‚ùå Failed to build Sandbox"
    FAILED_BUILDS+=("sandbox")
  fi
  echo ""

  # Build summary
  local BUILD_END=$(date +%s)
  local BUILD_DURATION=$((BUILD_END - BUILD_START))
  local BUILD_MINUTES=$((BUILD_DURATION / 60))
  local BUILD_SECONDS=$((BUILD_DURATION % 60))

  echo "=========================================================================="
  echo "üéâ Build Summary"
  echo "=========================================================================="
  echo "üìä Completed: ${COMPLETED_BUILDS}/${TOTAL_BUILDS} builds"
  echo "‚è±Ô∏è  Duration: ${BUILD_MINUTES}m ${BUILD_SECONDS}s"
  echo "üìù Commit: ${COMMIT_HASH}"
  echo "üè∑Ô∏è  Registry: registry.helixml.tech/helix/"
  echo ""

  if [ ${#FAILED_BUILDS[@]} -eq 0 ]; then
    echo "‚úÖ All images built and pushed successfully!"
    echo ""
    echo "üì¶ Production images ready (commit: ${COMMIT_HASH}):"
    echo "   ‚Ä¢ registry.helixml.tech/helix/helix-sandbox:${COMMIT_HASH}"
    echo ""
    echo "üìù Note: helix-sandbox contains Wolf + Moonlight Web + helix-sway (all embedded)"
    if [ -n "$GIT_TAG" ]; then
      echo ""
      echo "üì¶ Also tagged with git tag (${GIT_TAG}):"
      echo "   ‚Ä¢ registry.helixml.tech/helix/helix-sandbox:${GIT_TAG}"
    fi
    echo ""
    echo "üöÄ Ready for production deployment!"
    echo ""
    echo "Note: API and Frontend images are built by CI and available at:"
    echo "   ‚Ä¢ registry.helixml.tech/helix/api:${COMMIT_HASH}"
    echo "   ‚Ä¢ registry.helixml.tech/helix/frontend:${COMMIT_HASH}"
    return 0
  else
    echo "‚ö†Ô∏è  Some builds failed:"
    for failed in "${FAILED_BUILDS[@]}"; do
      echo "   ‚úó ${failed}"
    done
    echo ""
    echo "Please review the errors above and retry failed builds individually."
    return 1
  fi
}

function db() {
  local subcommand="${1-cli}"
  shift
  local containername="${1-postgres}"
  shift
  if [[ "$subcommand" == "cli" ]]; then
    docker compose -f docker-compose.dev.yaml exec $containername psql --user postgres "$@"
  elif [[ "$subcommand" == "pipe" ]]; then
    docker compose -f docker-compose.dev.yaml exec -T $containername psql --user postgres "$@"
  fi
}

# Regenerate test mocks
function generate() {
  go generate ./...
}

function psql() {
  db cli postgres "$@"
}

function psql_pipe() {
  db pipe postgres "$@"
}

function pgvector() {
  db cli pgvector "$@"
}

function pgvector_pipe() {
  db pipe pgvector "$@"
}

function list-slots() {
  echo "SELECT * FROM runner_slots ORDER BY created DESC;" | db pipe postgres
}

function slots() {
  echo "Formatted view of all slots:"
  echo "SELECT
    id,
    runner_id,
    model,
    runtime,
    active,
    ready,
    status,
    created::timestamp(0) as created,
    updated::timestamp(0) as updated
  FROM runner_slots
  ORDER BY created DESC;" | db pipe postgres
}

function active-slots() {
  echo "Active slots only:"
  echo "SELECT
    id,
    runner_id,
    model,
    runtime,
    status,
    created::timestamp(0) as created
  FROM runner_slots
  WHERE active = true
  ORDER BY created DESC;" | db pipe postgres
}

function slot-stats() {
  echo "Slot statistics:"
  echo "SELECT
    runner_id,
    COUNT(*) as total_slots,
    COUNT(CASE WHEN active = true THEN 1 END) as active_slots,
    COUNT(CASE WHEN active = false THEN 1 END) as inactive_slots
  FROM runner_slots
  GROUP BY runner_id
  ORDER BY total_slots DESC;" | db pipe postgres
}

function wipe-slots() {
  echo "üßπ Wiping all slots from database..."
  echo "DELETE FROM runner_slots;" | db pipe postgres
  echo "‚úÖ All slots have been deleted from the database."
}

function install() {
  go install ./api/..
}

function update_openapi() {
	echo "üîÑ Installing swag..."
	go install github.com/swaggo/swag/cmd/swag@v1.16.4 || {
		echo "‚ùå Failed to install swag"
		return 1
	}

	echo "üîÑ Generating swagger documentation..."
	swag init -g api/pkg/server/swagger.go \
		--parseDependency --parseInternal --parseDepth 3 \
		-o api/pkg/server || {
		echo "‚ùå CRITICAL: Swagger generation FAILED"
		echo "Check for ParseComment errors above"
		return 1
	}

	# Verify swagger files were created
	if [[ ! -f "api/pkg/server/swagger.json" ]]; then
		echo "‚ùå CRITICAL: swagger.json was not generated"
		return 1
	fi

	echo "‚úÖ Swagger generated successfully"
	echo "üìã Copying swagger to frontend..."
	cp -r api/pkg/server/swagger.yaml frontend/swagger/ || {
		echo "‚ùå Failed to copy swagger.yaml"
		return 1
	}

	echo "üîÑ Generating TypeScript client..."
	npx swagger-typescript-api@13.0.23 -p ./frontend/swagger/swagger.yaml -o ./frontend/src/api --axios -n api.ts || {
		echo "‚ùå TypeScript client generation FAILED"
		return 1
	}

	echo "‚úÖ OpenAPI update complete"
}

function lint() {
        golangci-lint run
}

# Before running this, ensure Postgres port is open (5432) for local connections
# and that API server is stopped (if you started it with ./stack up)
function test-integration() {
  cd integration-test/api && go test -v "$@"
}

# Examples:
# Run all tests:                    ./stack test
# Run specific tests:               ./stack test ./api/pkg/oauth_test
# Run a single test:                ./stack test ./api/pkg/oauth_test -run TestOAuthAppIDPropagationProduction

function ollama-sync() {
  local OLLAMA_PATH="../ollama"
  local TARGET_DIR="api/pkg/ollamav11"

  # Check if we're in the right directory (should have api/ subdirectory)
  if [[ ! -d "api" ]]; then
    echo "Error: Must run from the root of the helix repository"
    echo "Expected to find 'api/' directory in current path"
    exit 1
  fi

  if [[ ! -d "$OLLAMA_PATH" ]]; then
    echo "Error: Ollama repository not found at $OLLAMA_PATH"
    echo "Expected ollama to be checked out as a sibling directory to helix"
    exit 1
  fi

  # Check that ollama is on a release tag
  echo "Checking Ollama version..."
  if [[ ! -d "$OLLAMA_PATH/.git" ]]; then
    echo "Error: $OLLAMA_PATH is not a git repository"
    exit 1
  fi

  local OLLAMA_TAG=$(cd "$OLLAMA_PATH" && git describe --exact-match --tags HEAD 2>/dev/null)
  if [[ -z "$OLLAMA_TAG" ]]; then
    local CURRENT_COMMIT=$(cd "$OLLAMA_PATH" && git rev-parse --short HEAD)
    echo "Error: Ollama is not checked out on a release tag"
    echo "Current commit: $CURRENT_COMMIT"
    echo "Please checkout a specific release tag (e.g., v0.11.4) before syncing"
    echo "Example: cd $OLLAMA_PATH && git checkout v0.11.4"
    exit 1
  fi

  echo "‚úÖ Ollama is on release tag: $OLLAMA_TAG"
  echo "Syncing Ollama memory estimation files..."

  # Clean out target directory first to avoid stale files
  if [[ -d "$TARGET_DIR" ]]; then
    echo "Cleaning existing target directory..."
    rm -rf "$TARGET_DIR"
  fi

  # Create target directory
  mkdir -p "$TARGET_DIR"

  # Copy core memory estimation files
  echo "Copying memory estimation files..."
  cp "$OLLAMA_PATH/llm/memory.go" "$TARGET_DIR/"

  # Copy GGML/GGUF parsing files
  echo "Copying GGML/GGUF files..."
  cp -r "$OLLAMA_PATH/fs/ggml" "$TARGET_DIR/"
  cp -r "$OLLAMA_PATH/fs/gguf" "$TARGET_DIR/"

  # Copy supporting files
  echo "Copying supporting files..."
  cp -r "$OLLAMA_PATH/discover" "$TARGET_DIR/"
  cp "$OLLAMA_PATH/api/types.go" "$TARGET_DIR/api_types.go"
  cp "$OLLAMA_PATH/envconfig/config.go" "$TARGET_DIR/envconfig.go"
  cp "$OLLAMA_PATH/format/bytes.go" "$TARGET_DIR/format.go"
  cp -r "$OLLAMA_PATH/fs/util" "$TARGET_DIR/"

  # Transform imports to use local versions
  echo "Transforming imports for local use..."

  # Transform package declarations to avoid import cycle
  sed -i 's|package llm|package ollamav11|g' "$TARGET_DIR/memory.go"
  sed -i 's|package api|package ollamav11|g' "$TARGET_DIR/api_types.go"
  sed -i 's|package envconfig|package ollamav11|g' "$TARGET_DIR/envconfig.go"
  sed -i 's|package format|package ollamav11|g' "$TARGET_DIR/format.go"

  # Transform imports in memory.go - avoid self-imports by removing local package imports
  sed -i 's|"github.com/ollama/ollama/api"|.|g' "$TARGET_DIR/memory.go"
  sed -i 's|"github.com/ollama/ollama/discover"|"github.com/helixml/helix/api/pkg/ollamav11/discover"|g' "$TARGET_DIR/memory.go"
  sed -i 's|"github.com/ollama/ollama/envconfig"|.|g' "$TARGET_DIR/memory.go"
  sed -i 's|"github.com/ollama/ollama/format"|.|g' "$TARGET_DIR/memory.go"
  sed -i 's|"github.com/ollama/ollama/fs/ggml"|"github.com/helixml/helix/api/pkg/ollamav11/ggml"|g' "$TARGET_DIR/memory.go"

  # Remove the dot imports that were created (they'll use local functions)
  sed -i '/^\s*\.\s*$/d' "$TARGET_DIR/memory.go"

  # Transform imports in subdirectories
  find "$TARGET_DIR/ggml" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/fs/gguf"|"github.com/helixml/helix/api/pkg/ollamav11/gguf"|g' {} \;
  find "$TARGET_DIR/ggml" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/fs/util/bufioutil"|"github.com/helixml/helix/api/pkg/ollamav11/util/bufioutil"|g' {} \;
  find "$TARGET_DIR/gguf" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/fs/ggml"|"github.com/helixml/helix/api/pkg/ollamav11/ggml"|g' {} \;
  find "$TARGET_DIR/discover" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/envconfig"|"github.com/helixml/helix/api/pkg/ollamav11"|g' {} \;
  find "$TARGET_DIR/discover" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/format"|"github.com/helixml/helix/api/pkg/ollamav11"|g' {} \;

  echo "Import transformations complete. You can now create type adapters manually."

  # Create sync info file
  cat > "$TARGET_DIR/SYNC_INFO.md" << EOF
# Ollama Memory Estimation Sync

**Synced from:** $OLLAMA_PATH
**Ollama version:** $OLLAMA_TAG
**Sync date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")

## Files synced:
- llm/memory.go ‚Üí memory.go
- fs/ggml/ ‚Üí ggml/
- fs/gguf/ ‚Üí gguf/
- discover/ ‚Üí discover/
- api/types.go ‚Üí api_types.go
- envconfig/config.go ‚Üí envconfig.go
- format/bytes.go ‚Üí format.go
- fs/util/ ‚Üí util/

## Next steps:
1. Create type adapters to convert Helix types to Ollama types
2. Modify imports in copied files to use local versions
3. Use exact Ollama EstimateGPULayers function with adapted types

## Important:
This sync was done against Ollama $OLLAMA_TAG. If Ollama is updated,
re-run './stack ollama-sync' to get the latest memory estimation algorithms.
EOF

  echo "‚úÖ Ollama files synced to $TARGET_DIR"
  echo "üìÑ See $TARGET_DIR/SYNC_INFO.md for details"
  echo ""
  echo "Next steps:"
  echo "1. Create type adapters in api/pkg/memory/ollama_wrapper.go"
  echo "2. Update imports in copied files to use local versions"
  echo "3. Test with exact Ollama memory estimation algorithm"
}

function test() {
  # Ingest env variables from .env file
  set -a
  source .env
  set +a

  # Check whether environment variables are set. If not, error
  if [[ -z "$TOGETHER_API_KEY" ]]; then
    echo "TOGETHER_API_KEY is not set"
    exit 1
  fi
  if [[ -z "$TOGETHER_BASE_URL" ]]; then
    echo "TOGETHER_BASE_URL is not set"
    exit 1
  fi

  # Ensure postgres, tika, typesense and chrome are running
  docker compose -f docker-compose.dev.yaml up -d postgres tika typesense chrome pgvector keycloak

  # Database config (running in a sidecar)
  export POSTGRES_USER=postgres
  export POSTGRES_PASSWORD=postgres
  export POSTGRES_DATABASE=postgres
  export POSTGRES_HOST=localhost

  export KEYCLOAK_USER=admin
  export KEYCLOAK_PASSWORD=oh-hallo-insecure-password

  export PGVECTOR_USER=postgres
  export PGVECTOR_PASSWORD=postgres
  export PGVECTOR_DATABASE=postgres
  export PGVECTOR_HOST=localhost
  export PGVECTOR_PORT=5433

  export TYPESENSE_URL=http://localhost:8108
  export TYPESENSE_API_KEY=typesense
  export TEXT_EXTRACTION_TIKA_URL=http://localhost:9998
  export RAG_CRAWLER_LAUNCHER_URL=http://localhost:7317

  # To debug test hangs, try this:
  # Run tests one at a time and show which test is running

  # If a test path is provided, run tests from that path,
  # otherwise run all tests
  if [[ $# -gt 0 ]]; then
    echo "Running tests from path: $1"
    go test -v -p 1 "$@" 2>&1 | sed -u 's/^/[TEST] /'
  else
    echo "Running all tests"
    go test -v -p 1 ./... 2>&1 | sed -u 's/^/[TEST] /'
  fi
}

function zed-test() {
  echo "Testing Zed with External WebSocket Thread Sync..."

  if [ ! -f "./zed-build/zed" ]; then
    echo "‚ùå Zed binary not found. Run: ./stack build-zed"
    return 1
  fi

  echo "üß™ Running basic tests..."

  # Test 1: Binary execution
  if ./zed-build/zed --version > /dev/null 2>&1; then
    echo "‚úÖ Zed binary executes successfully"
  else
    echo "‚ùå Zed binary failed to execute"
    return 1
  fi

  # Test 2: Check for external sync feature
  if strings ./zed-build/zed | grep -q "external_websocket_sync"; then
    echo "‚úÖ External WebSocket Thread Sync feature detected"
  else
    echo "‚ö†Ô∏è  External WebSocket Thread Sync not clearly detectable"
  fi

  echo "üéâ Basic Zed tests passed!"
  echo ""
  echo "For full integration testing:"
  echo "  1. Start Zed: RUST_LOG=external_websocket_sync=debug ./zed-build/zed"
  echo "  2. Open a project folder"
  echo "  3. Test API: curl http://localhost:3030/health"
}

function help() {
  echo "Helix Stack Management Tool"
  echo ""
  echo "Available commands:"
  echo "  build              - Build docker containers (optionally with WITH_RUNNER or WITH_DEMOS)"
  echo "  build-runner       - Build the helix-runner binary locally"
  echo "  build-runner-image - Build the runner Docker image (includes ROCm vLLM)"
  echo "  static-compile     - Build static Go binary"
  echo "  start              - Start the development environment with tmux"
  echo "  stop               - Stop docker containers"
  echo "  mock-runner        - Start a mock runner for testing"
  echo "  up [services]      - Start specific docker services"
  echo "  rebuild [services] - Rebuild and start specific docker services"
  echo ""
  echo "Production build commands:"
  echo "  build-and-push-helix-code [tag] - Build ALL Helix Code images and push to registry (optional tag override)"
  echo "  build-sandbox      - Build unified sandbox container (Wolf + Moonlight Web + RevDial + DinD)"
  echo "  build-wolf         - Build Wolf container with latest source code"
  echo "  build-xfce         - Build custom XFCE container with passwordless sudo"
  echo "  build-sway         - Build Sway+Zed container image and push to registry (builds Zed if needed)"
  echo "  build-moonlight-web - Build Moonlight Web container and push to registry"
  echo ""
  echo "Zed Agent commands:"
  echo "  build-zed [dev|release] - Build Zed binary (stripped in release mode)"
  echo "  build-zed-agent    - Build Zed agent Docker image"
  echo "  zed-agent-up       - Start Zed agent services"
  echo "  zed-agent-down     - Stop Zed agent services"
  echo "  zed-agent-logs [service] - View Zed agent logs"
  echo "  zed-test           - Test Zed binary functionality"
  echo ""
  echo "Database commands:"
  echo "  db [cli|pipe] [postgres|pgvector] - Access database"
  echo "  psql               - PostgreSQL CLI"
  echo "  pgvector           - PGVector CLI"
  echo "  list-slots         - List all runner slots"
  echo "  slots              - Formatted view of all slots"
  echo "  active-slots       - Show only active slots"
  echo "  slot-stats         - Show slot statistics"
  echo "  wipe-slots         - Delete all slots from database"
  echo ""
  echo "Development commands:"
  echo "  generate           - Generate test mocks"
  echo "  update_openapi     - Update OpenAPI documentation"
  echo "  lint               - Run linter"
  echo "  test [path]        - Run tests"
  echo "  test-integration   - Run integration tests"
  echo "  ollama-sync        - Sync Ollama memory estimation files"
  echo ""
  echo "Environment variables:"
  echo "  WITH_RUNNER=1      - Include runner containers"
  echo "  WITH_DEMOS=1       - Include demo containers"
  echo "  FORCE_CPU=1        - Force CPU-only mode"
  echo "  WIPE_SLOTS=1       - Wipe database slots on start"
  echo "  STOP_KEYCLOAK=1    - Stop Keycloak when stopping"
  echo "  STOP_POSTGRES=1    - Stop PostgreSQL when stopping"
  echo "  STOP_PGVECTOR=1    - Stop PGVector when stopping"
}

# Show help if no arguments provided
if [[ $# -eq 0 ]]; then
  help
  exit 0
fi

eval "$@"
