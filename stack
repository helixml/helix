#!/usr/bin/env bash
set -euo pipefail
IFS=$'\n\t'

export DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
export HELIX_HOST_HOME="$DIR"
export TMUX_SESSION=${TMUX_SESSION:="helix"}
export WITH_RUNNER=${WITH_RUNNER:=""}
export WITH_DEMOS=${WITH_DEMOS:=""}
export STOP_KEYCLOAK=${STOP_KEYCLOAK:=""}
export STOP_POSTGRES=${STOP_POSTGRES:=""}
export STOP_PGVECTOR=${STOP_PGVECTOR:=""}
export WIPE_SLOTS=${WIPE_SLOTS:="0"}
export COMPOSE_PROFILES=${COMPOSE_PROFILES:=""}

# Helper function to check for GPU and set appropriate runner profile
function setup_runner_profile() {
  export FORCE_CPU=${FORCE_CPU:=""}

  if [[ -n "$FORCE_CPU" ]]; then
    # Forced CPU mode
    echo "ğŸ’» FORCE_CPU is set, forcing CPU mode regardless of GPU detection"
    export RUNNER_CONTAINER="runner"
    export RUNNER_PROFILE="--profile runner"
    export DEV_CPU_ONLY_CMD="DEVELOPMENT_CPU_ONLY=true "
    export VLLM_ENV_VARS="VLLM_DEVICE=cpu VLLM_LOGGING_LEVEL=DEBUG"
  elif command -v nvidia-smi &> /dev/null && nvidia-smi &> /dev/null; then
    # NVIDIA GPU mode
    echo "ğŸš€ NVIDIA GPU detected, using GPU support"
    export RUNNER_CONTAINER="runner_gpu"
    export RUNNER_PROFILE="--profile runner_gpu"
    export DEV_CPU_ONLY_CMD=""
    export VLLM_ENV_VARS=""
  elif [[ -e "/dev/kfd" ]] && [[ -d "/dev/dri" ]] && command -v lspci &> /dev/null && lspci | grep -iE "(VGA|3D|Display).*AMD" &> /dev/null; then
    # AMD GPU mode (ROCm)
    echo "ğŸš€ AMD GPU detected (ROCm), using AMD GPU support"
    export RUNNER_CONTAINER="runner_gpu_amd"
    export RUNNER_PROFILE="--profile runner_gpu_amd"
    export DEV_CPU_ONLY_CMD=""
    export VLLM_ENV_VARS=""
  else
    # CPU mode (fallback)
    echo "âŒ No supported GPU detected, running without GPU support"
    export RUNNER_CONTAINER="runner"
    export RUNNER_PROFILE="--profile runner"
    export DEV_CPU_ONLY_CMD="DEVELOPMENT_CPU_ONLY=true "
    export VLLM_ENV_VARS="VLLM_DEVICE=cpu VLLM_LOGGING_LEVEL=DEBUG"
  fi
}

# Helper function to determine sandbox service and container names based on COMPOSE_PROFILES
# Sets SANDBOX_SERVICE (docker-compose service name) and SANDBOX_CONTAINER (docker container name)
function get_sandbox_names() {
  local profile="${COMPOSE_PROFILES:-}"
  if [[ "$profile" == *"code-software"* ]]; then
    export SANDBOX_SERVICE="sandbox-software"
    export SANDBOX_CONTAINER="helix-sandbox-software-1"
  elif [[ "$profile" == *"code-amd-intel"* ]]; then
    export SANDBOX_SERVICE="sandbox-amd-intel"
    export SANDBOX_CONTAINER="helix-sandbox-amd-intel-1"
  else
    # Default to NVIDIA (code-nvidia profile)
    export SANDBOX_SERVICE="sandbox-nvidia"
    export SANDBOX_CONTAINER="helix-sandbox-nvidia-1"
  fi
}

# Helper function to detect GPU type and set appropriate sandbox profile
# Sets COMPOSE_PROFILES to include 'code-nvidia' (NVIDIA) or 'code-amd-intel' (AMD/Intel) if not already set
function setup_sandbox_profile() {
  # Check if COMPOSE_PROFILES was explicitly set to a non-empty value in environment
  # (empty string triggers auto-detection, non-empty respects user's choice)
  local env_was_set=""
  if [[ -n "${COMPOSE_PROFILES:-}" ]]; then
    env_was_set="true"
  fi

  # Load existing .env if present
  if [[ -f "$DIR/.env" ]]; then
    source "$DIR/.env"
  fi

  # Stop conflicting sandbox containers before starting
  # All sandbox variants use the same static IP (172.19.0.50), so only one can run at a time
  # Silently remove any sandbox containers that might conflict with the one we're about to start
  local current_profile="${COMPOSE_PROFILES:-}"
  if [[ "$current_profile" == *"code-software"* ]]; then
    # Starting software sandbox - stop GPU sandboxes
    docker rm -f helix-sandbox-nvidia-1 helix-sandbox-amd-intel-1 2>/dev/null || true
  elif [[ "$current_profile" == *"code-amd-intel"* ]]; then
    # Starting AMD/Intel sandbox - stop other sandboxes
    docker rm -f helix-sandbox-nvidia-1 helix-sandbox-software-1 2>/dev/null || true
  else
    # Starting NVIDIA sandbox (default) - stop other sandboxes
    docker rm -f helix-sandbox-software-1 helix-sandbox-amd-intel-1 2>/dev/null || true
  fi

  # If COMPOSE_PROFILES was set in environment before .env (even to empty), respect it
  if [[ "$env_was_set" == "true" ]]; then
    echo "ğŸ® Using COMPOSE_PROFILES from environment: '${COMPOSE_PROFILES:-<empty>}'"
    get_sandbox_names
    return
  fi

  # If COMPOSE_PROFILES is explicitly set in .env (even to empty), respect it
  if [[ -f "$DIR/.env" ]] && grep -q "^COMPOSE_PROFILES=" "$DIR/.env"; then
    echo "ğŸ® Using COMPOSE_PROFILES from .env: '${COMPOSE_PROFILES:-<empty>}'"
    get_sandbox_names
    return
  fi

  # Auto-detect GPU type
  local gpu_profile=""

  # Check for NVIDIA GPU first
  if command -v nvidia-smi &> /dev/null && nvidia-smi &> /dev/null; then
    gpu_profile="code-nvidia"
    echo "ğŸ® NVIDIA GPU detected, using 'code-nvidia' sandbox profile"
  # Check for AMD GPU (ROCm)
  elif [[ -e "/dev/kfd" ]] && [[ -d "/dev/dri" ]] && command -v lspci &> /dev/null && lspci | grep -iE "(VGA|3D|Display).*AMD" &> /dev/null; then
    gpu_profile="code-amd-intel"
    echo "ğŸ® AMD GPU detected (ROCm), using 'code-amd-intel' sandbox profile"
  # Check for Intel GPU (or generic /dev/dri)
  elif [[ -d "/dev/dri" ]] && [[ -n "$(ls -A /dev/dri 2>/dev/null)" ]]; then
    gpu_profile="code-amd-intel"  # Intel uses same profile as AMD (no nvidia runtime)
    echo "ğŸ® Intel/Generic GPU detected, using 'code-amd-intel' sandbox profile"
  else
    echo "âš ï¸  No GPU detected, sandbox features may not work"
    get_sandbox_names
    return
  fi

  # Add to COMPOSE_PROFILES if we detected a GPU
  if [[ -n "$gpu_profile" ]]; then
    if [[ -n "${COMPOSE_PROFILES:-}" ]]; then
      export COMPOSE_PROFILES="${COMPOSE_PROFILES},${gpu_profile}"
    else
      export COMPOSE_PROFILES="$gpu_profile"
    fi
    echo "ğŸ“‹ COMPOSE_PROFILES set to: $COMPOSE_PROFILES"
  fi

  # Set sandbox service/container names based on profile
  get_sandbox_names
}

function mock-runner() {
  echo "ğŸ”¨ Building helix-runner binary for mock runner..."
  build-runner || return 1

  echo "ğŸš€ Starting mock runner..."
  ./helix-runner \
    --mock-runner \
    --server-port 8090 \
    --api-host http://localhost:8080 \
    --api-token oh-hallo-insecure-token \
    --memory 24GB \
    --runner-id mock \
    --label gpu=4090 "$@"
}


function build() {
  # First detect GPU and set variables
  setup_runner_profile

  if [[ -n "$WITH_RUNNER" ]]; then
    # Check for Zed dependency and build if needed
    if [ ! -d "../zed" ]; then
      echo "âŒ ERROR: Zed source code not found at ../zed/"
      echo ""
      echo "The Zed runner requires the Zed source code to be checked out alongside Helix."
      echo ""
      echo "Please run:"
      echo "  cd .."
      echo "  git clone https://github.com/helixml/zed.git"
      echo "  cd helix"
      echo "  WITH_RUNNER=1 ./stack build"
      exit 1
    fi

    if [ ! -f "./zed-build/zed" ]; then
      echo "ğŸ”¨ Zed binary not found, building automatically..."
      build-zed || {
        echo "âŒ Failed to build Zed. Please check the error messages above."
        echo "Note: Rust/Cargo is required to build Zed. Install from: https://rustup.rs/"
        exit 1
      }
    fi

    echo "ğŸ”¨ Building runner: $RUNNER_CONTAINER"
    docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" build
    return
  fi

  if [[ -n "$WITH_DEMOS" ]]; then
    echo "ğŸ”¨ Building demos"
    docker compose -f docker-compose.dev.yaml --profile demos build
    return
  fi

  # No profiles specified, just build everything
  echo "ğŸ”¨ Building all services"
  docker compose -f docker-compose.dev.yaml build
}

function static-compile() {
  export CGO_ENABLED=0
  go build -ldflags '-extldflags "-static"' -o helix .
}

function build-runner() {
  echo "ğŸ”¨ Building helix-runner binary..."
  export CGO_ENABLED=1
  local APP_VERSION=${APP_VERSION:-"v0.0.0+dev"}

  if go build -buildvcs=false -tags '!rocm' -ldflags '-s -w -X github.com/helixml/helix/api/pkg/data.Version='$APP_VERSION -o helix-runner ./runner-cmd/helix-runner; then
    echo "âœ… Successfully built helix-runner binary"
  else
    echo "âŒ Failed to build helix-runner binary"
    return 1
  fi
}

function build-runner-image() {
  echo "ğŸ³ Building runner Docker image..."
  local IMAGE_TAG="${1:-test}"
  local APP_VERSION=$(git rev-parse HEAD 2>/dev/null || echo "v0.0.0+dev")
  # Base image tag - default to latest-empty for fast test builds (skips ~16GB download)
  # Use 'latest-small' for production builds that need full base image
  local BASE_TAG="${2:-latest-empty}"

  echo "  Output: registry.helixml.tech/helix/runner:$IMAGE_TAG"
  echo "  Base: registry.helixml.tech/helix/runner-base:$BASE_TAG"
  echo "  Version: $APP_VERSION"
  echo "  Note: ROCm vLLM build takes ~10 minutes"
  echo ""

  docker build \
    -f Dockerfile.runner \
    --build-arg TAG="$BASE_TAG" \
    --build-arg APP_VERSION="$APP_VERSION" \
    -t "registry.helixml.tech/helix/runner:$IMAGE_TAG" \
    .
}

function build-zed() {
  echo "ğŸ”¨ Building Zed with External WebSocket Thread Sync..."

  local ZED_SOURCE_DIR="../zed"
  local ZED_OUTPUT_DIR="./zed-build"
  local BUILD_TYPE="${1:-dev}"

  # Validate build type
  if [[ "$BUILD_TYPE" != "dev" && "$BUILD_TYPE" != "release" ]]; then
    echo "âŒ Error: BUILD_TYPE must be 'dev' or 'release'"
    echo "Usage: ./stack build-zed [dev|release]"
    echo ""
    echo "Build types:"
    echo "  dev     - Fast incremental builds with debug symbols (default)"
    echo "  release - Optimized production builds (slower, ~3-5 minutes)"
    return 1
  fi

  # Check if Zed source directory exists
  if [ ! -d "$ZED_SOURCE_DIR" ]; then
    echo "âŒ Zed source directory not found at: $ZED_SOURCE_DIR"
    echo "Expected directory structure:"
    echo "  helix/                 (current directory)"
    echo "  zed/                   (Zed fork with external_websocket_sync)"
    return 1
  fi

  # Check if external_websocket_sync exists in Zed source
  if [ ! -d "$ZED_SOURCE_DIR/crates/external_websocket_sync" ]; then
    echo "âŒ external_websocket_sync crate not found in Zed source"
    echo "Make sure you're using the Zed fork with External WebSocket Thread Sync"
    return 1
  fi

  # Check if Rust is installed
  if ! command -v cargo &> /dev/null; then
    echo "âŒ Rust/Cargo not found. Please install Rust first."
    echo "Install Rust: https://rustup.rs/"
    return 1
  fi

  # Create output directory
  mkdir -p "$ZED_OUTPUT_DIR"

  # Change to Zed source directory
  cd "$ZED_SOURCE_DIR"

  echo "ğŸ”¨ Building Zed with External WebSocket Thread Sync..."
  echo "Source directory: $(pwd)"
  echo "Build type: $BUILD_TYPE"

  # Build Zed based on build type
  if [ "$BUILD_TYPE" = "release" ]; then
    echo "ğŸ”¨ Building in release mode (optimized, stripped, slower build)..."
    # Use RUSTFLAGS to enable stripping during build (better than post-build strip)
    if RUSTFLAGS="-C link-arg=-s" RUST_LOG=info cargo build --release --features external_websocket_sync; then
      BINARY_PATH="target/release/zed"
    else
      echo "âŒ Zed release build failed"
      cd - > /dev/null
      return 1
    fi
  else
    echo "ğŸ”¨ Building in dev mode (fast incremental builds with debug symbols)..."
    if RUST_LOG=info cargo build --features external_websocket_sync; then
      BINARY_PATH="target/debug/zed"
    else
      echo "âŒ Zed dev build failed"
      cd - > /dev/null
      return 1
    fi
  fi

  # Check if build was successful
  if [ ! -f "$BINARY_PATH" ]; then
    echo "âŒ Build failed: Binary not found at $BINARY_PATH"
    cd - > /dev/null
    return 1
  fi

  echo "âœ… Zed compilation completed successfully"

  # Copy binary to output directory (atomic rename to avoid "text file busy")
  cd - > /dev/null
  cp "$ZED_SOURCE_DIR/$BINARY_PATH" "$ZED_OUTPUT_DIR/zed.new"
  chmod +x "$ZED_OUTPUT_DIR/zed.new"

  # Atomic rename (works even if old binary is in use by running containers)
  if [ -f "$ZED_OUTPUT_DIR/zed" ]; then
    mv "$ZED_OUTPUT_DIR/zed" "$ZED_OUTPUT_DIR/zed.old" 2>/dev/null || true
  fi
  mv "$ZED_OUTPUT_DIR/zed.new" "$ZED_OUTPUT_DIR/zed"
  rm -f "$ZED_OUTPUT_DIR/zed.old" 2>/dev/null || true

  # Get binary info
  local BINARY_SIZE=$(du -h "$ZED_OUTPUT_DIR/zed" | cut -f1)

  echo "âœ… Zed binary copied to: $ZED_OUTPUT_DIR/zed"
  echo "ğŸ“¦ Binary size: $BINARY_SIZE"

  # Verify external WebSocket sync is included
  if strings "$ZED_OUTPUT_DIR/zed" | grep -q "external_websocket_sync"; then
    echo "âœ… External WebSocket Thread Sync detected in binary"
  else
    echo "âš ï¸  External WebSocket Thread Sync not clearly detectable (this might be normal)"
  fi

  # Note: Release builds are already stripped via RUSTFLAGS during compilation
  if [ "$BUILD_TYPE" = "release" ]; then
    echo "âœ… Binary built with symbols stripped (via linker flags)"
  fi

  # Create test configuration
  cat > "$ZED_OUTPUT_DIR/test-settings.json" << EOF
{
  "external_websocket_sync": {
    "enabled": true,
    "server": {
      "enabled": true,
      "host": "127.0.0.1",
      "port": 3030
    },
    "websocket_sync": {
      "enabled": true,
      "external_url": "localhost:8080",
      "use_tls": false,
      "auto_reconnect": true
    }
  }
}
EOF

  echo "âœ… Created test configuration: $ZED_OUTPUT_DIR/test-settings.json"
  echo "ğŸ‰ Zed build completed successfully!"
  echo ""
  echo "Next steps:"
  echo "  1. Test the binary: cd $ZED_OUTPUT_DIR && ./zed --version"
  echo "  2. Build Sway container with Zed: ./stack build-sway"
  echo "  3. Start services: ./stack start"
}

function start() {
  if tmux has-session -t "$TMUX_SESSION" 2>/dev/null; then
    echo "ğŸ“º Session $TMUX_SESSION already exists. Attaching..."
    sleep 1
    tmux -2 attach -t $TMUX_SESSION
    exit 0;
  fi

  # Check for Zed dependency and build if needed
  if [ ! -d "../zed" ]; then
    echo "âŒ ERROR: Zed source code not found at ../zed/"
    echo ""
    echo "The Zed runner requires the Zed source code to be checked out alongside Helix."
    echo ""
    echo "Please run:"
    echo "  cd .."
    echo "  git clone https://github.com/helixml/zed.git"
    echo "  cd helix"
    echo "  ./stack start"
    exit 1
  fi

  if [ ! -f "./zed-build/zed" ]; then
    echo "ğŸ”¨ Zed binary not found, building automatically..."
    build-zed || {
      echo "âŒ Failed to build Zed. Please check the error messages above."
      exit 1
    }
  fi

  # Check if Wolf container exists, build if needed
  if ! docker image inspect wolf:helix-fixed &> /dev/null; then
    echo "ğŸº Wolf container not found, building automatically..."
    build-wolf || {
      echo "âŒ Failed to build Wolf. Please check the error messages above."
      exit 1
    }
  fi

  # Check if Moonlight Web container exists, build if needed
  if ! docker image inspect helix-moonlight-web:helix-fixed &> /dev/null; then
    echo "ğŸŒ™ Moonlight Web container not found, building automatically..."
    build-moonlight-web || {
      echo "âŒ Failed to build Moonlight Web. Please check the error messages above."
      exit 1
    }
  fi

  export MANUALRUN=1
  export LOG_LEVEL=debug

  echo "ğŸ³ Starting docker compose"

  # Setup runner profiles first
  setup_runner_profile

  # Setup sandbox profile based on GPU detection
  setup_sandbox_profile

  # Clean Wolf and Moonlight Web pairing state for fresh startup
  echo "ğŸ§¹ Cleaning Wolf and Moonlight Web pairing state..."

  # Stop sandbox if running (Wolf + Moonlight Web are unified in sandbox now)
  docker compose -f docker-compose.dev.yaml stop "$SANDBOX_SERVICE" 2>/dev/null || true

  # Remove state files to force fresh pairing on startup
  # These are bind-mounted into the sandbox container
  rm -f "$DIR/wolf/config.toml" "$DIR/moonlight-web-config/data.json" 2>/dev/null || true
  echo "âœ… Pairing state cleaned (will auto-pair on startup)"

  # Start services based on enabled profiles
  if [[ -n "$WITH_RUNNER" ]]; then
    if [[ -n "$WITH_DEMOS" ]]; then
      # Both runner and demos
      echo "ğŸš€ Starting services with runner ($RUNNER_CONTAINER) and demos profiles"
      docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" --profile demos up -d
    else
      # Just runner
      echo "ğŸš€ Starting services with runner ($RUNNER_CONTAINER) profile"
      docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" up -d
    fi
  elif [[ -n "$WITH_DEMOS" ]]; then
    # Just demos
    echo "ğŸš€ Starting services with demos profile"
    docker compose -f docker-compose.dev.yaml --profile demos up -d
  else
    # No special profiles
    echo "ğŸš€ Starting base services"
    docker compose -f docker-compose.dev.yaml up -d
  fi

  sleep 2

  # Wait for postgres to be ready before trying to wipe slots
  echo "â³ Waiting for postgres to be ready..."
  timeout=60
  while ! docker compose -f docker-compose.dev.yaml exec postgres pg_isready -h localhost -p 5432 >/dev/null 2>&1; do
    timeout=$((timeout - 1))
    if [[ $timeout -eq 0 ]]; then
      echo "âš ï¸ Warning: Postgres not ready after 60 seconds, continuing anyway"
      break
    fi
    echo "â³ Waiting for postgres... ($timeout seconds remaining)"
    sleep 1
  done

  # Check if WIPE_SLOTS is set and wipe slots if requested
  if [[ -n "$WIPE_SLOTS" ]]; then
    echo "ğŸ§¹ WIPE_SLOTS is set, wiping slots from database..."
    if ! wipe-slots; then
      echo "âš ï¸ Warning: Failed to wipe slots, but continuing startup..."
    fi
  fi

  echo "ğŸ“º Creating tmux session $TMUX_SESSION with 3x2 grid layout + full-width hacking terminal..."
  tmux -2 new-session -d -s "$TMUX_SESSION"

  # Create a 3x2 grid layout with full-width hacking terminal at bottom
  # First create top and middle rows for logs
  tmux split-window -v -d
  tmux split-window -v -d

  # Split the top row into 3 columns (Frontend, API, Haystack)
  tmux select-pane -t 0
  tmux split-window -h -d
  tmux select-pane -t 1
  tmux split-window -h -d

  # Split the middle row into 3 columns (Zed Agent, Zed Process, GPU Runner)
  tmux select-pane -t 3
  tmux split-window -h -d
  tmux select-pane -t 4
  tmux split-window -h -d

  # Bottom pane (6) stays full-width for hacking terminal

  # Set pane titles and start processes in 3x2 + full-width layout
  # Top row (0-2): Frontend, API, Haystack
  tmux select-pane -t 0 -T "Frontend Logs"
  tmux send-keys -t 0 'docker compose -f docker-compose.dev.yaml logs -f frontend' C-m

  tmux select-pane -t 1 -T "API Logs"
  tmux send-keys -t 1 'docker compose -f docker-compose.dev.yaml logs -f api' C-m

  tmux select-pane -t 2 -T "Haystack Logs"
  tmux send-keys -t 2 'docker compose -f docker-compose.dev.yaml logs -f haystack' C-m

  # Middle row (3-5): Context-aware based on WITH_RUNNER
  if [[ -n "$WITH_RUNNER" ]]; then
    # WITH_RUNNER mode: Sandbox logs in pane 3
    tmux select-pane -t 3 -T "Sandbox Logs (Wolf + Moonlight)"
    tmux send-keys -t 3 "docker compose -f docker-compose.dev.yaml logs -f $SANDBOX_SERVICE" C-m

    tmux select-pane -t 4 -T "ğŸ”¨ HACKING TERMINAL"
    tmux send-keys -t 4 'echo "ğŸ”¨ Hacking terminal ready!" && echo "ğŸ’¡ Tip: Use this for development, debugging, and building"' C-m

    # GPU runner logs with air hot reloading
    tmux select-pane -t 5 -T "GPU Runner ($RUNNER_CONTAINER)"
    tmux send-keys -t 5 'echo "Monitoring GPU Runner logs (with air hot reloading)..." && sleep 3 && docker compose -f docker-compose.dev.yaml --profile '"$RUNNER_CONTAINER"' logs -f '"$RUNNER_CONTAINER" C-m
  else
    # WITHOUT_RUNNER mode: Unified sandbox logs (Wolf + Moonlight Web in one container)
    tmux select-pane -t 3 -T "Sandbox Logs (Wolf + Moonlight)"
    tmux send-keys -t 3 "docker compose -f docker-compose.dev.yaml logs -f $SANDBOX_SERVICE" C-m

    tmux select-pane -t 4 -T "ğŸ”¨ HACKING TERMINAL"
    tmux send-keys -t 4 'echo "ğŸ”¨ Hacking terminal ready!" && echo "ğŸ’¡ Tip: Use this for development, debugging, and building"' C-m

    # Middle right pane (5) - contextual based on demos
    if [[ -n "$WITH_DEMOS" ]]; then
      # Demos interactive session
      tmux select-pane -t 5 -T "Demos"
      tmux send-keys -t 5 'docker compose -f docker-compose.dev.yaml --profile demos exec demos bash' C-m
    else
      # Hacking terminal
      tmux select-pane -t 5 -T "ğŸ”¨ HACKING TERMINAL"
      tmux send-keys -t 5 'echo "ğŸ”¨ Hacking terminal ready!" && echo "ğŸ’¡ Tip: Use this for development, debugging, and building"' C-m
    fi
  fi

  # Bottom full-width pane (6) - HACKING TERMINAL! ğŸ”¨
  tmux select-pane -t 6 -T "ğŸ”¨ HACKING TERMINAL"
  tmux send-keys -t 6 'echo "ğŸ”¨ Full-width hacking terminal ready!" && echo "ğŸ’¡ Tip: Use this for development, debugging, and building"' C-m

  if [[ -n "$WITH_DEMOS" && -n "$WITH_RUNNER" ]]; then
    echo "Note: Both GPU runner and demos enabled - demos available in background. Run manually with: docker compose -f docker-compose.dev.yaml --profile demos exec demos bash"
  fi

  # Enable pane titles display
  tmux set-option -g pane-border-status top
  tmux set-option -g pane-border-format "#{pane_index}: #{pane_title}"

  # Make all panes equal size
  tmux select-layout even-horizontal
  tmux select-layout tiled

  tmux -2 attach-session -t $TMUX_SESSION
}

function stop() {
  echo "ğŸ›‘ Stopping docker containers and tmux session..."

  # Clean up Wolf config and certificates to ensure fresh start next time
  if [ -f "wolf/config.toml" ]; then
    echo "ğŸ—‘ï¸  Removing Wolf config.toml (will be regenerated from template on next start)"
    rm -f wolf/config.toml
  fi
  if [ -f "wolf/cert.pem" ] || [ -f "wolf/key.pem" ]; then
    echo "ğŸ—‘ï¸  Removing Wolf SSL certificates (will be regenerated on next start)"
    rm -f wolf/cert.pem wolf/key.pem
  fi

  # Clean up Moonlight Web pairing data to ensure fresh pairing with Wolf's new certs
  if [ -f "moonlight-web-config/data.json" ]; then
    echo "ğŸ—‘ï¸  Removing Moonlight Web pairing data (will re-pair with Wolf on next start)"
    rm -f moonlight-web-config/data.json
  fi

  # Build exclude pattern for services that should not be stopped
  local exclude_services=()
  [[ -z "$STOP_KEYCLOAK" ]] && exclude_services+=("keycloak")
  [[ -z "$STOP_POSTGRES" ]] && exclude_services+=("postgres")
  [[ -z "$STOP_PGVECTOR" ]] && exclude_services+=("pgvector")

  # Setup runner profiles first
  setup_runner_profile

  if [[ ${#exclude_services[@]} -eq 0 ]]; then
    echo "ğŸ—‘ï¸ Removing all docker containers"

    # Stop containers based on enabled profiles
    if [[ -n "$WITH_RUNNER" ]]; then
      if [[ -n "$WITH_DEMOS" ]]; then
        # Both runner and demos
        echo "ğŸ”„ Stopping services with runner ($RUNNER_CONTAINER) and demos profiles"
        docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" --profile demos down -t 1 || echo "âš ï¸  Some services may not exist"
      else
        # Just runner
        echo "ğŸ”„ Stopping services with runner ($RUNNER_CONTAINER) profile"
        docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" down -t 1 || echo "âš ï¸  Some services may not exist"
      fi
    elif [[ -n "$WITH_DEMOS" ]]; then
      # Just demos
      echo "ğŸ”„ Stopping services with demos profile"
      docker compose -f docker-compose.dev.yaml --profile demos down -t 1 || echo "âš ï¸  Some services may not exist"
    else
      # Include all profiles when no environment variables are set
      echo "ğŸ”„ Stopping all services (all profiles)"
      docker compose -f docker-compose.dev.yaml --profile runner --profile runner_gpu --profile demos down -t 1 || echo "âš ï¸  Some services may not exist"
    fi
  else
    # Create exclude list for display and grep pattern
    local exclude_list=$(IFS=', '; echo "${exclude_services[*]}")
    local exclude_pattern=$(IFS='|'; echo "${exclude_services[*]}")
    echo "ğŸ—‘ï¸ Removing docker containers (except: $exclude_list)"

    # Get list of services to stop (excluding the ones we want to keep)
    if [[ -n "$WITH_RUNNER" ]]; then
      if [[ -n "$WITH_DEMOS" ]]; then
        echo "ğŸ”„ Stopping services with runner ($RUNNER_CONTAINER) and demos profiles (except: $exclude_list)"
        local services=$(docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" --profile demos config --services 2>/dev/null | grep -v -E "$exclude_pattern" || true)
      else
        echo "ğŸ”„ Stopping services with runner ($RUNNER_CONTAINER) profile (except: $exclude_list)"
        local services=$(docker compose -f docker-compose.dev.yaml --profile "$RUNNER_CONTAINER" config --services 2>/dev/null | grep -v -E "$exclude_pattern" || true)
      fi
    elif [[ -n "$WITH_DEMOS" ]]; then
      echo "ğŸ”„ Stopping services with demos profile (except: $exclude_list)"
      local services=$(docker compose -f docker-compose.dev.yaml --profile demos config --services 2>/dev/null | grep -v -E "$exclude_pattern" || true)
    else
      echo "ğŸ”„ Stopping all services (all profiles, except: $exclude_list)"
      local services=$(docker compose -f docker-compose.dev.yaml --profile runner --profile runner_gpu --profile demos config --services 2>/dev/null | grep -v -E "$exclude_pattern" || true)
    fi

    # Stop only the non-excluded services
    if [[ -n "$services" ]]; then
      echo "ğŸ—‘ï¸ Going to remove containers: $(echo $services | tr '\n' ' ')"
      # Stop and remove containers using a while loop to avoid xargs command line length issues
      while IFS= read -r service; do
        if [[ -n "$service" ]]; then
          echo "ğŸ—‘ï¸ Stopping and removing: $service"
          docker compose -f docker-compose.dev.yaml stop "$service" 2>/dev/null && \
          docker compose -f docker-compose.dev.yaml rm -f "$service" 2>/dev/null || \
          echo "âš ï¸  Could not stop/remove $service"
        fi
      done <<< "$services"
    else
      echo "âœ¨ No services to stop (all are excluded)"
    fi
  fi

  echo "ğŸ“º Stopping tmux session $TMUX_SESSION..."
  if tmux has-session -t $TMUX_SESSION 2>/dev/null; then
    tmux kill-session -t $TMUX_SESSION || echo "âš ï¸  Failed to kill tmux session, but continuing..."
  else
    echo "ğŸ“º Tmux session $TMUX_SESSION not found"
  fi

  echo "âœ¨ Stop completed successfully!"
}

function up() {
  # Check if Wolf source code exists, if not clone it
  if [ ! -d "../wolf" ]; then
    echo "ğŸº Wolf source code not found at ../wolf/"
    echo "ğŸ“¥ Cloning Wolf repository..."
    cd ..
    git clone https://github.com/games-on-whales/wolf.git
    cd helix
    echo "âœ… Wolf repository cloned successfully"
  fi

  # Setup sandbox profile based on GPU detection (if not already in .env)
  setup_sandbox_profile

  # Sandbox services are enabled via COMPOSE_PROFILES in .env or auto-detected above
  # Profile 'code-nvidia' = NVIDIA GPU, 'code-amd-intel' = AMD/Intel GPU

  docker compose -f docker-compose.dev.yaml up -d $@
}

function build-zed-agent() {
  echo "ğŸ”¨ Building Zed agent Docker image..."

  # Build the Docker image using the Zed binary we built
  if [ ! -f "./zed-build/zed" ]; then
    echo "âŒ Zed binary not found. Run './stack build-zed' first."
    return 1
  fi

  docker build -t helix-sway:latest -f Dockerfile.sway-helix .

  if [ $? -eq 0 ]; then
    echo "âœ… Zed agent Docker image built successfully"
  else
    echo "âŒ Failed to build Zed agent Docker image"
    return 1
  fi
}

function zed-agent-up() {
  echo "Starting Zed agent services..."

  # Build Zed if binary doesn't exist
  if [ ! -f "./zed-build/zed" ]; then
    echo "Zed binary not found, building first..."
    build-zed || return 1
  fi

  # Check if image doesn't exist
  if ! docker image inspect helix/zed-agent:latest &> /dev/null; then
    echo "Zed agent image not found, building first..."
    build-zed-agent || return 1
  fi

  docker compose -f docker-compose.zed-agent.yaml up -d

  echo "âœ… Zed agent services started"
  echo "ğŸ“‹ Services running:"
  echo "  - Helix API: http://localhost:8080"
  echo "  - Zed HTTP API: http://localhost:3030"
  echo "  - VNC Web Client: http://localhost:6080"
  echo ""
  echo "ğŸ§ª Test commands:"
  echo "  curl http://localhost:8080/health    # Helix API"
  echo "  curl http://localhost:3030/health    # Zed integration API"
}

function zed-agent-down() {
  echo "Stopping Zed agent services..."
  docker compose -f docker-compose.zed-agent.yaml down
}

function zed-agent-logs() {
  docker compose -f docker-compose.zed-agent.yaml logs -f "${1:-zed-agent-runner}"
}

function rebuild() {
  docker compose -f docker-compose.dev.yaml up -d --build $@
}

# Helper function to build image tags string (commit hash + git tag if available)
function get_image_tags() {
  local OLD_IFS=$IFS
  IFS=' '  # Temporarily use space as IFS for proper word splitting

  local IMAGE_BASE=$1
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")

  local TAG_STRING="-t ${IMAGE_BASE}:${COMMIT_HASH}"

  if [ -n "$GIT_TAG" ]; then
    TAG_STRING="${TAG_STRING} -t ${IMAGE_BASE}:${GIT_TAG}"
    echo "ğŸ·ï¸  Git tag detected: ${GIT_TAG}" >&2
  fi

  printf "%s" "${TAG_STRING}"  # Use printf to avoid trailing newline issues

  IFS=$OLD_IFS
}

# Helper function to push all image tags
function push_image_tags() {
  local IMAGE_BASE=$1
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  # Use exported GIT_TAG if available (from build-and-push-helix-code), otherwise detect from git
  local GIT_TAG="${GIT_TAG:-$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")}"

  # Always push commit hash tag
  echo "ğŸ“¤ Pushing ${IMAGE_BASE}:${COMMIT_HASH}"
  if ! docker push "${IMAGE_BASE}:${COMMIT_HASH}"; then
    echo "âš ï¸  Failed to push ${IMAGE_BASE}:${COMMIT_HASH}"
    return 1
  fi

  # Also push git tag if available
  if [ -n "$GIT_TAG" ]; then
    echo "ğŸ“¤ Pushing ${IMAGE_BASE}:${GIT_TAG}"
    if ! docker push "${IMAGE_BASE}:${GIT_TAG}"; then
      echo "âš ï¸  Failed to push ${IMAGE_BASE}:${GIT_TAG}"
      return 1
    fi
  fi

  return 0
}

function build-wolf() {
  echo "ğŸº Building Wolf container with latest source code..."

  # Check if Wolf source directory exists
  if [ ! -d "../wolf" ]; then
    echo "âŒ ERROR: Wolf source code not found at ../wolf/"
    echo ""
    echo "The Wolf integration requires the Wolf source code to be checked out alongside Helix."
    echo ""
    echo "Please run:"
    echo "  cd .."
    echo "  git clone https://github.com/games-on-whales/wolf.git"
    echo "  cd helix"
    echo "  ./stack build-wolf"
    exit 1
  fi

  # Build Wolf container with image tags
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")

  echo "ğŸ”¨ Building Wolf container from source..."
  cd ../wolf

  if [ -n "$GIT_TAG" ]; then
    echo "ğŸ·ï¸  Git tag detected: ${GIT_TAG}"
    docker build -f docker/wolf.Dockerfile \
      -t wolf:helix-fixed \
      -t "registry.helixml.tech/helix/wolf:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/wolf:${GIT_TAG}" \
      .
  else
    docker build -f docker/wolf.Dockerfile \
      -t wolf:helix-fixed \
      -t "registry.helixml.tech/helix/wolf:${COMMIT_HASH}" \
      .
  fi

  if [ $? -eq 0 ]; then
    echo "âœ… Wolf container built successfully"
  else
    echo "âŒ Failed to build Wolf container"
    cd - > /dev/null
    return 1
  fi
  cd - > /dev/null

  # Note: Wolf image is an intermediate build artifact, embedded in helix-sandbox
  # It's not pushed to registry separately - only the sandbox container is pushed
  # Wolf runs inside the sandbox container now, not as a standalone service
}

function build-xfce() {
  echo "ğŸ–¥ï¸  Building custom XFCE container with passwordless sudo..."

  # Build the custom XFCE image
  echo "ğŸ”¨ Building helix-xfce:latest container..."
  if docker build -f Dockerfile.xfce-helix -t helix-xfce:latest .; then
    echo "âœ… XFCE container built successfully"
    echo "ğŸ–¥ï¸  Custom XFCE image ready: helix-xfce:latest"
    echo ""
    echo "Features added:"
    echo "  - Passwordless sudo for retro and user accounts"
    echo "  - Proper work directory permissions"
  else
    echo "âŒ Failed to build XFCE container"
    exit 1
  fi
}

# Generic desktop build function - builds any desktop (sway, zorin, ubuntu)
# Uses Docker image hashes for content-addressable versioning
function build-desktop() {
  local DESKTOP_NAME="$1"

  if [ -z "$DESKTOP_NAME" ]; then
    echo "Usage: ./stack build-desktop <name>"
    echo "Available: sway, zorin, ubuntu"
    exit 1
  fi

  local DOCKERFILE="Dockerfile.${DESKTOP_NAME}-helix"
  local IMAGE_NAME="helix-${DESKTOP_NAME}"

  # Validate Dockerfile exists
  if [ ! -f "$DOCKERFILE" ]; then
    echo "âŒ Dockerfile not found: $DOCKERFILE"
    exit 1
  fi

  echo "ğŸ–¥ï¸  Building ${DESKTOP_NAME} desktop container..."

  # Production mode: Always rebuild Zed from latest source in release mode
  if [ -n "${SKIP_DEV_RESTART:-}" ]; then
    echo "ğŸ”¨ Production mode: Building fresh Zed release from latest source..."
    if ! build-zed release; then
      echo "âŒ Failed to build Zed binary"
      exit 1
    fi
  # Dev mode: Only build if binary doesn't exist
  elif [ ! -f "./zed-build/zed" ]; then
    echo "âŒ Zed binary not found. Building in release mode first..."
    if ! build-zed release; then
      echo "âŒ Failed to build Zed binary"
      exit 1
    fi
  else
    echo "âœ… Using existing Zed binary at ./zed-build/zed (dev mode)"
  fi

  # Capture image hash BEFORE build to detect if it actually changed
  local IMAGE_HASH_BEFORE=$(docker images "${IMAGE_NAME}:latest" --format '{{.ID}}' 2>/dev/null || echo "")
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git tag --points-at HEAD 2>/dev/null | head -1)

  # Build the desktop image
  # Use --provenance=false to get stable image IDs when layers are cached
  # (BuildKit attestation manifests change each build, causing ID changes)
  echo "ğŸ”¨ Building ${IMAGE_NAME}:latest..."

  # Registry tagging only for sway (primary production image)
  if [ "$DESKTOP_NAME" = "sway" ] && [ -n "$GIT_TAG" ]; then
    echo "ğŸ·ï¸  Git tag detected: ${GIT_TAG}"
    docker build --provenance=false -f "$DOCKERFILE" \
      -t "${IMAGE_NAME}:latest" \
      -t "${IMAGE_NAME}:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/zed-agent:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/zed-agent:${GIT_TAG}" \
      .
  elif [ "$DESKTOP_NAME" = "sway" ]; then
    docker build --provenance=false -f "$DOCKERFILE" \
      -t "${IMAGE_NAME}:latest" \
      -t "${IMAGE_NAME}:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/zed-agent:${COMMIT_HASH}" \
      .
  else
    # Non-sway desktops: just latest and commit hash tags
    docker build --provenance=false -f "$DOCKERFILE" \
      -t "${IMAGE_NAME}:latest" \
      -t "${IMAGE_NAME}:${COMMIT_HASH}" \
      .
  fi

  if [ $? -ne 0 ]; then
    echo "âŒ Failed to build ${DESKTOP_NAME} container"
    exit 1
  fi

  # Capture image hash AFTER build
  local IMAGE_HASH_AFTER=$(docker images "${IMAGE_NAME}:latest" --format '{{.ID}}')

  # Get Docker image hash (content-addressable, survives save/load)
  local IMAGE_HASH=$(echo "$IMAGE_HASH_AFTER" | sed 's/sha256://')

  echo "âœ… ${DESKTOP_NAME} container built successfully"
  echo "ğŸ“¦ Image hash: ${IMAGE_HASH}"

  # Log image hash comparison for debugging cache behavior
  echo "ğŸ” Image cache check:"
  echo "   Before: ${IMAGE_HASH_BEFORE:-<not captured>}"
  echo "   After:  ${IMAGE_HASH_AFTER:-<not captured>}"
  if [ -f "sandbox-images/${IMAGE_NAME}.tar" ]; then
    echo "   Tarball: exists ($(du -h sandbox-images/${IMAGE_NAME}.tar | cut -f1))"
  else
    echo "   Tarball: missing"
  fi

  # Skip export if: image unchanged AND tarball exists
  if [ -n "$IMAGE_HASH_BEFORE" ] && [ "$IMAGE_HASH_BEFORE" = "$IMAGE_HASH_AFTER" ] && [ -f "sandbox-images/${IMAGE_NAME}.tar" ]; then
    TARBALL_SIZE=$(du -h "sandbox-images/${IMAGE_NAME}.tar" | cut -f1)
    echo "âœ… Image unchanged, tarball up-to-date: sandbox-images/${IMAGE_NAME}.tar ($TARBALL_SIZE) - skipping export"
    # Still transfer to sandbox if running (in case sandbox was restarted)
    if [ -z "${SKIP_DESKTOP_TRANSFER:-}" ]; then
      transfer-desktop-to-sandbox "$DESKTOP_NAME"
    fi
    return 0
  fi

  # Export tarball for embedding in sandbox
  echo "ğŸ“¦ Exporting ${DESKTOP_NAME} tarball..."
  docker save "${IMAGE_NAME}:latest" > "sandbox-images/${IMAGE_NAME}.tar"
  echo "${IMAGE_HASH}" > "sandbox-images/${IMAGE_NAME}.version"

  local TARBALL_SIZE=$(du -h "sandbox-images/${IMAGE_NAME}.tar" | cut -f1)
  echo "âœ… Tarball created: sandbox-images/${IMAGE_NAME}.tar ($TARBALL_SIZE) hash=${IMAGE_HASH}"

  # Transfer to running sandbox (hot-reload in development)
  # Skip if SKIP_DESKTOP_TRANSFER is set (called from build-sandbox)
  if [ -z "${SKIP_DESKTOP_TRANSFER:-}" ]; then
    transfer-desktop-to-sandbox "$DESKTOP_NAME"
  fi
}

# Generic transfer function - transfers any desktop image to sandbox's dockerd
function transfer-desktop-to-sandbox() {
  local DESKTOP_NAME="$1"
  local IMAGE_NAME="helix-${DESKTOP_NAME}"

  if [ -z "$DESKTOP_NAME" ]; then
    echo "Usage: transfer-desktop-to-sandbox <name>"
    return 1
  fi

  # Determine correct sandbox service/container based on GPU profile
  if [[ -f "$DIR/.env" ]]; then
    source "$DIR/.env"
  fi
  get_sandbox_names

  # Check if sandbox container is running
  if ! docker compose -f docker-compose.dev.yaml ps "$SANDBOX_SERVICE" | grep -q "Up"; then
    echo "â„¹ï¸  Sandbox container not running, skipping image transfer (will transfer on next start)"
    return 0
  fi

  # Check if image exists on host
  if ! docker images "${IMAGE_NAME}:latest" -q | grep -q .; then
    echo "âš ï¸  ${IMAGE_NAME}:latest not found on host, skipping transfer"
    return 0
  fi

  # Get image hash and commit hash for versioned tags
  local IMAGE_HASH=$(docker images "${IMAGE_NAME}:latest" --format '{{.ID}}' | sed 's/sha256://')
  local COMMIT_HASH=$(git rev-parse --short HEAD)

  # CRITICAL: Create image hash tag on host - Wolf executor requests images by hash
  # The heartbeat reports the image hash from the version file, and Wolf uses
  # helix-${desktop}:${hash} when creating containers. Without this tag, the
  # sandbox won't find the image and the container will fail to start.
  echo "ğŸ·ï¸  Tagging ${IMAGE_NAME}:latest as ${IMAGE_NAME}:${IMAGE_HASH} (for Wolf executor)..."
  docker tag "${IMAGE_NAME}:latest" "${IMAGE_NAME}:${IMAGE_HASH}"

  # Check if versioned tag exists locally
  local HAS_VERSIONED_TAG=""
  if docker images "${IMAGE_NAME}:${COMMIT_HASH}" -q | grep -q .; then
    HAS_VERSIONED_TAG="true"
  fi

  # Transfer image(s) to sandbox's dockerd
  # Always include the IMAGE_HASH tag since Wolf uses it to pull images
  local TRANSFER_SUCCESS=""
  if [ -n "$HAS_VERSIONED_TAG" ]; then
    # Transfer all tags: latest, commit hash, and image hash (Wolf uses helix-${desktop}:${hash})
    echo "ğŸ“¦ Transferring ${IMAGE_NAME}:latest, ${IMAGE_NAME}:${COMMIT_HASH}, and ${IMAGE_NAME}:${IMAGE_HASH} to sandbox's dockerd..."
    if docker save "${IMAGE_NAME}:latest" "${IMAGE_NAME}:${COMMIT_HASH}" "${IMAGE_NAME}:${IMAGE_HASH}" | docker exec -i "$SANDBOX_CONTAINER" docker load 2>/dev/null; then
      TRANSFER_SUCCESS="true"
      echo "âœ… ${IMAGE_NAME} images transferred to sandbox's dockerd"
      echo "ğŸ“¦ Image hash tag: ${IMAGE_NAME}:${IMAGE_HASH}"
    fi
  else
    # Only :latest exists - transfer with image hash tag
    echo "ğŸ“¦ Transferring ${IMAGE_NAME}:latest and ${IMAGE_NAME}:${IMAGE_HASH} to sandbox's dockerd..."
    if docker save "${IMAGE_NAME}:latest" "${IMAGE_NAME}:${IMAGE_HASH}" | docker exec -i "$SANDBOX_CONTAINER" docker load 2>/dev/null; then
      echo "âœ… ${IMAGE_NAME} images transferred to sandbox's dockerd"
      # Tag it with the commit hash inside sandbox for consistency
      echo "ğŸ·ï¸  Tagging ${IMAGE_NAME}:latest as ${IMAGE_NAME}:${COMMIT_HASH} inside sandbox..."
      docker exec "$SANDBOX_CONTAINER" docker tag "${IMAGE_NAME}:latest" "${IMAGE_NAME}:${COMMIT_HASH}"
      TRANSFER_SUCCESS="true"
      echo "ğŸ“¦ Image hash tag: ${IMAGE_NAME}:${IMAGE_HASH}"
    fi
  fi

  if [ -n "$TRANSFER_SUCCESS" ]; then
    # Version files are bind-mounted from host (updated by build-desktop)
    if [ -f "sandbox-images/${IMAGE_NAME}.version" ]; then
      echo "âœ… Version file sandbox-images/${IMAGE_NAME}.version contains: $(cat sandbox-images/${IMAGE_NAME}.version)"
    fi
    # Restart heartbeat to pick up the new version immediately
    echo "ğŸ”„ Restarting heartbeat daemon to report new version..."
    docker exec "$SANDBOX_CONTAINER" pkill -f sandbox-heartbeat 2>/dev/null || true
    echo "âœ… Image transferred and heartbeat restarted"
  else
    echo "â„¹ï¸  Could not transfer image to sandbox (container may be starting/restarting)"
  fi
}

# Backward compatibility wrappers
function build-sway() {
  build-desktop sway
}

function transfer-sway-to-sandbox() {
  transfer-desktop-to-sandbox sway
}

function build-zorin() {
  build-desktop zorin
}

function transfer-zorin-to-sandbox() {
  transfer-desktop-to-sandbox zorin
}

function build-ubuntu() {
  build-desktop ubuntu
}

function transfer-ubuntu-to-sandbox() {
  transfer-desktop-to-sandbox ubuntu
}

function build-moonlight-web() {
  echo "ğŸŒ™ Building Moonlight Web container..."

  # Check if moonlight-web source directory exists
  if [ ! -d "../moonlight-web-stream" ]; then
    echo "âŒ ERROR: Moonlight Web source code not found at ../moonlight-web-stream/"
    echo ""
    echo "The Moonlight Web integration requires the source code to be checked out alongside Helix."
    echo ""
    echo "Please run:"
    echo "  cd .."
    echo "  git clone https://github.com/helixml/moonlight-web-stream.git"
    echo "  cd helix"
    echo "  ./stack build-moonlight-web"
    exit 1
  fi

  # Build Moonlight Web container with image tags (like Wolf)
  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")

  # Determine build mode: always use release (fast, optimized)
  # Set BUILD_MODE=debug to override for debugging purposes
  local BUILD_MODE="${BUILD_MODE:-release}"
  if [ "$BUILD_MODE" = "release" ]; then
    echo "ğŸ”¨ Building Moonlight Web container from source (RELEASE MODE)..."
  else
    echo "ğŸ”¨ Building Moonlight Web container from source (DEBUG MODE)..."
  fi
  cd ../moonlight-web-stream

  if [ -n "$GIT_TAG" ]; then
    echo "ğŸ·ï¸  Git tag detected: ${GIT_TAG}"
    docker build -f Dockerfile \
      --build-arg BUILD_MODE=$BUILD_MODE \
      -t helix-moonlight-web:helix-fixed \
      -t "registry.helixml.tech/helix/moonlight-web:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/moonlight-web:${GIT_TAG}" \
      .
  else
    docker build -f Dockerfile \
      --build-arg BUILD_MODE=$BUILD_MODE \
      -t helix-moonlight-web:helix-fixed \
      -t "registry.helixml.tech/helix/moonlight-web:${COMMIT_HASH}" \
      .
  fi

  if [ $? -eq 0 ]; then
    echo "âœ… Moonlight Web container built successfully"
  else
    echo "âŒ Failed to build Moonlight Web container"
    cd - > /dev/null
    return 1
  fi
  cd - > /dev/null

  # Note: Moonlight Web image is an intermediate build artifact, embedded in helix-sandbox
  # It's not pushed to registry separately - only the sandbox container is pushed
  # Moonlight Web runs inside the sandbox container now, not as a standalone service
}

function build-sandbox() {
  echo "ğŸ“¦ Building unified Helix Sandbox container (Wolf + Moonlight Web + RevDial + DinD)..."
  echo ""
  echo "This builds a unified container with:"
  echo "  â€¢ Wolf streaming platform (from ~/pm/wolf)"
  echo "  â€¢ Moonlight Web (from ~/pm/moonlight-web-stream)"
  echo "  â€¢ RevDial client (built from source)"
  echo "  â€¢ Docker-in-Docker with NVIDIA runtime"
  echo "  â€¢ helix-sway image (pre-loaded into Wolf's dockerd)"
  echo "  â€¢ helix-zorin image (pre-loaded into Wolf's dockerd)"
  echo "  â€¢ GOW base-app init system (cont-init.d + entrypoint.sh)"
  echo ""

  local COMMIT_HASH=$(git rev-parse --short HEAD)
  # Use exported GIT_TAG if available (from build-and-push-helix-code), otherwise detect from git
  local GIT_TAG="${GIT_TAG:-$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")}"

  # Step 0: Build Wolf and Moonlight Web (fast if unchanged due to Docker cache)
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“ [0/6] Building Wolf and Moonlight Web dependencies..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  # Build Wolf (skip container restart - we'll restart sandbox instead)
  echo "ğŸº Building Wolf..."
  if ! SKIP_DEV_RESTART=1 build-wolf; then
    echo "âŒ Failed to build Wolf"
    return 1
  fi

  # Build Moonlight Web (skip container restart - we'll restart sandbox instead)
  echo "ğŸŒ™ Building Moonlight Web..."
  if ! SKIP_DEV_RESTART=1 build-moonlight-web; then
    echo "âŒ Failed to build Moonlight Web"
    return 1
  fi
  echo ""

  # Step 1: Build Zed if needed (required for helix-sway and helix-zorin)
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“ [1/6] Checking Zed binary..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  if [ ! -f "./zed-build/zed" ] || [ -n "${SKIP_DEV_RESTART:-}" ]; then
    echo "Building Zed in release mode..."
    if ! build-zed release; then
      echo "âŒ Failed to build Zed"
      return 1
    fi
  else
    echo "âœ… Using existing Zed binary"
  fi
  echo ""

  # Step 2: Build helix-sway and export as tarball
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“ [2/6] Building helix-sway and exporting tarball..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  # Build helix-sway image and export tarball (build-desktop now handles tarball export)
  # Skip image transfer since we'll restart sandbox with new embedded tarball
  if ! SKIP_DESKTOP_TRANSFER=1 build-sway; then
    echo "âŒ Failed to build helix-sway"
    return 1
  fi

  # Verify tarball was created (build-desktop exports it)
  if [ ! -f sandbox-images/helix-sway.tar ]; then
    echo "âŒ sandbox-images/helix-sway.tar not found after build-sway - this shouldn't happen"
    return 1
  fi

  # Remove old compressed tarball if it exists (migrating to uncompressed)
  [ -f sandbox-images/helix-sway.tar.gz ] && rm -f sandbox-images/helix-sway.tar.gz sandbox-images/helix-sway.tar.gz.hash

  TARBALL_SIZE=$(du -h sandbox-images/helix-sway.tar | cut -f1)
  echo "âœ… Using sandbox-images/helix-sway.tar ($TARBALL_SIZE) version=$(cat sandbox-images/helix-sway.version)"
  echo ""

  # Step 3: Build helix-zorin and export as tarball
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“ [3/6] Building helix-zorin and exporting tarball..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  # Build helix-zorin image and export tarball (build-desktop now handles tarball export)
  # Skip image transfer since we'll restart sandbox with new embedded tarball
  if ! SKIP_DESKTOP_TRANSFER=1 build-zorin; then
    echo "âŒ Failed to build helix-zorin"
    return 1
  fi

  # Verify tarball was created (build-desktop exports it)
  if [ ! -f sandbox-images/helix-zorin.tar ]; then
    echo "âŒ sandbox-images/helix-zorin.tar not found after build-zorin - this shouldn't happen"
    return 1
  fi

  TARBALL_SIZE=$(du -h sandbox-images/helix-zorin.tar | cut -f1)
  echo "âœ… Using sandbox-images/helix-zorin.tar ($TARBALL_SIZE) version=$(cat sandbox-images/helix-zorin.version)"
  echo ""

  # Step 4: Build helix-ubuntu and export as tarball
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“ [4/6] Building helix-ubuntu and exporting tarball..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  # Build helix-ubuntu image and export tarball (build-desktop now handles tarball export)
  # Skip image transfer since we'll restart sandbox with new embedded tarball
  if ! SKIP_DESKTOP_TRANSFER=1 build-ubuntu; then
    echo "âŒ Failed to build helix-ubuntu"
    return 1
  fi

  # Verify tarball was created (build-desktop exports it)
  if [ ! -f sandbox-images/helix-ubuntu.tar ]; then
    echo "âŒ sandbox-images/helix-ubuntu.tar not found after build-ubuntu - this shouldn't happen"
    return 1
  fi

  TARBALL_SIZE=$(du -h sandbox-images/helix-ubuntu.tar | cut -f1)
  echo "âœ… Using sandbox-images/helix-ubuntu.tar ($TARBALL_SIZE) version=$(cat sandbox-images/helix-ubuntu.version)"
  echo ""

  # Step 5: Build unified sandbox container with embedded tarballs
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“ [5/6] Building helix-sandbox container..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  # Build sandbox with tarball embedded
  if [ -n "$GIT_TAG" ]; then
    echo "ğŸ·ï¸  Git tag detected: ${GIT_TAG}"
    docker build -f Dockerfile.sandbox \
      -t helix-sandbox:latest \
      -t "registry.helixml.tech/helix/helix-sandbox:${COMMIT_HASH}" \
      -t "registry.helixml.tech/helix/helix-sandbox:${GIT_TAG}" \
      .
  else
    docker build -f Dockerfile.sandbox \
      -t helix-sandbox:latest \
      -t "registry.helixml.tech/helix/helix-sandbox:${COMMIT_HASH}" \
      .
  fi

  if [ $? -ne 0 ]; then
    echo "âŒ Failed to build helix-sandbox container"
    rm -f sandbox-images/helix-sway.tar sandbox-images/helix-zorin.tar sandbox-images/helix-ubuntu.tar
    return 1
  fi

  # Keep tarballs for future builds (enables fast rebuilds when desktop images are cached)
  # Only cleanup on failure or when explicitly requested
  echo "âœ… helix-sandbox container built successfully (kept tarballs for next build)"
  echo ""

  # Step 6: Restart sandbox and transfer fresh image
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“ [6/6] Restarting sandbox container..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

  # Restart to pick up new image (handled by existing code below)

  # Push to registry in production mode
  if [ -n "${PUSH_TO_REGISTRY:-}" ]; then
    echo "ğŸ“¤ Pushing sandbox image to registry..."

    # Push helix-sandbox (contains Wolf + Moonlight Web + helix-sway + helix-zorin + helix-ubuntu tarballs)
    local SANDBOX_BASE="registry.helixml.tech/helix/helix-sandbox"
    if push_image_tags "$SANDBOX_BASE"; then
      echo "âœ… Sandbox images pushed successfully"
    else
      echo "âš ï¸  Failed to push sandbox images"
      return 1
    fi

    echo "ğŸ“¦ Registry images pushed (desktop images are embedded, not pushed separately)"
  fi

  # Restart sandbox in dev mode
  if [ -z "${SKIP_DEV_RESTART:-}" ]; then
    # Determine correct sandbox service based on GPU profile
    if [[ -f "$DIR/.env" ]]; then
      source "$DIR/.env"
    fi
    get_sandbox_names
    echo "ğŸ”„ Restarting sandbox container ($SANDBOX_SERVICE) with updated image..."
    docker compose -f docker-compose.dev.yaml rm -f "$SANDBOX_SERVICE"
    docker compose -f docker-compose.dev.yaml up -d "$SANDBOX_SERVICE"

    echo "âœ… Sandbox container rebuilt and restarted successfully"
  fi

  echo ""
  echo "ğŸ“¦ Unified sandbox ready: helix-sandbox:latest"
  echo ""
  echo "Components included:"
  echo "  â€¢ Wolf (streaming platform)"
  echo "  â€¢ Moonlight Web (WebRTC browser streaming)"
  echo "  â€¢ RevDial client (control plane connection)"
  echo "  â€¢ Docker-in-Docker (Wolf's isolated dockerd)"
  echo "  â€¢ helix-sway image (pre-loaded tarball: $TARBALL_SIZE)"
  echo ""
  echo "Services managed by GOW's init system:"
  echo "  â€¢ 04-start-dockerd.sh - starts Wolf's dockerd + loads helix-sway"
  echo "  â€¢ 05-init-wolf-config.sh - initializes Wolf config"
  echo "  â€¢ 06-init-moonlight-config.sh - initializes Moonlight Web"
  echo "  â€¢ 07-start-moonlight-web.sh - starts Moonlight Web daemon"
  echo "  â€¢ 08-start-revdial-client.sh - starts RevDial daemon (if configured)"
  echo "  â€¢ startup-app.sh - starts Wolf as main process"
  echo ""
  echo "ğŸ‰ Sandbox build completed successfully!"
}

# NOTE: This function requires specific branches to be checked out in dependency repositories:
# - wolf: wolf-ui-working (adds client_unique_id for secure auto-join)
# - moonlight-web-stream: feature/kickoff (threads Wolf client_id through stack)
# - zed: feature/external-thread-sync (external agent WebSocket sync support)
# Verify branches before running: cd ../wolf && git branch --show-current
function build-and-push-helix-code() {
  # Optional: pass a tag override as first argument to force tagging even if commit doesn't match
  local TAG_OVERRIDE="${1:-}"

  echo "ğŸš€ Building and pushing Helix Code components for production deployment"
  echo "========================================================================"
  echo ""
  echo "Note: API and Frontend are built by CI - this builds Wolf, Zed Agent, Moonlight Web, and Sandbox"
  echo ""

  # Enable image pushing to registry for production builds
  export PUSH_TO_REGISTRY=1
  # Skip dev service restarts during production builds
  export SKIP_DEV_RESTART=1

  local COMMIT_HASH=$(git rev-parse --short HEAD)
  local GIT_TAG=$(git describe --exact-match --tags HEAD 2>/dev/null || echo "")
  local BUILD_START=$(date +%s)
  local FAILED_BUILDS=()

  # Allow tag override for building specific tags even if commit doesn't exactly match
  if [ -n "$TAG_OVERRIDE" ]; then
    echo "âš ï¸  Tag override: ${TAG_OVERRIDE} (ignoring git tag check)"
    GIT_TAG="$TAG_OVERRIDE"
  fi

  # Export GIT_TAG so build-sandbox and other functions can use it
  export GIT_TAG

  echo "ğŸ“ Commit hash: ${COMMIT_HASH}"
  if [ -n "$GIT_TAG" ]; then
    echo "ğŸ·ï¸  Git tag: ${GIT_TAG}"
  fi
  echo "ğŸ“… Build started: $(date)"
  echo ""

  # Track build status
  # Note: helix-sway (Zed agent) is built as part of build-sandbox, not separately
  local TOTAL_BUILDS=3
  local COMPLETED_BUILDS=0

  # 1. Build Wolf
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“¦ [1/$TOTAL_BUILDS] Building Wolf streaming platform..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  if build-wolf; then
    echo "âœ… Wolf built and pushed successfully"
    COMPLETED_BUILDS=$((COMPLETED_BUILDS + 1))
  else
    echo "âŒ Failed to build Wolf"
    FAILED_BUILDS+=("wolf")
  fi
  echo ""

  # 2. Build Moonlight Web
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“¦ [2/$TOTAL_BUILDS] Building Moonlight Web..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  if build-moonlight-web; then
    echo "âœ… Moonlight Web built and pushed successfully"
    COMPLETED_BUILDS=$((COMPLETED_BUILDS + 1))
  else
    echo "âŒ Failed to build Moonlight Web"
    FAILED_BUILDS+=("moonlight-web")
  fi
  echo ""

  # 3. Build unified Sandbox (Wolf + Moonlight Web + Sway/Zed + RevDial + DinD)
  # Note: This also builds helix-sway (Zed agent) and embeds it as a tarball
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  echo "ğŸ“¦ [3/$TOTAL_BUILDS] Building unified Sandbox container (includes Sway/Zed)..."
  echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
  if build-sandbox; then
    echo "âœ… Sandbox built and pushed successfully"
    COMPLETED_BUILDS=$((COMPLETED_BUILDS + 1))
  else
    echo "âŒ Failed to build Sandbox"
    FAILED_BUILDS+=("sandbox")
  fi
  echo ""

  # Build summary
  local BUILD_END=$(date +%s)
  local BUILD_DURATION=$((BUILD_END - BUILD_START))
  local BUILD_MINUTES=$((BUILD_DURATION / 60))
  local BUILD_SECONDS=$((BUILD_DURATION % 60))

  echo "=========================================================================="
  echo "ğŸ‰ Build Summary"
  echo "=========================================================================="
  echo "ğŸ“Š Completed: ${COMPLETED_BUILDS}/${TOTAL_BUILDS} builds"
  echo "â±ï¸  Duration: ${BUILD_MINUTES}m ${BUILD_SECONDS}s"
  echo "ğŸ“ Commit: ${COMMIT_HASH}"
  echo "ğŸ·ï¸  Registry: registry.helixml.tech/helix/"
  echo ""

  if [ ${#FAILED_BUILDS[@]} -eq 0 ]; then
    echo "âœ… All images built and pushed successfully!"
    echo ""
    echo "ğŸ“¦ Production images ready (commit: ${COMMIT_HASH}):"
    echo "   â€¢ registry.helixml.tech/helix/helix-sandbox:${COMMIT_HASH}"
    echo ""
    echo "ğŸ“ Note: helix-sandbox contains Wolf + Moonlight Web + helix-sway (all embedded)"
    if [ -n "$GIT_TAG" ]; then
      echo ""
      echo "ğŸ“¦ Also tagged with git tag (${GIT_TAG}):"
      echo "   â€¢ registry.helixml.tech/helix/helix-sandbox:${GIT_TAG}"
    fi
    echo ""
    echo "ğŸš€ Ready for production deployment!"
    echo ""
    echo "Note: API and Frontend images are built by CI and available at:"
    echo "   â€¢ registry.helixml.tech/helix/api:${COMMIT_HASH}"
    echo "   â€¢ registry.helixml.tech/helix/frontend:${COMMIT_HASH}"
    return 0
  else
    echo "âš ï¸  Some builds failed:"
    for failed in "${FAILED_BUILDS[@]}"; do
      echo "   âœ— ${failed}"
    done
    echo ""
    echo "Please review the errors above and retry failed builds individually."
    return 1
  fi
}

function db() {
  local subcommand="${1-cli}"
  shift
  local containername="${1-postgres}"
  shift
  if [[ "$subcommand" == "cli" ]]; then
    docker compose -f docker-compose.dev.yaml exec $containername psql --user postgres "$@"
  elif [[ "$subcommand" == "pipe" ]]; then
    docker compose -f docker-compose.dev.yaml exec -T $containername psql --user postgres "$@"
  fi
}

# Regenerate test mocks
function generate() {
  go generate ./...
}

function psql() {
  db cli postgres "$@"
}

function psql_pipe() {
  db pipe postgres "$@"
}

function pgvector() {
  db cli pgvector "$@"
}

function pgvector_pipe() {
  db pipe pgvector "$@"
}

function list-slots() {
  echo "SELECT * FROM runner_slots ORDER BY created DESC;" | db pipe postgres
}

function slots() {
  echo "Formatted view of all slots:"
  echo "SELECT
    id,
    runner_id,
    model,
    runtime,
    active,
    ready,
    status,
    created::timestamp(0) as created,
    updated::timestamp(0) as updated
  FROM runner_slots
  ORDER BY created DESC;" | db pipe postgres
}

function active-slots() {
  echo "Active slots only:"
  echo "SELECT
    id,
    runner_id,
    model,
    runtime,
    status,
    created::timestamp(0) as created
  FROM runner_slots
  WHERE active = true
  ORDER BY created DESC;" | db pipe postgres
}

function slot-stats() {
  echo "Slot statistics:"
  echo "SELECT
    runner_id,
    COUNT(*) as total_slots,
    COUNT(CASE WHEN active = true THEN 1 END) as active_slots,
    COUNT(CASE WHEN active = false THEN 1 END) as inactive_slots
  FROM runner_slots
  GROUP BY runner_id
  ORDER BY total_slots DESC;" | db pipe postgres
}

function wipe-slots() {
  echo "ğŸ§¹ Wiping all slots from database..."
  echo "DELETE FROM runner_slots;" | db pipe postgres
  echo "âœ… All slots have been deleted from the database."
}

function install() {
  go install ./api/..
}

function update_openapi() {
	echo "ğŸ”„ Installing swag..."
	go install github.com/swaggo/swag/cmd/swag@v1.16.4 || {
		echo "âŒ Failed to install swag"
		return 1
	}

	echo "ğŸ”„ Generating swagger documentation..."
	swag init -g api/pkg/server/swagger.go \
		--parseDependency --parseInternal --parseDepth 3 \
		-o api/pkg/server || {
		echo "âŒ CRITICAL: Swagger generation FAILED"
		echo "Check for ParseComment errors above"
		return 1
	}

	# Verify swagger files were created
	if [[ ! -f "api/pkg/server/swagger.json" ]]; then
		echo "âŒ CRITICAL: swagger.json was not generated"
		return 1
	fi

	echo "âœ… Swagger generated successfully"
	echo "ğŸ“‹ Copying swagger to frontend..."
	cp -r api/pkg/server/swagger.yaml frontend/swagger/ || {
		echo "âŒ Failed to copy swagger.yaml"
		return 1
	}

	echo "ğŸ”„ Generating TypeScript client..."
	npx swagger-typescript-api@13.0.23 -p ./frontend/swagger/swagger.yaml -o ./frontend/src/api --axios -n api.ts || {
		echo "âŒ TypeScript client generation FAILED"
		return 1
	}

	echo "âœ… OpenAPI update complete"
}

function lint() {
        golangci-lint run
}

# Before running this, ensure Postgres port is open (5432) for local connections
# and that API server is stopped (if you started it with ./stack up)
function test-integration() {
  cd integration-test/api && go test -v "$@"
}

# Examples:
# Run all tests:                    ./stack test
# Run specific tests:               ./stack test ./api/pkg/oauth_test
# Run a single test:                ./stack test ./api/pkg/oauth_test -run TestOAuthAppIDPropagationProduction

function ollama-sync() {
  local OLLAMA_PATH="../ollama"
  local TARGET_DIR="api/pkg/ollamav11"

  # Check if we're in the right directory (should have api/ subdirectory)
  if [[ ! -d "api" ]]; then
    echo "Error: Must run from the root of the helix repository"
    echo "Expected to find 'api/' directory in current path"
    exit 1
  fi

  if [[ ! -d "$OLLAMA_PATH" ]]; then
    echo "Error: Ollama repository not found at $OLLAMA_PATH"
    echo "Expected ollama to be checked out as a sibling directory to helix"
    exit 1
  fi

  # Check that ollama is on a release tag
  echo "Checking Ollama version..."
  if [[ ! -d "$OLLAMA_PATH/.git" ]]; then
    echo "Error: $OLLAMA_PATH is not a git repository"
    exit 1
  fi

  local OLLAMA_TAG=$(cd "$OLLAMA_PATH" && git describe --exact-match --tags HEAD 2>/dev/null)
  if [[ -z "$OLLAMA_TAG" ]]; then
    local CURRENT_COMMIT=$(cd "$OLLAMA_PATH" && git rev-parse --short HEAD)
    echo "Error: Ollama is not checked out on a release tag"
    echo "Current commit: $CURRENT_COMMIT"
    echo "Please checkout a specific release tag (e.g., v0.11.4) before syncing"
    echo "Example: cd $OLLAMA_PATH && git checkout v0.11.4"
    exit 1
  fi

  echo "âœ… Ollama is on release tag: $OLLAMA_TAG"
  echo "Syncing Ollama memory estimation files..."

  # Clean out target directory first to avoid stale files
  if [[ -d "$TARGET_DIR" ]]; then
    echo "Cleaning existing target directory..."
    rm -rf "$TARGET_DIR"
  fi

  # Create target directory
  mkdir -p "$TARGET_DIR"

  # Copy core memory estimation files
  echo "Copying memory estimation files..."
  cp "$OLLAMA_PATH/llm/memory.go" "$TARGET_DIR/"

  # Copy GGML/GGUF parsing files
  echo "Copying GGML/GGUF files..."
  cp -r "$OLLAMA_PATH/fs/ggml" "$TARGET_DIR/"
  cp -r "$OLLAMA_PATH/fs/gguf" "$TARGET_DIR/"

  # Copy supporting files
  echo "Copying supporting files..."
  cp -r "$OLLAMA_PATH/discover" "$TARGET_DIR/"
  cp "$OLLAMA_PATH/api/types.go" "$TARGET_DIR/api_types.go"
  cp "$OLLAMA_PATH/envconfig/config.go" "$TARGET_DIR/envconfig.go"
  cp "$OLLAMA_PATH/format/bytes.go" "$TARGET_DIR/format.go"
  cp -r "$OLLAMA_PATH/fs/util" "$TARGET_DIR/"

  # Transform imports to use local versions
  echo "Transforming imports for local use..."

  # Transform package declarations to avoid import cycle
  sed -i 's|package llm|package ollamav11|g' "$TARGET_DIR/memory.go"
  sed -i 's|package api|package ollamav11|g' "$TARGET_DIR/api_types.go"
  sed -i 's|package envconfig|package ollamav11|g' "$TARGET_DIR/envconfig.go"
  sed -i 's|package format|package ollamav11|g' "$TARGET_DIR/format.go"

  # Transform imports in memory.go - avoid self-imports by removing local package imports
  sed -i 's|"github.com/ollama/ollama/api"|.|g' "$TARGET_DIR/memory.go"
  sed -i 's|"github.com/ollama/ollama/discover"|"github.com/helixml/helix/api/pkg/ollamav11/discover"|g' "$TARGET_DIR/memory.go"
  sed -i 's|"github.com/ollama/ollama/envconfig"|.|g' "$TARGET_DIR/memory.go"
  sed -i 's|"github.com/ollama/ollama/format"|.|g' "$TARGET_DIR/memory.go"
  sed -i 's|"github.com/ollama/ollama/fs/ggml"|"github.com/helixml/helix/api/pkg/ollamav11/ggml"|g' "$TARGET_DIR/memory.go"

  # Remove the dot imports that were created (they'll use local functions)
  sed -i '/^\s*\.\s*$/d' "$TARGET_DIR/memory.go"

  # Transform imports in subdirectories
  find "$TARGET_DIR/ggml" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/fs/gguf"|"github.com/helixml/helix/api/pkg/ollamav11/gguf"|g' {} \;
  find "$TARGET_DIR/ggml" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/fs/util/bufioutil"|"github.com/helixml/helix/api/pkg/ollamav11/util/bufioutil"|g' {} \;
  find "$TARGET_DIR/gguf" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/fs/ggml"|"github.com/helixml/helix/api/pkg/ollamav11/ggml"|g' {} \;
  find "$TARGET_DIR/discover" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/envconfig"|"github.com/helixml/helix/api/pkg/ollamav11"|g' {} \;
  find "$TARGET_DIR/discover" -name "*.go" -exec sed -i 's|"github.com/ollama/ollama/format"|"github.com/helixml/helix/api/pkg/ollamav11"|g' {} \;

  echo "Import transformations complete. You can now create type adapters manually."

  # Create sync info file
  cat > "$TARGET_DIR/SYNC_INFO.md" << EOF
# Ollama Memory Estimation Sync

**Synced from:** $OLLAMA_PATH
**Ollama version:** $OLLAMA_TAG
**Sync date:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")

## Files synced:
- llm/memory.go â†’ memory.go
- fs/ggml/ â†’ ggml/
- fs/gguf/ â†’ gguf/
- discover/ â†’ discover/
- api/types.go â†’ api_types.go
- envconfig/config.go â†’ envconfig.go
- format/bytes.go â†’ format.go
- fs/util/ â†’ util/

## Next steps:
1. Create type adapters to convert Helix types to Ollama types
2. Modify imports in copied files to use local versions
3. Use exact Ollama EstimateGPULayers function with adapted types

## Important:
This sync was done against Ollama $OLLAMA_TAG. If Ollama is updated,
re-run './stack ollama-sync' to get the latest memory estimation algorithms.
EOF

  echo "âœ… Ollama files synced to $TARGET_DIR"
  echo "ğŸ“„ See $TARGET_DIR/SYNC_INFO.md for details"
  echo ""
  echo "Next steps:"
  echo "1. Create type adapters in api/pkg/memory/ollama_wrapper.go"
  echo "2. Update imports in copied files to use local versions"
  echo "3. Test with exact Ollama memory estimation algorithm"
}

function test() {
  # Ingest env variables from .env file
  set -a
  source .env
  set +a

  # Check whether environment variables are set. If not, error
  if [[ -z "$TOGETHER_API_KEY" ]]; then
    echo "TOGETHER_API_KEY is not set"
    exit 1
  fi
  if [[ -z "$TOGETHER_BASE_URL" ]]; then
    echo "TOGETHER_BASE_URL is not set"
    exit 1
  fi

  # Ensure postgres, tika, typesense and chrome are running
  docker compose -f docker-compose.dev.yaml up -d postgres tika typesense chrome pgvector keycloak

  # Database config (running in a sidecar)
  export POSTGRES_USER=postgres
  export POSTGRES_PASSWORD=postgres
  export POSTGRES_DATABASE=postgres
  export POSTGRES_HOST=localhost

  export KEYCLOAK_USER=admin
  export KEYCLOAK_PASSWORD=oh-hallo-insecure-password

  export PGVECTOR_USER=postgres
  export PGVECTOR_PASSWORD=postgres
  export PGVECTOR_DATABASE=postgres
  export PGVECTOR_HOST=localhost
  export PGVECTOR_PORT=5433

  export TYPESENSE_URL=http://localhost:8108
  export TYPESENSE_API_KEY=typesense
  export TEXT_EXTRACTION_TIKA_URL=http://localhost:9998
  export RAG_CRAWLER_LAUNCHER_URL=http://localhost:7317

  # To debug test hangs, try this:
  # Run tests one at a time and show which test is running

  # If a test path is provided, run tests from that path,
  # otherwise run all tests
  if [[ $# -gt 0 ]]; then
    echo "Running tests from path: $1"
    go test -v -p 1 "$@" 2>&1 | sed -u 's/^/[TEST] /'
  else
    echo "Running all tests"
    go test -v -p 1 ./... 2>&1 | sed -u 's/^/[TEST] /'
  fi
}

function zed-test() {
  echo "Testing Zed with External WebSocket Thread Sync..."

  if [ ! -f "./zed-build/zed" ]; then
    echo "âŒ Zed binary not found. Run: ./stack build-zed"
    return 1
  fi

  echo "ğŸ§ª Running basic tests..."

  # Test 1: Binary execution
  if ./zed-build/zed --version > /dev/null 2>&1; then
    echo "âœ… Zed binary executes successfully"
  else
    echo "âŒ Zed binary failed to execute"
    return 1
  fi

  # Test 2: Check for external sync feature
  if strings ./zed-build/zed | grep -q "external_websocket_sync"; then
    echo "âœ… External WebSocket Thread Sync feature detected"
  else
    echo "âš ï¸  External WebSocket Thread Sync not clearly detectable"
  fi

  echo "ğŸ‰ Basic Zed tests passed!"
  echo ""
  echo "For full integration testing:"
  echo "  1. Start Zed: RUST_LOG=external_websocket_sync=debug ./zed-build/zed"
  echo "  2. Open a project folder"
  echo "  3. Test API: curl http://localhost:3030/health"
}

function help() {
  echo "Helix Stack Management Tool"
  echo ""
  echo "Available commands:"
  echo "  build              - Build docker containers (optionally with WITH_RUNNER or WITH_DEMOS)"
  echo "  build-runner       - Build the helix-runner binary locally"
  echo "  build-runner-image - Build the runner Docker image (includes ROCm vLLM)"
  echo "  static-compile     - Build static Go binary"
  echo "  start              - Start the development environment with tmux"
  echo "  stop               - Stop docker containers"
  echo "  mock-runner        - Start a mock runner for testing"
  echo "  up [services]      - Start specific docker services"
  echo "  rebuild [services] - Rebuild and start specific docker services"
  echo ""
  echo "Production build commands:"
  echo "  build-and-push-helix-code [tag] - Build ALL Helix Code images and push to registry (optional tag override)"
  echo "  build-sandbox      - Build unified sandbox container (Wolf + Moonlight Web + RevDial + DinD)"
  echo "  build-wolf         - Build Wolf container with latest source code"
  echo "  build-xfce         - Build custom XFCE container with passwordless sudo"
  echo "  build-desktop <name> - Build desktop container (sway, zorin, ubuntu)"
  echo "  build-sway         - Build Sway+Zed container (alias for build-desktop sway)"
  echo "  build-zorin        - Build Zorin+Zed container (alias for build-desktop zorin)"
  echo "  build-ubuntu       - Build Ubuntu+Zed container (alias for build-desktop ubuntu)"
  echo "  build-moonlight-web - Build Moonlight Web container and push to registry"
  echo ""
  echo "Zed Agent commands:"
  echo "  build-zed [dev|release] - Build Zed binary (stripped in release mode)"
  echo "  build-zed-agent    - Build Zed agent Docker image"
  echo "  zed-agent-up       - Start Zed agent services"
  echo "  zed-agent-down     - Stop Zed agent services"
  echo "  zed-agent-logs [service] - View Zed agent logs"
  echo "  zed-test           - Test Zed binary functionality"
  echo ""
  echo "Database commands:"
  echo "  db [cli|pipe] [postgres|pgvector] - Access database"
  echo "  psql               - PostgreSQL CLI"
  echo "  pgvector           - PGVector CLI"
  echo "  list-slots         - List all runner slots"
  echo "  slots              - Formatted view of all slots"
  echo "  active-slots       - Show only active slots"
  echo "  slot-stats         - Show slot statistics"
  echo "  wipe-slots         - Delete all slots from database"
  echo ""
  echo "Development commands:"
  echo "  generate           - Generate test mocks"
  echo "  update_openapi     - Update OpenAPI documentation"
  echo "  lint               - Run linter"
  echo "  test [path]        - Run tests"
  echo "  test-integration   - Run integration tests"
  echo "  ollama-sync        - Sync Ollama memory estimation files"
  echo ""
  echo "Environment variables:"
  echo "  WITH_RUNNER=1      - Include runner containers"
  echo "  WITH_DEMOS=1       - Include demo containers"
  echo "  FORCE_CPU=1        - Force CPU-only mode"
  echo "  WIPE_SLOTS=1       - Wipe database slots on start"
  echo "  STOP_KEYCLOAK=1    - Stop Keycloak when stopping"
  echo "  STOP_POSTGRES=1    - Stop PostgreSQL when stopping"
  echo "  STOP_PGVECTOR=1    - Stop PGVector when stopping"
}

# Show help if no arguments provided
if [[ $# -eq 0 ]]; then
  help
  exit 0
fi

eval "$@"
